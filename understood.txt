UNDERSTOOD (MATH)

Finite dimensional normed vector space is complete: isometrically isomorphic to K^n with l^2 norm, so it must be complete.

Compactness of subsets of finite dimensional normed vector space is equivalent to closed and boundedness: forward: closure and boundedness is preserved under equivalent norms, identity map on equivalent norms is continuous, so it is really just a statement on how closure and boundedness is equivalent to compactness in topology.

All norms are equivalent on finite dimensional vector space: harder than K^n since you need to construct a norm on V. First construct Euclidean norm on components of the basis of V, then apply that K^n with l^2 norm is isometrically isomorphic to this norm. So it is sufficient to prove norms being equivalent on K^n since equivalence of norms is equivalence relation. Now use the tirangle inequality and the Cauchy-Schwarz inequality (see Robinson) to show norm(x) <= C norm_E(x) and some details attaining lower bound, considering unit spherical shell in K^n as closed and bounded subset of K^n and is compact to show norm(x) >= alpha norm_E(x). It just seems like there are a lot of details for this proof, hard to keep it in your head.

Contraction mapping theorem (Banach fixed point theorem): suppose non-empty CLOSED subset K of a completed normed space X with norm norm(x), let f: K -> K be a contraction a endomorphism which norm(f(x) - f(y)) <= k norm((x - y)), for k < 1, then f has a fixed point in the subset k, there exist a unique point where f(x) = x. NOTE: for k <= 1, you need compactness of K. Proof involves constructing a Cauchy sequence bounded by repeatedly using this inequality on terms of the convergent subsequence, then use X being Banach space, K closed, so this limit must be in this set K. Note that such a contraction is CONTINOUS by definition (preimage of opens is in K), we have that function of convergent f(x_n) -> f(x) this is nice since function is continuous, you have the limit of this subsequence x to be equal to f(x) of the contraction, so this is a fixed point. Uniqueness follows by considering norms norm(x - y) = norm(f(x) - f(y)) <= (k) norm(x - y). So we have (1 - k) norm(x - y) = 0 using the fact that k is less than 1, and norm(x - y) is nonnegative. Therefore, x = y.

Fixed point under function: x = f(x) after action of the function.

Contraction mapping: endomorphism on non-empty closed subset K such that distance between f(x) and f(y) in this set K is bounded by a scalar multiple k * distance between x and y, where k is in closed unit interval from 0 to 1 in reals. Note, this works since when define norms it is output on the half open positive ray [0, infinity).

Convergent series of norms of Banach spaces implies sequence converges in the Banach space: let X be such that Banach space, key step is to show that partial sums form a Cauchy sequence using the triangle inequality repeatedly, since the Banach space is complete. Sequence convergent.

Space is normed space where series of norms if finite AND the sum of components converges in the space so the space must be Banach space: two key steps, equivalently show some subsequence converges to y (this needs to be shown separately), next key step is to think that each term is bounded by 2^(-k) carefully using (y_i) is Cauchy so that the full norm is bounded by 1, then replace this with x_j which is some difference, this shows that series of norms is finite, so series of x_j converges to some y in X, then define y_1 + series of differences equal to y_n_j to show this converges to y, so X is complete and y_k converges to y.

Product of Banach spaces is Banach space for Manhattan form and Eculidean norm: proof: step 1 Cauchy sequence, show that p-norms are bounded by epsilon gap using Cauchy sequences in X and Y. Then take difference between norm of convergence of sequences with their converged limit in each component versus that of the pair. Therefore product of components converge to their pair of points, so the product space is alsi complete.

Cauchy seqeuence: sequence that convergeces in metric space i.le. for every nonzero gap epsilon, there exists an integer lower bound N such that d(x_n, x_m) is bounded by (less than) the gap epsilon for all _n and _m more than this lower bound N. Apply triangle inequality, so this definition makes sense when we are careful to use half of the nonzero gap epsilon, which is epsilon/2.

Complete metric space: a space where every Cauchy sequence converges.

Banach space: normed complete metric spaces. The reals and the complexes are completes. This carries over to powers of reals and complexes with standard norms. Examples: space of l^p sequences l^p(K), c0(K), l^\infty(K), space C^1([a,b]) is complete on closed intervals.

Linear closed subspaces of Banach spaces are Banach spaces: proof key step, forward just apply thae fact that it is Cauchy in Y and then it is Cauchy in X, the limit must be in Y since Y is closed. For reverse, if Y is complete then a must be in X, and Cauchy sequences converge in Y, so Y must be closed.

Banach spaces with equivalent norms must be equivalent under completeness: first spell out definition of equivalent norms, key step is to use left haft and right half of equivalence inequality properly, right half implies that Cauchy sequence (x_n) in X must be Cauchy sequence (Tx_n) in Y. Use the fact that Y is a Banach space (complete), then you can use left half to show that X is Banach space by taking preimages of the sequences and using the left half tending to zero when Y is complete. Lemma 4.5 in Robinson, just use endomorphism of maps with different norms.

Completeness arguments prototype: step 1, define what it means for sequence to be Cauchy, step 2: use this definition to identify a limit, step 3, show it convergences to this limit with the appropriate norm, step 4, show this limit lies in the correct space.

K^d complete with standard norm: step 1, pick l2 norm to be complete, then consider arbitray powers of n and m where |x_i^n 0 x_i^m| less than equal to bounded gap epsilon. Show that candidate l^2 norm is bounded so limit of this gap in the arbitrary case convergeces to zero., and this limit lies as an element of K^n.

Linear subspaces of normed spaces need not be closed: this is easy, take unit ball, consider the sum of two identical unit vectors in the ball, it will escape.

Equivalent norms preserve convergence and continuity: for convergence consider c1 norm1(x_n - x) <= norm2(x_n -x) <= c2 norm1(x_n - x). Convergence to zero for norm 1 is equivalent to convergence to zero for norm 2. Compactness is defined by open covers, so equivalence under scalar multiplication means that equivalence of norms preserve compactness.

Isomorphism of normed spaces: if we have a map from normed space X to normed space Y that is a bijection under sets, linear preserving vector space (so this is a matrix) and makes it such that c1 normX(x) <= normY(Tx) <= c2 normX(x) i.e. the map Tx makes norms X and norm Y equivalent, then this is an nisomorphism of normed spaces. Linear maps that are bijections are requirement for isomorphism of vector spaces, so this third property gives it an equivalence of norms. Normed spaces are isomorphic if we have this isomorphism. Intuitively, it is an isomorphism of vector spaces + equivalence of norms.

C^n is isometrically isomorphic to R^2n: use map (x1, y1, x2, y2, ... xn, yn), z_i = x_i + y_i as the isometric isomorphism.

Closed linear span: set of all elements that can be approximated arbitraily closly by finite linear combinations of E, this feels like separability. We call this the clin(E), which is the closure of the span of E.

Equivalence of separable, separability of unit sphere, linear space is dense: separable spaces containing countable dense subset, scale by scalar using the fact that this is a normed space, 

l^infty(K) is not separable: prove using Cantor's diagonal argument using the trivial norm ||x-y|| = 1 if they differ. So any dense set A must contain uncountable number of elements.

l^p(K) is separable: proof key step is to consider the difference between x and linear combination of unit vectors in e^j, then also sum of components powers by p is bounded by some epsilon^p, we used the fact that l^p is a norm here. Therefore the gap bbetween x and linear combination of unit vectors in e^j is the lp norm of components is bounded by another epsilon. See Robinson for a more explainable proof.

Linear span of subset of normed space: set of all finite linear combinations of elements of the subset of normed space X

Isometry: instead of enforcing equivalence of norms X and Y, we say these are equal i.e. norm_X(x) = norm_Y(Tx). Ito isometry is an example, where norms on Wiener process and on time itself are isometric in power 2.

Isometrically isomorphic, replace equivalence of norms with isometry as a condition. Still must be a isomorphism of vector space.

Lp norm is norm proof: nonnegativity show by contradiction: need to show converse, norm is 0 means it must be 0 function. Suppose you do have a nonzero function that gives norm zero, take some integral from 0 to 1 of the norm of the function, it is more than zero somehow (see Robinson for proof). Next step is simply to apply triangle inequality internally within on the convex combinations of the norm and show that it is less than or equal to 1 by careful integration.

Map from x to norm of x is always continuous: proof is by considering triangle inequality.

Equivalent norms: norms that are equivalent (reflexive, symmetric, transitive) up to constant scalar multiples i.e. c_1 norm(x1) <= norm(x2) <= c_2 norm(x1)

Sequence space: all real valued sequence such that the Lp norm is finite. At infinity, it is the space of bounded sequences equipped with the supremum norm of components.

c0(K) subspaces of null seqeuences: consists of seqeuences that have all zeroes as the number of components tends towards ifnity:

Norms on a vector space: map from vector space X to positive half open ray [0, infinity), that is zero at zero (note: nonnegative implicit in valid range), has scalar multiplication, and obeys the triangle inequality. This feels very similar to random variables actually, maps from outcome space to closed interval. Need this to define open and closed balls.

Norm on a FIELD: map from field F to real numbers, nonnegative and zero at zero, mapping is homomorphism under group product, mapping is weaker than homomorphism obey triangle inequality under group addition i.e. f(x + y) <= f(x) + f(y). Lastly, group identity makes sense f(1) = f(-1) = 1, and norm preserves group inverses i.e. f(x^-1) = x. Examples: if field is reals, the norm defined is the max norm. If the field is the complex number, the norm is the absolute modulus of product of complex numbers, or the geometric mean of a complex number and its complex conjugate. Any field has trivial norm, norm 1 if nonzero, norm zero if x is zero, and finite fields and finite field extensions only have this trivial norm (I want proof for this).

Valuation as logarithmic norm on fields: logarithmic norm on fields, generalises norm to linearly ordered ring (need linear order like in half open positive ray in reals). It is a mapping from field K into a totally ordered linear group adjoined by infinity (similar to half open positive ray.) Infinity is absorbing element, any element added to infinity gives infinity. Properties: the valuation at zero must be infinity, any valuation of an element is less than infinity, the valuation is a group homomorphism converting products f(xy) in fields to group addition in this totally ordered group f(x) + f(y) and lastly, the valuation of a difference f(x - y) is more than or equal to the minima of the valuation in this group i.e. f(x - y) >= min(f(x), f(y)).

Example of valuation as p-adic: suppose v is valuation in field K to linearly ordered group of reals R, if a is real number in open unit interval i.e. 0 < a < 1, then phi(x) = a^(v(x)) is a norm. Now pick field K to be the rationals, v_p is the p-adic valuation of Q, then we have |x| = (1/p)^(v(x)) as the p-adic norm. It is also an example of a ultrametric norm.

Ultrametric norm: useful since it looks like p-infity norm, it is a group homomorphism f(x+y) is less than or equal to the max(f(x),f(y)). It refers to the difference between the sup/max norm to this.

Normed space: vector space with norm. This has a notion of convergence, and linear structures, so series make sense.

Normed space are metric spaces: endow with taxicab distance d(x,y) = norm(x-y), pick whatever norm you want.

Open ball: set of all points where norm is strictly less than the radius. This work because norms are maps to positive half open rays, so the radius makes sense. For closed balls, change to not strictly less than the radius.

Convex subset: line segment joining two points lie within the set. Points can be as general as you want. Example, let e be the coefficient, we have ex + (1-e)y, or if we have functions we have f(ex + (1-e)y) <= e f(x) + (1 - e)f(y), where e is in open unit interval. You use an inequality here (Jensen's) to get a weaker version of homomorphism of convex functions. I realise you can have an inequality to form a weaker version of homomorphisms (I also realised homomorphism is a lot like linearity i.e. f(xy) = f(x) f(y)).

Constructing norms from bounded convex symmetric set: suppose N is zero on zero, has scalar multiplication. If the set where N applies such that N(x) is convex. Key step for proof: (N[x] / N[x] + N[y])(x / N[x]) + (N(y) / N[x] + N[y])(y / N[y]). The triangle inequality in N(x+y)/(N(x) + N(y)).

Lp norm: take sum of p power components modulus, then take 1/p power of the sum. L2 norm in Euclidean norm. Linfty is amx of components. Proof, key step is Lp norm is obviously norm, since L1 is Manhattan distance, trivially obeying triangle inequality, Linfty is a max norm, looks like a square. The function deforming L1 square to Linfty square preserves convexity of the set. You will need to show this in calculation.

Triangle inequality: I realise this is the whole basis of analysis, this is the weaker version of homomorphism, group law is addition. Example: f(x + y) <= f(x) + f(y), f is the NORM, + is the group law. If you have scalar multiple, this is just Jensen's inequality.

Max norm proofs: it always looks like this: step 1, norm is max norm, step 2: apply triangle inequality for norms within the max, step 3, decompose the max, step 4: redefine max to be the norm. State the max, split the inner norm, split the max, redefine max as norm again.

Lp norm: nonnegativity obvious.
 
Jacobson ring: used to describe the Nullstellensatz, a Jacobson ring is every prime ideal of the commutative ring R is inthe intersection of maximal ideals. See pg. 132 of Eisenbud.

Points near p in set X: Illustration in Eisenbud. Consider Y is algebraic subset of X not containing P, consider X - Y, this is not an affine algebraic set (examples: plane minus a point is not a affine algebraic set), however you can have it isomorphic to an algebraic set embedded in A^{r+1}(k). This is important: assume that Y is the set defined by vanishing of a single function f. So you can get the affine ring A(X - Y) and A(X), we can invert f by adjoining multiplicative inverses. This localisation gives is an algebraic thing like of the germ of X at p, the local ring of X at p.

Representable nature of limits / colimits: for functor diagram F: J -> C, there is natural isomorphism between C(X, lim_J F) and lim_J C(X, F-). Similarly, there is natural isomorphism for C(colim_J F, X) to lim_J^op C(F-, X). Note, be careful, the diagram is for the opposite category.

Reflective subcategory: consider category C, pick subcategory D such that inclusion (or embedding) admits left adjoint (preserving colimits) called reflector or localisation. Mnemoic: object looks at its reflection. Example: category of compact Hausdorff spaces included into category of topological spaces. The reflector left adjoint is Stone-Cech compactificiation. Example 2: category of abelian groups admitted into category of groups, the reflector right adjoint is abelianisation. Example 3: Sheaves as subcategory of presheaves, left adjoint is sheafification. Example 4: inclusion of certain categories of general commutative rings have localisation as left adjoint to inclusion. Example 5: small categories included to the category of simplicial sets, the left adjoint sends simplicial set to its homotopy category, no good name for this.

Reflection of isomorphisms: consider a full and faithful functor F from category C to category D, if Ff is isomorphism in cat D, f is morphism in C, then f is isomorphism in C. 

Creation of isomorphisms: consider a full and faithful functor F from category C to category D, if Fx is isomorphic to Fy in cat D, and x and y are objects in category C, then x and y are isomorphic in C.

Full functor: consider category C and category D with functor F : C -> D, if C(x,y) -> D(Fx, Fy) is surjective, this is full for each x, y in C.

Faithful functor: consider category C and category D with functor F : C -> D, if C(x,y) -> D(Fx, Fy) is injective, this is faithful for each x, y in C.

Essentially surjective on objects: if for object d in category D, there exists Fc for object in c and functor F that Fc is isomorphic to d, then the functor F is essential surjective.

Homotopical category: category is equipped with a class of weak equivalence.

Homotopical functor: functor is homotopical if it preserves weak equivalence.

Universal property of homotopy category: homotopical category C has a homotopy category HoC, universal property, initial among categories equipped with homotopical category C -> E, that is a functor that sends weak equivalence in C to isomorphisms.

Localisation functor: universal functor from HoC -> E. Precomposition with localisation functors induces bijection between HoC -> E and C -> E. 

Finiteness of commutative diagram: a diagram is finite if it is indexing category contains only finitely many morphisms.

Binomial theorem as convex combination: seems to be a generalisation of convex combination coefficients with NCj p^j (1-p)^(N-j), for j = 2 it is just p and (1-p), standard convex combination.

Temperature in stastistical mechanics: degree ot stochasticity in the system. See Sornette for better explanation. See also inverse temperature as measure of disorder or something.

Central limit theorem by pertubation: goal is to define some pertubation pdf close to Gaussian law, apply constraints for the cumulants and normalisation then show that the decay of the perturbation approaches zero.

Central limit theorem: normalised sum of 1/root(N) of N random independent and identically distributed variables of zero mean, and FINITE VARIANCE sigma^2 is random variable with pdf converging to Gaussian distribution with variance sigma^2. Convergence holds measure theoretical sense i.e. probability that above normalised sum falls in given integeral converges to that calculated from Gausssian distribution. Limitations: applies to centre of distribution, fails at large deviations, X_i must be independent, works for finite variance with same order of magnitude but DIFFERENT PDFS. The order of magnitude limitation is deviation sigma approximately root(N). You can relax the root(N) to get a weaker version of the central limit law. Very tricky example, but captures much of the collective phenomena one wants to study.

Central limit theorem with renormalisation group theory: see Sornette, step 1, decimate the degrees of freedom of groups of sum of pairs, this becomes some sort of tree, see Sornette, characteristic function looks like P^(n+1)(k) = [P^n(k)]^2. So cumulant is c_l^(n+1) = 2c_l(n) on log scale. Step 2 is to rescale the variables, cumulants are multiplied by 2^(a l), where a is to be determined and c_l has dimension k^(-l). In this case, pick alpha = 1/2. For cumulant cl we have 2^(1 - la), iterate process of decimation and rescaling, get that first two cumulant nonzero, rest becomes zero and shrinks in the limit, so it is a Gaussian law. Apply Fourier transform, to get characteristic equation of Gaussian law. See pg. 54 of Sornette, note that it is renormalisation of P(x, N, c1, c2, ...) = 1/(2^a) (x/2^a, N/2, 2^(1-a)c_1, ... 2^(1-l) c_l). So the second cumulant pops up naturally because in the decimation process, you just need to split into bins of two.

Stable extreme value distributions classification: Gumbel, Frechet, and Weibull. Location, scale, and shape parameter. For me, Taleb classifies political processes based on these three parameters as well.

Gumbel intuition: tail falls faster than power law, converges to Gumbel.

Frechet intuition: tail falling as power law X^(-1-mu), follows Frechet.

Weibull intuition: pdf with finite right end point, dependence close to this end point with (x_F - x)^(1 / |eta|), eta is shape parameter, x_F is endpoint. Explains why Weibull is very common.

Derivatives of the characteristic function: (-i)^n d^n(P(x))/dk^n at k = 0, then you can express it as some sort of Taylor series, in fact this will appear as the cumulants of a pdf.

Cumulants: derivatives of the logarithm of the characteristic function, it looks like the action of the (-i) as an action (circle group in the imaginary plane) on the n-th derivative of the logarithm of the probability distribution at k = 0. We have c_n = (-i)^n d^n(log(P(k)))/dk^n at k = 0. So you can write the characteristif function as the exponential of a Taylor series i.e. sum of exp(sum c_n / n! (ik)^n), it becomes the action of (ik) instead. Sum is cumulant preserving, proof is using product of convolution is product of Foruier transform. Also, it motivates alternative measures of dispersion from normality, fixing some problems with moments of a probability distribution.

Dutch book argument: bettor puts in px, house gives x, at odds (1-p)/p, house can set x to be anything but the bettor must accept both sides of the bet (win/lose). Bettor is consistent if it is not forced to accept a sure loss in probability assignment. I learnt of this argument in Sornette's book.

Mode: maximises frequency count i.e. dP/dx = 0. If nonunique, then pick largest mode value. so argmax(dP/dx = 0).

Moments (in probability, physics): average of the powers of x, so x works as action on probability. It is integral of x^n * P(x) dx, supported on the entire real line.

Support: possibilities for some values. Example: alphabets in the dictionary. Real number values possible.

Mean value based on philosophy in probability: adding all values dividing by number of cases. This is the combinatorial approach converted to the frequency approach.

Frequentist interpretation (braindead version): just imagine X number of times happening, then some part Y smaller than X will happen.

Filtration: nondecreasing family of sigma algebra F_0 in F_s in F_t , for 0 < s < t. Basically, the set of possibilities become larger.

Stochastic processes as random functions of one random variables: events are sets of paths, are typical paths continuous? Motivates random fields, with more than one random variable.

Stochastic process as probability distribution on path spaces. Use functional analysis with path spaces as infinite dimensional spaces. Measure theory suggests no analogs of Lebesgue measure (translation invariant measure) on such spaces, so hard to construct nontrivial measures on these spaces.

Motivation for Kolmogorov extension theorem: consider fixed finite set of points, get random vector distributed on finite dimensional space. Extension theorem allows one to construct stochastic process from family of consistent finite dimensional probability distributions.

Stochastic matrix is largest eigenvalue with Gershgorin discs: consult Horn, eigenvalues lie in Gershgorin disc, so spectral radius 1.

Spectral radius of probability matrices is 1: proof (Spivey) starts with assuming 1 is eigenvalue of transition matrix. Suppose we have (A - e I)x = 0, e > 1. Rows of A are nonnegative, sum to 1, each element of Ax is convex combinations of components of x, not greater than x_max. But if e > 1, one element of e x is greater than x_max, so we cannot have e > 1! See https://math.stackexchange.com/questions/40320/proof-that-the-largest-eigenvalue-of-a-stochastic-matrix-is-1.

Symmetric random walk: +-1, with probability 0.5, random walk on integers. Markov, because distribution is completely determined, probability of Xn+1 conditional on Xn alone.

Transition probabilities: probabilities in state j at n + 1, conditional on state k at time n. Motivated by definition of Markov process, so must understand what a Markov process is first.

Stationary: Markov process where transition probabilities do not depend on state n.

Invariant distribution: action of invariant distribution pi is such that pi = pi * P, i.e. probability transition matrix is idempotent on the invariant distribution.

Action of stochastic matrix of Markov chain: for Markov chain u_n, it is equal to u_n = u_0 P^n, where P^n is the repeated application of the stochastic matrix P, for time up to n (indexing set assumed to be nonnegative integers).

Stochastic matrix: all entries nonnegative, sum of all entries is 1.

Chapman-Kolmogorov equation: probability of state j at time n, given state i at time 0, is sum of all trnasition probabilities in the state space S, probability of state j at time n, given state k at time m * probability of state k at time m, given state i at time 0. This is just Baye's rule, with stipulation of Markov chain giving only one instance of the product for each state space.

Markov process: probability of Xn+1 is conditional on Xn = probability of Xn+1 conditioned on whole history.
Easy to build nonexamples, such as left right random walk such that once you go right, the next step must be right.

Ehrenfest diffusion model: middle membrane container with K particles, pick one at random and place in other part of container. This is Markov process, just look at the current state and you can determine the probability of the next outcome.

Lattice: partially ordered set where each two element subset has a UNIQUE least upper bound (join) and dually a UNIQUE greatest lower bound (meet). Alternatively, a set with two binary absorptions in to A for a join (a meet b) = a and a meet (a join b) = a.

Formal concept analysis: pick complete lattices, with pairs of objects (A, B) where A is extent or set of objects, B is intent or set of attributes. Extent contains all objects that share the attributes in B, intent contains all attributes shared by object in A. Constitutes meet and join.

Descent as inverse of stable under base change: see "https://math.stackexchange.com/questions/4769096/smooth-proper-connected-curve-over-a-field-is-projective". The idea is instead of saying "if f: X -> S has property P, then base change X *_S S' -> S' along S' -> S also has property P", we ask "if X *_S S' -> S' has property P, must f: X -> S has property P"?. For nice S' -> S (the magic words for the case presented is faithfully flat, quasicompact), then you have closed immersion, descent. 

Inverse image of sheaf which is not a sheaf: consider topological space Y, define X as two disjoint copies of Y, set f : X -> Y as canonical projection, take G, sheaf on Y. For subset V in Y open, and define U as the preimage using f on V, we have sheaf F such that  F(U) = G(V). So F = f^-1(G), F is presheaf. But the preimage of a sheaf (f^-1 F)(U) := F^sh(U) = G(V) * G(V). So the inverse image of the sheaf gives cartesian product of sheaves G, but the inverse of the canonical projection is a sheaf. Example: section of one copy, section on other copy, you cannot glue them together, intersection is empty since these are disjoint copies.

Partially ordered set: reflexive (p < p), antisymmetric (i.e. p < q or q < p but not both), and transitive (p < q < r).

Poset of truth values: {0, 1}, we have 0 < 1 as partial order.

Horizontal categorification: step 1: pick concept as magmoid (binary operation) with single object. Typical example is thinking of group as category of one object with morphisms that are all invertible (unitary by default due to category definition), the -oidfied by presenting more than one object instead.

Horizontal categorification of monoid: gives category! Start with unital associative magma i.e. one object with binary operation that has identity and is associative. Do horizontal categorification, it gives a category.

Horizontal categorification of untyped languages: is a typed language.

Magmoid: quiver (generalise set) with partial binary operation Mor(Q) * Mor(Q) -> Mor(Q) + 1, coproduct injections inj: Mor(Q) -> Mor(Q) + 1, such that there is function h in preimage inj(h) = f * g, if s(f) = t(g) and f * g  = point. Easier: groupoid is oidification of group. Group can be category with one object, and isomorphisms on that one object. Groupoid extends to more than one object.

Quiver: generalisation of set, opposite category, and even presheaves! It is a functor G from X -> Set. Where X is a walking quiver. Quiver in a category C is X -> C, C is some category.

Walking quiver: cateogry with one object of vertices X0, one object of edges X1, two "contravariant/preimagey" morphisms s,t: X1 -> X0 called source and target, with identity morphisms. For some reason, it feels like simplifical structure trying to be built in to set.

Category of quivers in C, Quiv(C): functor category C^X, where X is the walking quiver, where objects are functors G: X -> C, morphisms are natural transformations.

Examples of category of quivers in its simplest case: Quiv(Set) is equivalent to category of presheaves on X^op, where X is category of walking quivers.

Toy example of linear functional: consider functions from unit intervals to the reals, define linear functional F(u) = u(1) - u(0). F is not continuous or defined everywhere on L^2(0,1) failing at measure zero single points, but continuous on H^1(0,1). This motivates the trace operator to be defined for H1, then you can use them to sovle PDEs. This example motivates why you do not want to use L^2 spaces for everything.

L^2 space: set of square integrable L2-functions, where <f, g> = int_X fg du, for measure u. Example: pick X = reals, with Lebesgue measures, these are the square summable series. These are equivalence classes of functions with the same L^2 function where the set they differ has measure zero i.e. one point. It is a sort of density function giving bad boundary conditions in differential equations for point f(p) since it is not well defined on measure zero since it is an integral.

Functional analogous to energy: functional is analogous to ENERGY. This is why functional analysis is so important, for example minimising energy / action. Example: Dirichlet functional is integral | grad u |^2 dx

Specialisation topology / Alexandroff's topology: subset A of preordered set, is open subset if it is upward closed, i.e. if x <= y, x in A, then y is in A. This is a topology, or the specialisation topology. Example: apply specialisation topology to poset of truth values {0,1}. Start with empty, then {1} is open, and total space {0,1} is open.

Sierpinski space: set of 0, 1, topological space is {}, {1}and {0,1}. Note: {0} is omitted. It can also be defined using homotopy type theory as higher inductive type using constructors for meet, top terms; type, left, right associativitt, commutative, idempotence, for meets and joins; meet-join absorption, join-meet absorption, and other functions. Very long, see ncatlab.

Sifted category: category where colimits of diagrams of shape D commute with finite products in category of Set. Consider diagram functor F: product D and S -> Set, S is finite discrete category, the colimit commutes with finite products.

Discrete category: it is a groupoid and preorder i.e. all morphisms are invertible, and two parallel morphisms are equal.

Accessible cardinals: apply cardinal arithmetic on cardinal numbers like omega for infinity, successors, disjoint union for addition, Cartesian product for multiplication, power set of functions for exponentiation. If you cannot use these to get the cardinals you want, these are the inaccessible cardinals.

Schwarz lemma: apply maximum modulus priniciple on function g(z) = f(z) / z if z nonzero, and f'(0) if z = 0, i.e. derivative when z = 0, feels like differentiation and localisation to me, holomorphic on the whole of D at origin,look at |g(z)|. For z_r on boundary of D_r, we have |g(z_r) which must be less than 1/r, if r tends towards 1, then |g(z)| less than or equal to 1, now pick |f(z)| = |z| or |f'(0)| = 1, then f(z) = az with |a| = 1. This gives the hypothesis of the open unit disk centred on origin, and holomoprhic map where f(0) = 0, |f(z)| is less than or equal to 1.

Spin group: Lie group whose manifold is double cover of special orthogonal group, for short exact sequennce 1 -> Z/2 -> Spin(n) -> SO(n) -> 1. Group law by lifting multiplication of special orthogonal group. Represents symmetries of fermions. Complexification describes electrically charged fermions or electrons. Strictly, works only on fermions in zero dimensional space, fix this with pseudo-Riemannian manifolds.

Diagram chasing as linear algebra (Daniel Litt on Math Overflow): ASSUMING category of finite dimensional vector space, diagram is finite acyclic, (1) triangulate all composition of arrows, spam kernels and cokernels until terminates; (2) tabulate all exact paths or infinite long exact sequences, all but finitely many objects are zero, (3) can write the equation of the exact path sum (-1) dim A_i = 0, then solve linear system for dim Ai, telling you about surjectivity and injectivity. See also Gelfand and Manin Methods of Homological Algebra, Section II.5. The E construction in the exercise or MacLane's members.

Common diagram chasing lemma: salamander lemma is the basic, then you have the 3 by 3 then n by n lemma, then four lemma to five lemma, and the snake lemma which generalises to the connecting homomorphism. Lastly, there is the braid lemma.

Open mapping theorem: nonconstant holomorphic functions map open sets to open sets. If |f| obtains locally maximum at z and nonconstant, take sufficiently small neighbourhood and the image, this cannot be open by open mapping theorem, so |f| is constant, therefore proving the maximum modulus principle.

Maximum modulus principle in heat equation: log |f(z)| of heat equation is harmonic, it is the steady state on region D, if STRICT maximum obtained of D, heat at this maximum will disperse to nearby point, contradicting that this is steady state.

Maximum modulus principle: if f is holomorphic, complex differentiable at each point in its complex domain, modulus |f| cannot obtain strict maximum that is strictly within the domain of f.

Compact topological group: topological group whose topology can be realised as a compact topological space, element of group operated on, result is within that group. Examples: circle groups, orthogonal group of rotations, unitary groups, torus groups.

Immersion of linear maps: maps whose derivative everywhere is injective as a linear map (locally). In topology, you do not require it to be homemorphic to its image. Embedding requires injectivity and continuity, X and f(X) to have same topological properties. Example: immersion is mapping circle to figure 8, or double circle onto circle or semiopen interval to circle, inverse map is not continuous.

Immersion: tangent spaces are mapped injectively. Example: Klein bottle, any point of intersection has two distinct tangent planes, map is injective onto R^3. But Klein bottle cannot be embedded in R^3. Best thought of as a local embedding.

Jaffard ring: ring such that poly ring R[T1, ... T_n] = n + dim R, so dim of variables + dim of ring itself is equal to dim of poly ring (NOTE: using Krull dimension, Noetherian chain definition)

Embeddings in concrete categories: since concrete categories have underlying set, you can just use injective functions on underlying set to define embeddings for concrete categories. However, general definition of embedding does not exist yet. The dual of embedding is a quotient, this makes sense if you think about algebraic geometry.

Embedding as topological invariant: a (topological) space is different from another if one object can be embedded in the space, and the other cannot.

Embedding in topology: homeomorphism onto its image, or injective continuous map f: X -> Y, if f is homeomorphism (preserving topological structure) between X and f(X), where f(X) inherits subspace topology of Y. 

Locally injective / locally embedding at point: consider neighbourhood and the point as the domain for the injection as a restriction of a function. Similarly, restriction of an embedding to the neighbourhood of the point. Note: generalises say for topological embeddings, smooth embeddings, isometric embedding in Riemannian geometry, field embeddings using ring homemorphisms and instead of neighbourhoods you use ideals.

Morphism in category theory as structure preserving map: since it is still in the same category, therefore morphisms in category is a structure preserving map.

Laurent series of complex f(z) about point c: generalises Taylor's series with positive and negative dimension. f(z) can be represented as sum of a_n (z - c)^n from negative infinity to positive infinity. Coefficients a_n is path integral f(z) / (z-c)^n+1 divided by 2 pi i.

Complemntary: variables in primal problem is complementary to constraints in dual problem. There cannot be a slack in both a constraint and the corresponding dual variable. Result from duality of linear programming problem. Intuition: benefit problem is dual to cost problem.

Centraliser of a subset S in a group G: set of elements in G that commute with every element in the subset S. Motivation is also very good, you can apply techniques of commutativity to a group that is noncommutative. Obviously, a subgroup of G by definition. This motivates the name commutant.

Normaliser of a subset S in a group G: set of elements in G that is fixed under conjugation.

Rolle's theorem: real differentiable function with two equal values at two distinct point must have one point bin between them a stationary point.

Galois conjugate: element of a separable closure L of a field K, which are in the orbit of x under the group action of the absolute Galois group G_K on L.

Landau's function: maximum order of element in symmetric group. Or least common multiple of all partitions of number 1 to n. Example of the order of an element in a group.

Abelian group and conjugacy: an abelian group is group where every element is self conjugate example: a = gag^{-1} or ga = ag, this gives the reason why abelian is so important.

Group conjugate and linear algebra: conjugate is b = gag^{-1}, this is used all the time in linear algebra by the way since if inverse equals to conjugate transpose, b is unitarily similar to a, g is group action.

Conjugacy relation: equivalence relation of conjugacy classes. Example: invertible matrices form general linear group, matrix similarity is conjugacy relation. Unitary matrices for unitary group, unitary similarity is conjugacy relation.

Conjugate: element a, b, g in group such that b is conjugate of a means b = gag^-1.

Conjugacy classes, equivalence of conjugates form an equivalence class that is reflexive, symmetric, and transitive, so this is a conjugacy class.

Class functions: functions that are constant for members in same conjugacy classes.

Character: complex valued function on the group, for vector space V as a representation of group G we have x(g) = Tr(g|v) for elements g in a group. Characters are preserved by group conjugation, we have x(g) = x(hgh^-1). Further, x(1) = dim V. Direct sums give addition of character (characters are like dimensions, so is sum of eigenvalues), tensor products give multiplication of characters (product of eigenvalues), duality of vector spaces gives conjugation of characters (eigenvalues are n-th roots of unity, n the order of the element g), exterior powers of characters i.e. x_(Ext^2 V)(g) = 0.5(x_V(g)^2 - x_V(g^2)) (given by sum of products of eigenvalues apply binomial theorem), symmetric powers of characters, the x_(Sym^2 V)(g) = 0.5(x_V(g)^2 + x_V(g^2)) from comptability of symmetric power and exterior power decomposition of the tensor product.

Residue field of local ring: local ring has one maximal ideal, so the residue field is unique for a local ring.

Residue field: quotient ring of a commutative ring and a maximal ideal.

Reduced commutative ring: commutative ring with no nonzero nilpotents. Meaning: equivalently nilradical is zero.

Nilradical of a commutative ring: ideal of nilpotent elements. Radical of zero ideal. Sum of two nilpotents is nilpotent (binomial theorem), product of two nilpotents is nilpotent (commutative!). 

Localisation: adjoining quotients to the ring defined by (x,s) related to (y,t) for (xt - ys)u = 0. Satisfying (x/s + y/t) = (xt + ys)/st, and x/s * y/t = xy/st. See Borcherd's video for two step proof, I forgot about it. It basically corresponds to zooming in on a variety. Need multiplicative subset S. Example: R integers, S to be nonzero integers (multiplicative subsets), you have R[S^-1] to be rational. Another example, R integers, S to be even integers, get localisation to be Z/2, therefore looks like localisation of a spectrum zooming in points other than (2) in Spec(Z).Another example, pick R = C[x], S all nonzero elements, then R[S^-1] is rational functions. pick S = {x} instead then R[S^-1] is Laurent polys.

Localisation with copying construction from rationals, only for case with no zero divisors: for ring R, S multiplicative subset, mostly harmeless. Construction of Q from Z, consider pair r/s. But 4/2 = 2/1, so need equivalence relation. For addition, need r1s2 + r2s1 / s1s2, need multiplicative subset, then r -> r/1 has one subset. Check equivalence relation, operations defined, ring axioms. ONE SUBTLE POINT, checking transitivity of equivalence relation, r1/s1 equivalent to r2/s2 and r2/s2 equivalent to r3/s3, so you get r1s2s3 = r2s1s3 = r3s2s1, implying r1/s1 = r3/s3 ASSUMING s2 is not zero divisor i.e. divides zero. Injectivity R to its localisation also uses the fact that there are no zero divisors. Motivates s(r1s2 - r2s1) = 0 as equivalence relation. 

Zero divisor: nonzero element b such that ab = 0 for any a in ring. Double sided, of course you can have left and right zero divisors.

Localisation relation to linear algebra: construction by R[t1, t2, ...] quotient out by (s1t1 -1, s2t2 - 1, ...) as ideals. Furthermore, this makes it such that elements of (sx tx - 1) or in linear algebra (A - e I)^n for eigenvalue e, linear transformation n as action of nilpotent over subspace.

Nilradical is intersection of all minimal prime ideals: proof for commutative ring A, all ideals contains zero, all prime ideals contain prime nilpotent r^n = 0, every prime ideal contains nilradical. Conversely and equivalently (Brandenburg), assume an comm. ring element a is not nilpotent, show there exists prime ideal does not contain this non-nilpotent element (is enough to show inequality), then localisation of ring A at element a is nonzero (if not then 1/1 = 0, then a^n 1 = 0, then a^n nilpotent which is untrue). Since the localisation is nonzero, it has a prime ideal p (unique maximal element, Zorn's is used here), the preimage in A is a prime not containing element a, since a is non-nilpotent and p is a prime ideal and should not contain invertible elements, so eleemnt a is not contained in the intersection of all prime ideals.

Unitary: inverse equals conjugate transpose for matrix.

Nilpotency: collapse dimensions to lose all informations. All linear transformation is an action of nilpotent over subspace. This connects group theory, to linear algebra.

Generalised eigenvector: (A - e I)^k w = 0, A matrix/linear transform, e eigenvalue, I identity matrix, k integer, x vector. Then we have (A - e I)^(k - 1) x = v, v is eigenvector. This gives all linear transformations as some action of a nilpotent (A - e I) over some subspace x.

Linear transformation: function of vector space such that f(ax + by) = a f(x) + b f(y). In linear algebra, x and y are elements of vector space, but this definition is an indirection and can be generalised.

Functional analysis no-eigenvalue example: S(a1, a2, ...) = (0, a1, a2, ...), Sx = ax, suppose eigenvalue a nonzero, BUT limit of product of a is nilpotent i.e. a^n x, n tends towards infinity. But a is nonzero! So x must be zero.

Wiener process: Gaussian process, with funny covariance function K(s,t) = min(s,t) as random series. Markov process with generator as Laplace operator, and transition density as heat kernel.

Conditional probability: ratio of probability of A and B over probability of B. Intuition, given B, you can divide by the probability of B since you know B will happen, to raise the likelihood of A and B (less or equally likely) to A given B (more or equally likely).

Poisson random variable: it is like a memoryless queue, probability is (expected value ^ time)/(time factorial) * damping exp(-expected value), since the expected value being achieved means the effect of the queue is damped somehow. The mean and the variance is the expected value. Limit of Binomial process as the number of bins is infinite and the probability gets to zero, by simple substitution. Intuitively, this makes sense, you have an infinitely small time slice of something showing up in the queue to consider as a Poisson if you think of it is as Binomial. Proof, substitute np = lambda, then take k fixed, n >> k.∂

Characteristic function of a random variable: expectation of the damping e^{i zeta X} or the integral of the damping e^(i zeta x) aka the Fourier transform of the probability distribution. Apply Fourier theory to probability theory.

Independent random variable: preserved under products of random variable.

Curry-apply adjunction: equivalent to tensor hom adjunction. Apply is hom, currying is tensor product. Example: in Lisp (apply #’ + (list 1 2)) looks like hom from + to list. See Wikipedia.

Apply: space of exp object Y^X given Y compact open topology, X is locally compact Hausdorff. Needed for homotopy to be continuous paths in space of functions.

Mean value theorem: secant through endpoints, you can find tangent that is parallel to that. Feels like extreme value theorem but for first derivative?

Eigenspace: eigenvectors set of eigenvalue + zero vector. 

Indirection: keep the name, change the object. Example, website name, IP address, keep the website name, change the address. Indirection lets you choose the reference to be invariant, not the object. Better definition: indirection is the contravariant functor to covariant naming. Name network addresses with human readable addresses. INDIRECTION from human readable addresses to network addresses. Indirection is left adjoint to naming which is right adjoint.

Bernoulli source, hamming distortion: probability from 0 to 1/2, Hamming loss is H(p) - H(D) for prescribed distortion less than the probability (so there is loss), and zero if the prescribed distortion is larger than the distortion. This is proven by (1) considering that the rate distortion function is the minimum of the mutual information between the input X and output X^, then simply calculate the joint pmt of the two that satisfies where H(X + X^) = H(D).

Prescribed distortion: D as the upper bound for the limit supremum of the expectation of Hamming indicator loss between input X^n and output X^n.

Reliability function: probability of error decays exponentially with the code length, the minimal error exponent

Achievable rate: sequence of (2^nR, n) code such that probability of error tends to zero as the code is large. NOTE: it is insufficient to define it as argmin_R of the average of probability of error.

Binary symmetric channel, crossover: channel capacity using Shannon theorem gives max I(X;Y) = max H(Y) - H(X + Z|X), Z is Bernoulli p noise. This is max H(Y) - H(Z) = 1 - H(p), where p is probability of noise.

Binary symmetric channel, erasure probability p: this is just H(X) - p(H(X)) = 1 - p. Entropy is 1.

Probability of error: sum of conditional probability of error averaged over upper bound of throughput ceil(nR), n is length, R is rate. For an individual symbol: this is lambda(C) = P(M^ != m | M = m). It just means the probability the message is not realised given the alphabet. Average probability of error is just take the average over 2^ceil(nR)

Memoryless channel: ergodicity property over length n, with message M, input X^n, time i in [1:n], p(y_i | x_i) = p(y_i | x^I, y^I-1, m). Basically, x^I is input at the same time, y^i-1 was the output at the previous time, and m is the message. Memoryless channel, in El. Gamal in its most relaxed form, means that the conditional properly is dependent only on the message, input on time, output at previous time.

Discrete stationary memoryless channel: finite input set X, finite output set Y, conditional probability mass functions p(y|x) on Y. Instant transmission. Classical example is binary channel.

Discrete stationary memoryless SOURCE: alphabet X, probability mass function p(x).

Optimal lossless compression: infimum of all achievable rate. For a discrete stationary memoryless source, this is the entropy. Achievability uses typical sequences and encoding. Converse uses Fano's.

Hamming distortion: indicator function for error.

Max. differential entropy under average power constraint: achieved when X is normally distributed. The maximum of differential entropy h(X) when E(X^2). Is less than or equal to P is given by 0.5 log (2 pi e P), where P is power and is sigma squared. Therefore, for any X following pdf f(x) we have h(X) = h(X - E(X)) is less than or equal to 0.5 log (2 pi e Var(X)).

Power constraint of Gaussian channel: block length n then expected sum of square of random variables E(sum Xi^2) / n is less than or equal to P. Note that this is very similar to a kinetic energy term, dividing by n gives some sort of power since alphabet n is index of sequence, alphabet, or support. Hence the name, power constraint for a Gaussian channel. This is 0.5 log (2 pi e sigma^2), start with KL-divergence differential entropy D(f || phi) definition, get -h(X) and expectation of log(1/phi X), where phi X = e^{-X^2/2}/root(2 pi). This will give -h(X) + 0.5 log 2 pi + 0.5 log E(X^2) <= 0 for no KL divergence giving the constraint.

Capacity of Gaussian channel under power constraint: by power constraint of differential entropy, we have 0.5 log (2 pi e(P + sigma^2))- 0.5 log (2 pi e sigma^2) as the mutual information from h(Xg + Z) - h(Z) where Z is H(Y|X) for channel Y output Yi = Xi + Zi for input X, Zi independent of X. The subtraction of log simplifies to a quotient 0.5 log(1 + P^2/sigma^2).

Turing machine: finite control and single tape and pointer with symbols 0,1,B, B for blank

Bayesian reasoning: P(D|H) P(H) = P(H|D) P(D) or posterior * marginal = likelihood * prior. This is Wittgenstein ruler form. One can replace P(H) with sum of P(Xi) P(H | Xi) or sum of marginals, and still derive multivariate Bayes’ rule

Minimum description length from Bayesian reasoning: consider argmax P(D|H) P(H), take bit log and argmin of negative so argmin E(D|H) + E(H). Gives the minimum description length principle.

Chaitin constant: probability that computer halts when input p is a binary string drawn according to Bernoulli(1/2) process. Or sum of reciprocals of alphabet size of any program p that halts. Not computable, since no finite mechanical way to solve halting problem.

Slepian-Wolf code: correlated sources X, Y can be described at rates RX, RY, recovered with arbitrarily low probability if RX more than or equal to conditional entropy X given Y, RY more than or equal to conditional entropy Y given X and RX + RY more than or equal to joint entropy H(X, Y)

Chaitin constant philosopher's stone: list all programs in binary, supposed you have n bit of Chaitin constant, difference between full Chaitin's and truncated Chaitin's is less than probability of cardinality n (reciprocal of alphabet of n characters). Contributions in reciprocal of program length size is also less than that of reciprocal of alphabet of n characters. So, no program of length n that has yet to halt will half. Run increasingly longer lists of programs to keep track which one halts, find proofs to any yes/no theorems in less than n bits with 2^n characters of Chaitin's constant. Example: program that halts with counter-example to Fermat's last theorem. Program has finite bits N, so with 2^N bits of Chaitin's constant, can determining Fermat's last theorem. WARNING: Godel incompleteness still not bypassed since one cannot find effective procedures.

Kraft inequality: instantaneous codes iff sum of alphabet length raised to the string length for each strength is less than or equal to 1.

McMillan inequality: uniquely decodable codes iff sum of alphabet length raised to the string length for each strength is less than or equal to 1.

Effective alphabet size: 2^{nH(X)}, X discrete.

Effective support set size: 2^{nh(X)}, X continuous.

Effective channel capacity alphabet size: 2^{C}

Nats: replace 2 with e, same laws hold.

Rate distortion theory: relax constraint on lower bound of entropy for compression, find channel capacity to receive signal with acceptable distortion

Channel capacity: maximum mutual information between input and output given a probability transition matrix p(x) gives number of distinguishable inputs (not definition, but is Shannon's channel coding theorem). Alternatively, supremum of all achievable rates of a discrete memoryless channel. Examples: binary symmetric channel has capacity 1 - entropy. Note, one can set a constraint where the sum of the codebook is less than nB.

Channel coding theorem proof: random coding, joint typicality decoding. Weak converse requires Fano's inequality.

Jointly typical sequences: tuples of x y with joint distribution p(x,y) such that the difference between the entropy definition as negative expectation of logarithm for p(x), p(y) and p(x,y) are arbitrarily small (converges in probability).

Feedback capacity: feedback does not increase capacity for discrete memoryless channels.

Source-channel theorem: stochastic process with entropy rate H cannot be sent reliably over discreteness memoryless channel of entropy H more than channel capacity C.

Channel coding theorem: all rates below channel capacity are achievable, using random codes (2^(nR), n) codes, with rate R, n cardinality.

Mutual information: expected value of logarithm of covariate probability ratio p(x,y) / p(x) p(y).

Entropy: negative expectation of the logarithm of a probability distribution. This is concave. This is the average distribution length or the expectation of the ideal word length.

Ideal word length: negative of logarithm of probability distribution.

Estimated probability distribution of average distribution length: sum of entropy of distribution and the joint entropy / KL divergence of the probability distribution and its estimator.

Average redundancy: difference between expected actual word length and entropy.

Joint entropy (KL divergence): negative expectation of logarithm of a joint probability distribution. Different from Shannon's definition. This is convex.

AEP for ergodic sequence: 2^(nH) typical sequence, with probability 2^(-nH) uniform.

Entropy chain rule: the joint entropy is the sum of the unconditional entropy of X and the entropy of Y conditioned on X.

AEP for large deviations: probability of set is 2^(nD), D relative entropy between closest element and true distribution.

AEP: the logarithm of jointly independent and identically distributed random variables divided by sequence cardinality converges to the entropy in probability for sequence that is stationary ergodic.

Typical set: sequences that are between the probability of a set 2^(- card(X) H(X)) up to probability error 2^(- card(X) epsilon). This definitions lets you get high probability for cardinality large of set.

Markov chain thermodynamics: relative entropy to stationary distribution decreases with time. Entropy increases IF stationary distribution is uniform. Conditional entropy H(Xn | X1) increases with time of stationary Markov chain. Conditional entropy of initial condition H(X0 | Xn) increases for any Markov chain.

Entropy rate of joints for alphabet: limit of joint distribution of random variables divided by cardinality as cardinality of Markov chain approaches infinity.

Entropy rate of conditionals for alphabet: limit of conditional distribution of Markov chain terminal random variable against adjacent random variables as the cardinality of the Markov chain approaches infinity.

Stationary stochastic process: entropy rate of joints and conditionals are equal.

Conditioning: condition entropy is less than or equal to unconditional entropy

Log sum inequality: Jensen's using finite summations, only for non-negative inequality.

Relative entropy: sum of product between probability and log of prob. distribution ratio. Also, the expectation of the log of distribution ratio with respect to p(x)

Jensen's inequality: for convex f, expectation of payoff is more than payoff of expected frequency. Payoff space is better than probability space. Trick: use - concave to get convex. Proof sketch: draw slant line passing through y = x^2. Recall, convexity is lines segment lieing within the set. See triangle inequality, and see convexity as some geometric stuff. We have f(tx + (1-t)y) <= t f(x) + (1-t) f(y).

Jensen's gap: difference between the decomposed convex combination and the composed convex combination.
 
Information inequality: joint entropy (KL divergence) is nonnegative. Similarly, mutual information is nonnegative.

Zero joint entropy: occurs when distributions are the same.

Zero mutual information: occurs when distributions are independent.

Data processing inequality: if X to Y to Z is Markov chain, then mutual information I(X,Y) is more than or equal to I(X,Z). Proof I(X, Z|Y) is zero by definition of Markov chain.

Sufficient statistic: consider n -> X -> T(X) Markov chain, T(X) statistic, X random variable, n is indexing. Data processing inequality gives mutual information between indices and random variable - mutual information of indices and statistic to be nonnegative. Definition: this difference is equal to zero if T is a sufficient statistic. Example: number of tails is sufficient statistic to recover Bernoulli variable. Example: max and min values is sufficient statistic for uniform distribution.

Minimal sufficient statistic: if it forms “contravariant” Markov chain n -> T(X) -> U(X) -> X for any other sufficient statistic U. Alternatively, it has the same Kolmogorov complexity as the indices n, or it maximally compresses the indices n.

Fano's inequality: consider Markov chain of input X to output Y to correlated reconstruction X*, then let the error probability be probability that X*(Y) is not equal to X. Then Fano's inequality states that the sum of entropy of the error probability and the error probability times the logarithm of the (alphabet/support- 1) is more than or equal to the conditional entropy X given Y. Intuitively, entropy of error probability is uncertainty with correct predictions, the logarithm of the (alphabet/support -1) refers to the entropy of uniform distribution of all incorrect choice. Therefore, H(X|Y) is less than or equal to Hb(e) + Pe(X) log(card(X)-1), Hb(e) is binary entropy of Pe(X != X*)

Independent and identically distributed inequality, if X and Y are independent and identically distribution, the probability that they are equal is more than 2^{-H(X)}.

Markov chain: X, Y, Z forms Markov chain if X and Z are conditionally independent given Y or I(X, Z|Y) = 0 or Z depends only on Y, conditionally independent of X.

Hypothesis testing distance: relative entropy between hypothesis is exponent in error probability of hypothesis test.

Randomly generated code: Shannon used it to have achievable rate with arbitrarily low probability of error.

Prefix complexity K(x): use conditional Kolmogorov complexity, but programs and data must be self-delimiting. This is called K(x) since not having self-delimitation is annoying and disables some inequalities.

Kolmogorov complexity C(x): not to be confused with prefix complexity K(x); fixing an additively optimal partial computable function phi, it is the conditional Kolmogorov complexity C(x | epsilon). Epsilon is natural number on auxiliary tape.

Conditional Kolmogorov complexity C(x|y): minimum cardinality min(l(p)) such that an additively optimal partial computable function phi(<y, p>) for natural y and program p gives data x. If the program does not exist, then this is infinite. If the program is self-delimiting, then this is K(x|y). WARNING: the definition is subtle, since the program must halts without reading the next symbol after p, it does not need to calculate since it is conditioned on y. See Example 3.1.2. page 206 of Li and Vitanyi.

Computability theory: needed rigour to get quantitative bounds on Kolmogorov complexity. Motivates universal semicomputable semimeasures and stuff

Additive optimality: goal is to have unique minimal element (avoid nonsense with axiom of choice), defined by ensuring existence of functions with greater Kolmogorov complexity up to constant for any Kolmogorov complexity of function i.e. Cg(x) + c_f,g >= Cf(x)

Turing's thesis: effective procedure defined by Turing machine

Church's thesis: objective notion of effective procedure or computability independent of choice of Turing machine.

Partially computable functions: functions that can be computed numerically and algorithmically. Church's thesis guarantees the existence of this definition or equivalence of categories.

Laplace's MDL argument: chance of generating x literarily is 2^{-card(x)), chance of computer program generating x is 2^{-K(x)} (also works as definition of Kolmogorov complexity), probability of program comparison to random process is 2^{-K(x) -(-n)}.

Universal lower semicomputable continuous semimeasure complexity (KM): the logarithm of the reciprocal of the universal lower semicomputable continuous semimeasure M.

Universal lower semicomputable continuous semimeasure: the goal of this is to have a measure that gives an a priori probability

Universal: a lower semicomputable function is universal if enumeration exists.

Universal distribution: the idea is to instead of finding some sort of algorithm that maximises ignorance, you pick some sort of distribution that maximises ignorance.

Kolmogorov structure function / ML estimator: the minimal of maximal data-to-model code length log card(S) for model S.

Simplicity of model: Kolmogorov complexity of model K(S)

Exception MDL: minimise sum of description length K(H) and exception list K(E|H), E is error from between data D and data DH from hypothesis classification, compare this to the data processing inequality K(D|H) + K(H) >= K(D)

Max. Entropy: knowledge of constraints gives bounds that maximise entropy.

Maximum likelihood: pick hypothesis maximising probability of data conditioned on hypothesis. Special case of minimum description length

Probably approximately correct learning: the sum of probabilities of cases where concept in binary exemplified concept class is not equal to halted output concept can be made arbitrarily small by an algorithm. This is also the definition of an Occam algorithm. Predictive power of test set.

Pac-learning and compression relationship?

Asymmetric complexity (minimum description length): minimum sum of encoding and encoded data. Random string: zero encoding, compressibility = data.  Or min K(H) + K(D|H)

Symmetric complexity or Wittgenstein ruler: K(D,H) = K(H) + K(D) + K(K(H), D|H) + K(K(D), H|D). Need double dual to work correctly.

c-incompressibility: the Kolmogorov complexity of a c-incompressible string is at least the length of the string minus c character.

c-compressible: the Kolmogorov complexity of a c-compressible string is at most the length of the string -c characters.

Kolmogorov complexity alternate definition: the complexity K such that the string is both K compressible and K incompressible.

Incompressibility lemma: since there are sum from index 0 to log[card(A)]- c -1 programs is 2^(log [card(A)] - c - 1)so there are at least  card(A) 2^(-c-1) c-incompressible

Disjunctive normal forms (“DNF”): OR of ANDs

Concepts: measurable functions in set {0, 1}, concept class, functions on examples giving binary exemplar.

Occam learning: objective, short data representation. Pac learning implies Occam's not the converse (for some concept classes).

Occam algorithm: poly time, where complexity of hypothesis is at most complexity smallest concept ^ payoff exponent * number of examples ^ probability exponent. Pac-learnable if Occam algorithm exists. Number of hypothesis r is such that at most log r of Occam hypothesis complexity.

Landauer bound: 1 bit erases dissipates 10^-12 heat.

Simple Kolmogorov difference: work to transform strings most efficiently.

Instance complexity: minimal length asserting membership of instance. Describes complexity of individual.

Age of string x: minimum of product of random string 2^l(p) by steps t, where universal monotonic machine U on program p U(p) = x. Expected time for constant size probabilistic program to generate string by coin flips.

Levin Kt complexity: log of age. Or, the sum of program length and log of steps taken till x is printed.

Borel-Cantenelli: sum of probabilities Pk of Bernoulli trial Ak converges, only finitely events (with finitely many trials) occur certainly; also for mutually independent Ak, then if sum of probabilities Pk diverges, infinitely Ak certainly.

Logical depth of string x, least steps d for universal monotonic machine U computes x using b-incompressible program p at most d steps and halts.

Example of derivation: consider multivariable polynomial ring, there is a derivation for each nth variable called the partial derivative.

n-ary operation: suppose U is forgetful from commutative R- algebra to set, then it is an operation such that U^n to U. This is quite a whacko thing to define polynomials.

Dual graph: points are faces, faces are points of the graph. Draw points at each face (including outside edge), draw lines passing through each edge

Noetherian: condition so you can do induction over ideals. The ascending chain condition.

Base change: pullback over morphism of fields

Z[x] is not a PID. Example (x) and (x, 7) are prime ideals, contradiction derived as (x) = (p) since (x,7) = (p) assuming PID

Lie group: group that is also a differentiable manifold. Group multiplication and inverses are differentiable.

Manifold: locally similar to a vector space.

Classification of compact, connected, simply connected Lie group: product of finitely many, compact symplectic group, special unitary group, and spin group, or 5 exceptional groups?

Compact topological group: topology realised as a compact topological space. Like some sort of finite group with discrete topology. Example: unitary group, special unitary group, circle of center 0, radius 1 (symmetries everywhere). All symmetry lines pass through the two elements. Draw STRAIGHT line at center intersecting two points. Defines

Derivative of complex variable: same definition as that of a real variable. Quotient of infinitesimals taken as a limit.

Holomorphic function: complex differentiable complex variable at each point in complex domain.

Infinitely differentiable locally. Differentiable one, then differentiable twice. These are regular functions!

Analytic function: locally equal to its own Taylor series. General for convergent power series at each point for the domain. Some conflate holomorphic and analytic functions.

Unipotent: element r such that (r-1)^n is nilpotent some integer n. Feels like eigenvalue problem where (A - e I)^n, A linear transformation, then this is just generalised eigenvector.

Unipotent matrix: characteristic polynomial P(t) is power of t-1. Proof of definition: all roots are equal to 1. (t-1)^n = 0. All eigenvalues is one. Eigenvalues are roots.

Quasiunipotent: some power (r-1)^n is Unipotent. Classical example, diagonalisable matrix whose elements are roots of unity.

Principal ideal domain: a domain which all ideals are principal.

Principal ideals: ideals generated by one element

Field of fractions: defined like field extension, smallest field in which an integral domain can be embedded. Prototype: field of fractions of integers is rationals.  Example: field of fractions of half line operators yields operators, Dirac delta, differential and integral operator

Localisation of ring: generalisation of field of fractions, but with arbitrary commutative ring.

Subgroup: subset with the same group operation

Proper subgroup: proper subset, same group operation. Operation is Unital associative invertible magma

Embedding definitions: defined by how it can be embedded in a bigger objects: example, field of fractions of integral domain that can be embedded in a smallest field

Integral domain: nonzero comm ring, product of two nonzero elements is nonzero (no nilpotents, idempotents are OK)

Linear model: Schrodinger's coloured cat pill test: (1) relationship is linear (regressor, relationship, non-varying in time), (2) error expectation is zero, (3) error has constant variance, no autocorrelation, (4) observations do not affect the experiment (Schrodinger's come in), (5) bad case of number of observations + extra independent variables > number of independent variables assumed. See book by Peter Kennedy on this

Sigma-algebra: motivation is probability, closed under complements, countable unions and intersections. Complements because of not event, closure of countable unions and intersections because of Stone duality, corresponding to probability of countably infinitely many events (ergodicity without killing rate) being decidable in logic. If you take sigma-semiring, this can be used in ergodic analysis in my opinion.

Algebras are closed under finite unions and intersections, need not be closed under countably many, see example take Boolean algebra, infinite negation corresponds to Grandi series, truth is not decidable, then apply Stone duality, corresponds to Grandi series -1 + 1 - 1 + 1 - 1…

Compactness: every open cover admits finite sub cover. WARNING: single cover of X is finite, so insufficient for definition. A set that is closed and totally bounded (corresponding to not admitting rotations about infinitely many axes) is compact. Rotations also cause Banach Tarski paradox.

Hahn decomposition: Measure space X under signed measure can be decomposed into disjoint union of positive and negative sets P and N, up to differences in sets of measure zero. Proof: assume measure v cannot take -infty as a value, otherwise take -v without loss of generality. v(Pj) tends to supremum m, however a measure is continuous from above. Consider countable collections of Pj. By an additional lemma, countable unions of positive sets are positive, therefore P is positive. Take N = X - P. Assume nonnegative for contradiction. Note, if we have non null set E inside N, we can take union of P and E and take its measure and it exceeds supremum. Contradiction. Secondly, for A in N v(A) > 0, if B subset of A then v(B) = v(A) + k, k real number. Now for construction, consider collections of nj such that v(Aj+1) = v(Aj) + 1/nj for lowest integer n1, inductively define. Consider countably many intersections of this Aj collection, gives nj tends to infinity. Yet, the rule still applies due to point number 2, so there exist a n > nj even though nj tends to infinity. Contradiction in constructability. See stack exchange or Folland for full proof I am not sure about the last step.

Jordan decomposition: v = v+ - v-, which says a signed measure can be constructed from two positive measures called the positive and negative variations. Proof: take v+(E) = v(E intersect P) and v-(E) = -v(E intersect N), this is possible by Hahn decomposition. Note that these variations are mutually singular i.e. there exists E, F in M such that E, F disjoint, E union F whole space, v+(E) measure 0, v-(F) measure 0. Prototypical example are the positive and negative real axis with minimum 0.

Caratheodory definition of integral: define outer measure, measure m(S) = m(S intersect A) + m(S intersect Ac) are family of countable sets, forming sigma algebra. Intuition is from Lebesgue measure, outer measure = inner measure.

Radon-Nikodym idea: pick nu, sigma-finite signed measure, mu sigma-finite positive measure, then there exists two unique measure lambda and rho such that lambda and rho are mutually singular, rho << mu (what does this mean?) and nu = sigma + rho. Example, pick mu = Lebesgue measure, pick measure space as real n-dim vector space with open balls, can define point wise derivative if nu.

isProp is the dependent product of the identity types of all pairs of elements in type. We say type A is a (-1)-truncated type or a h-proposition if isProp is an inhibited type, or there is a path between pairs of points for all pairs of points in the space of sections. https://ncatlab.org/nlab/show/mere+proposition there are several provable equivalent ways about thinking.

Higher inductive type on X: A maps to F(A), group operation, unital invertible associative magma with identify and inverses.

Reflexive: space of sections of fibrations on same point. If there exists a proof a, then proof a is the same as proof a.

Symmetric: space of sections of fibrations (a,b) transported over function space to fibrations (b,a). If there exists proof a and proof b being the same, then proof b and proof a are the same.

Transitivity: space of sections of product space of fibrations (a,b) (b/c) can be moved to a(c) via a function space. There exist a predicate with if proof a is the same as proof b, and proof b is the same as proof c, so proof a is the same as proof c.

Intervals: generated by points of type segments and a path of type 0_I = 1_I. Recursion principle looks basically the same.

Circles: is of the type of base S1 and a loop of base =\_S1 base. Note that loop is not the refl_base.

Suspension: point north meridian of type suspension, point right meridian of suspension, and function meridian from the main space in a function space to the space where N = S in the suspension.

Cell complex higher inductive type: points in torus, and points p : b = b, points q: b = b, 2 path where you have p q = q p commutative, this makes it look like some naturality square between vertices a b c d. Identifying this produces a torus

Pushouts: generated by left injection from A to disjoint sum A U B, and right injection from B to disjoint sum A U B, and for each c: C, a glue that glue lefts inverses of functions of points on left injections of c with right injections of c. Left injections and right injection map to disjoint union (colimit inutitively)

W-type: give A in universe U and function type of A to universe U, A are labels, natural numbers as W-type, it will be the type 2 inhibited by 0_2 and 1_2, either it is 0, or it is a successor. So a W type is a generalisation of lists, numbers, binary tree. So 0_2 is the initial element, 1_2 is the induction principle.

N-algebra, type with two elements over the dependent pair c0: C and cs: C -> C, with the type of the dependent sum of product type of C \* (C->C). Example: N-algebra (N, 0, such).

0-type: no inductive generators

1-type: inductively generated by constructor \* of type 1.

Coproduction: generated by left inverse and right inverse, co-product of space, unions,

Surjective: a function is surjective if all fibres of are inhibited, there exists over the codomain space B there must be an induced element over the domain space A such that we have f(a) = b and these two are inhibited.

Interesting, connectedness means that the unique function from a space A to the 1-type space 1 for all dimensions, fibres of maps are contractible. Every function is (-2) connected, up to level of propositions. (-1)-connectedness means surjectivity. This generalised higher level subjectivity. 0-connected is connected, 1-connected is simply connected. This gives the generalisation of connectivity in terms of dimension.

Contractible maps: a map is contractible if it is contractible over all the fibres of a point in the total space.

Left inverse and right inverse: these are the dependent sum over the induced map of spaces B to A such that the g f is homotopy to idA as points for left inverse, g quasi inverse, then f g is homotopy to idB in points for right inverse. A map is bi-invertible if it has a left inverse and a right inverse.

Fiber of a map: this is dependent sum such that fibres over an element x in map f is equal to y where x is of type A, y is of type B. In space, this means the total space where maps of points y are equal to points of map y. It is easy to visualise, just pick two points in space, and then the thing connecting them is the fiber of the map.

Types are object classifiers.

Function types are internal Hom.

Quasiinverse: lemma and proof, quasi inverses are equivalent to dependent types with (x = x). In space, quasi inverses are equivalent to the space of sections where points are equal to points?

Sets are one types where points for points x and y in space A, p, q are of space x = y, and r, s are points of space p = q, therefore r = s in points. Some sort of Poincare duality taking lines as space, and point as points.

Contractible type: logically it means that there exists for all proofs, proofs are identical to the proof being the center of contraction i.e. all proofs are the same. A space is contractible if there is a total space of the space of sections such that all points are equivalent to the point known as the center of contraction.

Retraction is a function space from spaces A to B such that there exists a function space from B to A known as it section, as well as a homotopy such that the compositions of function spaces on points in the space of sections exists.

Unit type is the terminal object.

Dependent pair of P(x): logically it is subset, these are defined as subtype, therefore the total space of fibrations is a

Fiberwise mapping: dependent product from P(x) to Q(x), space of sections from two fibrations,

Dependent pair type of sigma types: a type of pairs where it varies based on the second component without using currying

Recursor for magma: dependent PAIR product (note that the dependent pair product is doing a lot of heavy lifting) A to A to A. Logically, this refers to an associativity principle, where for all propositions, implications of propositions can be taken in any order for a triplet of implications. Spatially, this means that we take the coproduct of three function spaces over the same space, this can be done in any order.

Recursor for pointed magma: Same thing as a recursor of a magma but with a product type at the end.

Induction principle for co-products:

Induction over unit type: (1) skip step 1, (2) construct for function type of unit type to universe, the dependent type of a point C(\*), (3) this is the function type to the dependent type over the unit type

Induction of product types: (1) take dependent type of pairs C(x,y) over elements x in universe X and elements y over universe Y; (2) take dependent type over function types of product type from X _ Y -> U; (3) take a function type to dependent product to the element u of type X _ Y for a proposition C(u). Logically, (1) consider a pair of proofs x and y, there exist a proof x that proves propositions X and proof in propositions Y. Consider this pair of propositions for where the (2) conjunction of these two proofs imply U. (3) It is implied that the pair of proofs can be treated as a proof on its own. In spaces: (1) consider the product space of two points (x,y) formed by the space of sections over their base space X and Y. Then consider the space of sections over the function space of their base space as a product space X \* Y to some other space U; (3) one can form the function space to the product space itself which associate this pair of points to a single point.

Proof for propositional uniqueness principle

Negation: function type into empty type. See section 3.7.1 for traditional logical notation.

Law of the excluded middle: either A or not A is not valid in intuitionism. In intuitionism, either a statement is provable or cannot be provable to be false, or false. Statement p is stronger than not not p. In type theory, this corresponds to the idea that there is no function type from a type to empty type to empty type again. It fails spectacularly in set theory since it implies the De Morgans laws are not valid. In homotopy theory, it corresponds to the statement that there is no function space of the function space of a space.

LEM can be defined as the dependent product of isprop(A) -> (A or not A). It is also the space of sections of the function space of function isprop(A) to disjoint sum of space A and space not A. Logically, the interpretation is easiest, for all statements, if they are propositions then it implies that it must be either true or it is not true but not both.

Type of boolean: coproduct of two one pointed space, set of two singletons, true and false

Boolean recursor: logically this is if then else, in type theory, Pi_C C to C to 2 to C, where 2 is type of booleans, in sets this means there are function spaces from families of the same set (truth and negation) which map to either truth or false which maps to each statement. Topologically there is a space of sections of product spaces of a space as a function space that maps to the two point set for each space.

0-Recursor, Pi_0 C -> C, space of sections over the empty space is a space, any set is a family of functions on the empty set. Logically, any false statement implies any statement.

Coproduct type: defined by type of recursor of coproduct A + B, which is the union of sets, disjunction in logic, and coproduct of spaces.

Recursor of coproducts: known as case analysis. Functions of A to C to functions of B to C are functions of A+B a function of C. Logically, it means that there exists a proposition if A implies C, that implies B implies C, this implies A or B implies C. In sets, there is a family of functions with common codomain can be made into a family of functions with the same codomain using a function. Topologically, space of sections function spaces to the same space can be made into a coproduct with the same function space to the same space.

Recursor through unit type; the recursor from Pi C to 1 to C. Logically, it means there exists for proposition C that is true and implies proposition C. In sets; there exists a set with one element which is the set. Topologically, there is a space of sections whose function spaces maps it to basepoint which has a function space that maps it to the same space of sections.

Nullary type: type in universe with only one object, space with one point, proposition with only one proof, set with one element denoted by empty set, terminal object.

Swap; triple dependent product of elements over the same universe A to B to C such that it becomes B to A to C. In logic, it means that there exists a propositions A implying proposition B implying proposition C such that there is a proposition B implying A which then implies C. In sets, it means there is a family of functions such that family A is a function of family B is a family C with a function making it such that family B is a function of family A which is a function of family C. Topologically, there is a space of sections such that the function spaces of A to B to C has a function space making it function spaces from B to A to C.

Polymorphic functions over universe: functions that take types as arguments and acts on elements of that type.

Cartesian product: type constructed by the recursor of dependent type. Example: generates product space A and B from function spaces of A, B, C.

Recursor of dependent types: function of types from dependent type of functions of types A to B to C, to functions of types A \* B, to C. Logically, it is the recursion principle such that there exists a proposition A implying proposition B implying proposition C, such that implies it is propositions A and B implying C. As sets, it means that there exists a family of families of sets of functions A, B and C, such that the intersection of families A and B gives the set family C. Topologically, it means that there exists a space of sections of function spaces from A to B to C, such that the product space A and B is a function space of C.

Projections of dependent types: type of functions from the product type to one of its components with idempotence as the defining eliminator. In sets, it means there exists a two proofs (a,b) which implies one of proofs is a proof. In sets, it means there is a family of two sets and a family of functions that selects one set out of the two. In homotopy, there is a space of sections on a product space whose function space gives a space that is one of the two spaces.

Product type: left adjoint to type of functions

Eta-expansion: judgemental uniqueness principle

Classical homotopy: continuous totally ordered family of maps graded by intervals such that compositions of maps at the endpoint is idempotent.

Isbell duality: space is dual to algebra.

Types: infinity groupoid, terminal object of a global section functor for an (infinity,1) category.

Identity type: path space A^I from interval to space A.

Universe: type whose elements are types. Hierarchy of universes prevent Russell's paradox.

Univalence: isomorphic structures can be identified or there is a canonical equivalence for the function space of id applied to function space of A and B to equiv applied to function space of spaces A and B

Type of naturals: constructed using zero and successor as the induction principle.

Higher inductive types: constructions built using induction principles.

Sets: homotopy equivalent to discrete space where every connected component is contractible.

isomorphisms: Iso(A,B) are dependent pairs of over A -> B and B -> A over dependent types of g(f(x)) = x and f(g(y)). Homotopically, they refer to symmetric total spaces of function spaces with defining equations being space of sections that have judgemental equalities between the composition of functions with their inverses and the identity.

0-types: sets, proofs

1-types: propositions

Types: propositions, sets, space

Proofs: elements, points in space

Predicates, B(x), families of sets, or fibration

0-1, true false, initial and terminal objects

A \* B, disjunction, sets of pairs, product space

A -> B, B^A, implication, sets of functions, function space

Sigma types or dependent sum types, there exists, disjoint sum, total space

Pi types or dependent product type, for all, product, space of sections from total space E to base space Sigma. Cartesian product over types.

Space of sections: internal hom where codomain depends on domain and internalises indexed products. Exponentiation of two natural numbers identified with product of copies of power. Categorify this, you get space of sections. Picking terminal morphisms gets the exponential object.

First order deduction: proposition has a proof.

Propositionally equal: there exists x such that x : a =\_A b. In logic, this means there exists a proof x where proof a is proof b given proposition A. In homotopy, if there is a point x in the space a =\_A b for space A, then there is a path between points a and b in space A. Logically, it means that x is an set in the family of sets where a and b are equal elements.

Definitionally equal: there exists a variable a = b in type A. Logically, it means there exists a proof or axiom of a = b in proposition A. In sets, it means that the elements a and b are the same in set A. Topologically, it means there exists a path from a to b in space A. Compare this to propositional equality geometrically, where the space a =\_A b has paths as points.

Function type, f has a type A -> B. Logically, f is a proof that A implies B. In sets, f is in the set of functions from A to B or the exponential set B^A. In homotopy, point f is in the function space A -> B.

Hypothesis: element x has type A. Logically, x is a proof of A as a statement is a hypothesis. Set theory wise, element x is in the set A. In homotopy, point x is in space A.

Lambda-abstraction: of the form lambda (element: type)-expression. Logically, it refers to the expression that shows that x is a proof of a proposition A. Sets, it means at an expression such that an element is a member of that sets. Topologically, it means that this expression defines points to be some space.

Element to expression is of functional type. Logically, it means a proof implying an expression is an implication of propositions. Set wise, it means an element with an expression is a family of functions. Topologically it means that a function space can be defined by points to expressions as points.

Currying: apply function to a, then apply function of a to b, then get the result. Logically, it means proof an implies fa, then proving proposition fa implies b, then b is a result. Set theoretically, it means element a is in the set of functions fa, which is in the set of functions b. Topologically, it means from point a, there is a path to fa, which then there is a path to b, so there is a path from a to b.

Inductive principle for the type of functions: this means that an expression is canonically isomorphic to the lambda (element: type)-expression. Logically, it means an expression is the same thing as applying an expression of a proof with some proposition. Sets, it means a set defined by its properties is equivalent to the property itself. Topologically, it means that an expression as a space is the same as an expression defining some points on some space to be a space.

Formation rules: rules that form types:

Eliminator rules: rules that apply expressions.

Characteristic equation: take the determinant map (lambda I - A) x = 0, there is some sort of group theory since the characteristic equation is equal to the power series with alternating signs of principle minor sums, or t^n - (tr A) t^{n-1} … (-1)^A (det A).

Sum of roots and product of roots as trace and determinant. For a 2x2 matrix, trace and determinant has something to do with sum of roots, product of roots; We have x^2 - tx + d, -t is trace, d is determinant.

Similarity: B is similar to A if there exists nonsingular S such that B = S^-1 A S.

Diagonalisable: if similar to diagonal matrix, then diagonalisable.

Matrices AB commute if they are simultaneously diagonal or similar to same diagonal matrix. Proof: use similarity transform, forms abelian subgroup. Same group action on group conjugate, also abelian.

Eigenvalue equation: Ax = lambda x. Converts matrices into polynomial ring.

Unitary matrices are nonsingular, its conjugate inverse is unitary. Rows and columns are orthonormal, same Euclidean norm. Proof, all follows under closure of unitary group, and also the fact that the product of unitary matrices is 1.

Selection principle, closed bounded subset of finite dimensional vector space is compact (note that unitary matrices have a spectrum closed in complex unit disk). Group of unitary disk is compact, so there must exist a limit of subsequence. Need not be unique! Similar to {-1}^n odd and even alternating matrices as counterexample!

Unitary similarity is equivalence relation: proof is easy, identity matrix, inverses and composition of inverses exist in the group of unitary matrices, so can form equivalence relation if you use these as products.

Schur form: proof: start with orthonormal basis matrices A = [Z1 Z2] \* A [Z1 Z2] which gives [lambda I, A12, 0, A22]. The lambda I, 0 is due to the properties of the orthonormal basis matrices being unitary, don’t care about A12, but A22 is not upper triangular! Iterate. Finite dim vector space have integer dimension n, iteration at most n steps, therefore any square matrix in complex numbers is unitary similar to upper triangular matrix.

A unitary matrix is a matrix whose inverse is equal to its conjugate transpose. The product of a matrix with its inverse gives the identity matrix. A conjugate transpose of a matrix swaps the rows and columns and computes its complex conjugate component wise.

A square complex matrix A in the set of n by n matrices M_n of complex entries have eigenvalues \lambda_1, ... \lambda_n in any order. Let x in the complex n-space C^n be a unit vector such that Ax = \lambda_1 x.

There is a unitary U =  [x u_2 ... u_n] in the set of n by n matrices M_n such that U^* A U = T = [t_{ij}] is upper triangular with diagonal entries t_ii = \lambda_i from i = 1, ..., n. This is the Schur form.

The upper triangular matrix T has the diagonal entries as the eigenvalues of A, the sum of these eigenvalues as the trace of A, the product of these eigenvalues as the determinant of A, and the main diagonal entries of adj T to be the product of all eigenvalues excluding the one corresponding to the entry in the diagonal.

The Cayley-Hamilton theorem follows by factorising the characteristic polynomial and representing the matrix A by the conjugacy UTU^*. The characteristic equation of A is that of the conjugacy which is Up_A(T)U^* = U([T - \lambda_1 I][T - \lambda_2 I]...[T - \lambda_n I])U^*. One can check that p_A(T) in this form must be zero (NOT TRIVIAL, see Horn and Johnson, pp. 110).

A square complex matrix A in the set of n by n matrices M_n of complex entries have scalars \lambda_1, ... \lambda_n in the complex plane C, positive integers q and n_1, ..., n_q such that the sum n_1 + ... + n_q = n such that A = S J_A S^{-1} where the Jordan matrix J_A is the direct sum of Jordan blocks J_{n_i}(\lambda_i), where J_A = \bigoplus^{q}_{i = 1} J_{n_i}(\lambda_i).

A Jordan block is an upper triangular matrix where the the scalar \lambda_i appears n_i times on the main diagonal, if n_1 > 1 then there are k - 1 entries which are +1 in the superdiagonal, and all other entries are zero.

The number of Jordan blocks is the maximum number of linearly independent eigenvalues of J_A.

If all the Jordan blocks are 1 by 1, then J_A is diagonalisable, in fact, the diagonal matrix looks like this.

The number of Jordan blocks corresponding to a given eigenvalue is the geometric multiplicity of the eigenvalue, which is the dimension of the associated eigenspace.

The sum of the sizes of all the Jordan blocks corresponding to a given eigenvalue is its algebraic multiplicity.

Jordan block: sum of a diagonal matrix and a nilpotent matrix since J_k(\lambda) = \lambda I_k + J_k(0) and J_k(0)^k = 0.

Category theory motivates (1) generalising morphisms; (2) generalising domain/codomain duality; (3) preserve integrity respecting identification and compositional order. The fastest illustration of category theory is with Kan extensions. All categories are locally small (that is to say ignore size issues in set theory) unless otherwise stated.

A category C have domain and codomain objects ob(C) and morphisms mor(C) that respect the identity 1_C and associative composition.

A morphism is between categories is a functor F maps morphisms f from a category C to a category FC respecting composition F(f *_{F} c) -> F(f) *_{FC} F(c) and identification in both categories. One can also use the family of homs definition, used in May or Lurie.

A 2-morphism of functors is natural transformation \eta that has components \alpha_c that takes morphism c composed by a functor F to a functor G such that there is a commutative diagram between the morphism Fc and its common composite Gc' for any morphism f that takes c to c' (Gf * \alpha_c = \alpha_{c'} * Ff).

An isomorphism is a composition of two morphisms between two sets of objects whose composition and inverse identify in their respective sets of objects. Objects are isomorphic if an isomorphism between two exist between them. Objects can be grouped into a class of objects of a category if they are isomorphic. Picking the same object for the domain and codomain gives an automorphism if the morphism is isomorphism, otherwise it is endomorphisms.

A comma category F \downarrow G of two functors F: D -> C and G: E -> C has objects, triples (d, e, f), where d is a morphism in category D, e is a morphism in category E, and f which are morphisms from Fd -> Ge in category C, as well as all diagrams of this shape commuting in category C, where h: d -> d', k: e -> e' such that f' * Fh = Gk * f, for morphisms of triples (d, e, f) -> (d', e' ,f').

A left Kan extension of a functor F that takes morphisms from initial domain category C to a codomain category E along a functor K that maps morphisms from extended domain D to the same codomain category E is a functor Lan_K F that also takes morphisms from category D to category E such that there is a natural transformation \eta that takes functor F to the functorial composition of Lan_K F * K. This natural transformation \eta is defined such that any other natural transformation \gamma factors uniquely through \eta for any other functor K' that, like K, takes morphisms from category D to category E.

A right Kan extension is defined the same but the arrows of the natural transformation reversed, taking the functorial composition of Ran_K F * K to functor F from the opposite category C^op to opposite category E^op when defined in terms of the left Kan extension.

A functor is extended naturally to left composition of a left Kan extension and the functor when the domain category is extended.

A functor is extended naturally from a left composition of a right Kan extension and the functor when the domain category is extended. Easy to remember, forgetful functors are typical examples of right adjoints which are right Kan extensions.

A presheaf is a functor from an opposite category to sets. A simplicial set is presheaf from the simplicial category.

A category of presheaves has presheaf functors as objects, and natural transformations as morphisms.

Most Kan extensions define the value of an extended functor on each object (each “point”) by a weighted (co)limit. For a locally small category E, a right Kan extension is pointwise if it is preserved by all representable functors E(e, -) to the category of sets Set. Representable functors are naturally isomorphic with a representation \theta: hom_C(-,c) -> E(e, -). A left Kan extension is pointwise if its corresponding right Kan extension is pointwise.

Also, a right Kan extension of functor F from category C to category E along a functor K from category C to D is pointwise if and only if the limit lim ( d \downarrow K -> C -> E) exists and is isomorphic Ran_K F(d) for morphism d in category C. We have d \downarrow K as an indexing category. This can be shown since a pointwise extension preserves representable functors, so Yoneda's lemma applies then the Ran_K F(d) is isomorphic limit of Fpi_d: d \downarrow K -> E where a l pi_d. Dually, a left Kan extension of functor F from category C to category E along a functor K from category C to D is pointwise if and only if the colimit colim ( K \downarrow d -> C -> E ) exists and is isomorphic Lan_K F(d) for morphism d in category C.

See Emily Riehl's "Category Theory in Context" for this construction. For any small diagram F from category C to category D valued in a category with products and equalisers. There exists an equaliser diagram for monomorphisms on Fc to the product pi_{c -> x} Fx for two parallel maps to pi_{c -> x -> y} Fy. One parallel map projects to the component indexed by the composite c -> x -> y. The other parallel map projects to the component indexed by the map c -> x and then acts by F on the second map x -> y. This is the Yoneda lemma, applied to functor F from the category C to the category of sets Set for set morphisms Fc which is isomorphic to a limit formula \lim(c/C -> C -> D). This limit formula can be shown to be expressed as an equaliser. The Yoneda lemma states that these two composites are equivalent.

Yoneda's lemma implies a composition of two morphisms between two sets of objects whose composition and inverse identify in their respective sets of objects called a isomorphism. This isomorphism is canonical and unique, and is between the value of a presheaf X at a morphism c and the collection of all morphisms (hom-set) of presheaf homomorphisms from the representable presheaf y(c) to the presheaf X. This means Hom_{Set^{C^op}}(y(c), X) is isomorphic to X(c).

A left Kan extension of a functor F that takes morphisms from category C to category D along a uniqueness functor ! from a category C to the category 1 defines a natural transformation to the colimit. This left Kan extension exists if and only if the colimit exists. A right Kan extension along a uniqueness functor ! from a category C to the category 1 defines a natural transformation from the limit. This right Kan extension exists if and only if the limit exists.

A unit \eta is a natural transformation from the identity functor * to a composition of functors GF. A left Kan extension of the identity functor * along F is defined with the unit \eta as an left adjoint. Left adjoints preserves colimits. A counit \epsilon is a natural transformation from a composition of a functors GF to the identity functor *. A right Kan extension of the identity functor along G is defined with the counit \epsilon as an right adjoint. Right adjoints preserves limits.

Yoneda extension: left Kan extension along a Yoneda embedding. See definition of field extension in Galois theory, similar.

Limit of a diagram with two objects without nontrivial morphisms is a product. 

A limit of a unique empty diagram from the empty category 0 to a category C defines a terminal object of C. This can be thought of as a product. 

A limit of a pair of parallel morphisms is an equaliser. A limit over a cospan is a pullback, considering pairs of morphisms with the same co-domain. Dually, there are coproducts, initial objects, coequalisers, and pushouts for parallel pairs of morphisms with the same domain.

Monoidal structure: a unital associative magma, except the magma is a tensor product BIFUNCTOR of categories. Unital and associativity come as FUNCTORS of categories.

Box topology: generated by the base of Cartesian product of opens for opens in topology. Box comes from basis sets that look like boxes. Standard counterexample to how products do not preserve continuity unless one uses the product topology.

Product topology: box topology but all but finitely many opens in components are equal to the full component space. The product of continuous functions (morphisms) are continuous iff the components of the product are continuous.

Affine combination versus convex combination: affine combination allows negative coefficients, line between them and is compact. Convex combination of a finite set is compact.

Measurement of random variable: defined when the exponential is taken out of an expectation value, you replace the random variable with the measured value. This is deterministic.

Mapping space of CW complex has type of CW complex: need domain compactness, example mapping from universal infinite discrete space to discrete space.

Germ: for open U and functor f, take image from i(U) from sheaves of opens on top space X OU(X) to cocone C, then G(u,f) is i(U)(f)

Perfect duality, equivalence of categories from opposite category C to D consisting of dual concrete structures

Heisenberg group: non abelian, every element cubed is 1

Exactness lemma: if 0 to A to B to C to 0, if any two are exact then the third must be exact. Proof is to take long exact sequence of homology groups. Then, eventually most of them will vanish, show injection and surjection.

Eisenstein criterion, for polynomial, if there exists a prime does not divide the nth power coefficient yet it divides the rest, and prime square does not divide the zeroth term, then the polynomial is irreducible. Example: x^2 + 2, pick 2 as the prime not dividing 1, power of x^2, 0, and 4 but it divides the other term 2.

Uses of pseudometric: you have two points with 0 distance that aren’t the same. To ignore it, quotient out by identification with distance.

Duality: pairs of concepts are mirror images of one another with some involution like two points define a line and the intersection of two lines is a point up to taking projections.

Derived functors: explicit computations of homology for Tor, and cohomology for Ext via resolutions

Burnside's lemma: enumeration of orbits of symmetry group, or counts distinct objects up to a symmetry equivalence relation. For a finite group G, consider elements x^g that are fixed by g i.e. g = x = x. The formula for orbits is |X/G| = sum of elements x fixed by g divided by the group G. Example, rotationally distinct colourings of cube with three colouring. Identity fixes 3^6 colours, six 90 degree face rotations fix 3^3 \* 6 colourings, three 180 degree face rotations fix 3^3 colourings, eight 120 degree vertex rotation fix 3^2 colourings, six 180 degree edge rotations fix 3^3 colourings. Now take average over group of order 64, get 57, so there are 57 rotationally distinct colourings of a cube with 3 colours.

Fourier transforms in distribution theory: turn multiplication by x into differentiation with respect to k, derivatives of delta function.

Jaffard domain: Krull dimension of the ring of polynomials, is the Krull dimension of the ring + number of parameters of the polynomial ring. Example dim R[T1 … Tn] = dim R + n.

Lie group and Lie algebra correspondence: isomorphic Lie algebra does not imply isomorphic Lie group (example real coordinate space, and circle group). However, requires simple connectedness. Problem is there is a hole in circle group.

Schur's lemma: all ground field, irreducible representations are unique up to homomorphism, if ground field is algebraically closed endomorphisms are scalar multiples of identity operator. Endomorphism of irreducible representation, multiply by complex number? This property is also known as complete reducibility or semisimplicity. Note: over finite fields, not completely irreducible, so modular representations is very tricky.

Schur's lemma (in Fulton Harris): consider V and W irreducible representations of G, and p: V -> W is a G-module homomorphism, then either p is an isomorphism, or p = 0, and if V = W then p = e I for some complex e, and I is identity matrix. First claim, the kernel and image of the map are invariant subspaces, so p is an isomorphisms or is some vanishing map. For the second claim, since the complex numbers is algebraically closed, p as a FINITE DIMENSIONAL linear map must have an eigenvalue, so (p - eI) has nonzero kernel. By (1), (p - eI) = 0, so p = eI. Note we did use the hypothesis that V and W are finite dimensional vector spaces.

Representations: group preserving map (group homomorphism) from the group to the general linear group of vector space V which is GL(V) which is the group of automorphisms (all invertible matrices) for vector space V. The representation gives the vector space the structure of a G-module for a group G (module is like vector space for rings). 

Degree of a representation: the dimension of the vector space (finite for finite simple groups)

Lp space: space using a power p as norm instead of typical Euclidean using p = 2

Hom Tensor adjunction on vector space: Hom(V,W) is canonically isomorphic to V * tensor W.

Duality of vector space: a vector space of rulers (sort of) of a vector space. It is not canonical, one can pick an arbitrary scale.

Periodicity of functions: reducible to linear combinations of exp(2 pi it)

Quotients: f(x) = f(y) if x is equivalent to y. That is why quotients are very powerful. They are almost functions

Linearising is the easiest thing in math (example, representation theory). Next best thing is to count.

Connectedness is not hereditary, example Q does not inherit connectedness from R or even path connectedness.

Normal subgroups: invariant under conjugation or serving as the identity for a different group compared to the rest of the elements. So I have the normal subgroup, then everything else not invariant under group conjugation. So the whole group is an identity somehow. Ideals of rings are comparable to normal subgroups?

Free group as universal property (universal left adjoint): there is a canonical free group, with any function from set S to the group G giving a unique isomorphism with set S included to the alphabet Fs mapping to the group G. If non unique, relations exist.

Maximal subgroup: proper subgroup that is not contained in any other proper subgroup. Note this implies that there can be nonunique maximal proper subgroups.

Proper subgroup: subgroup that is a proper subset of the group (particularly, excludes the group itself as a proper subgroup of a group)

Construction of Non-Noetherian rings for each finite dimension: start with a Noetherian ring, adjoin infinite number of nilpotents. Or take affine line, adjoin infinite number of fat points somewhere (Gelfand duality), the corresponding ring is not Noetherian even though it is dim 1.

Gros topos: sheaf is a generalised space with descent

Cuspoidal cubic: y^2 - x^3

Proof that every vector space has a norm: every vector space has a finite linear combination of basis vectors (even if it has infinite dimensions, this uses some weird completion magic). Take max of the coefficients amongst finitely many basis vectors, this defines one possible norm. Infinite dimensional TOPOLOGICAL vector spaces don’t have a norm that indices the topology

Exponential functions are quintessential examples of holomorphic functions

Unital subring: some authors define the identity to be in subring. Note that analysts don’t like forcing an identity at all.

Injective: covariant pullback, if f(x) = f(y) then x = y.

Well defined function: covariant pushforward, if x = y, then f(x) = f(y)

Sobolev embedding: amplitude A, frequency N, support on volume V. Wk,p norm is AN^kV^-p, Apply uncertainty principle, V >= N^-d. Think of it as a trade off between regularity and interrability. These are single bump function spaces, can extend a lot further. W11(R)  =  L^infty(R1) is fundamental theorem of calculus Wd1(R)  =  L^infty(Rd) is iterated and Fubini

Using calculus to get rid of bad fractions: newton numerators of form [f(t+h) - f(t)]/h is simply the integral

Utilities problem: F - E + V =  2. Consider 2 houses to 3 utilities fully done. Need to connect one house to all three utilities. Can make at most only one face on the plane. So max faces is 3. You have 9 edges, 6 vertices, this is a max of 0 which is less than 2. Therefore, fails in plane.

Trisection angle: impossible, proof, compass and straight edge constructions obey tower law, quadratics only. Consider cos(60 degree), which is rational valued, and expressed irreducible, cubic polynomial. cos(20) therefore cannot be constructed by tower law. But 60 degrees can be constructed. So it is impossible to trisect 60 degrees.

Smooth fibrations on compact spaces are fiber bundles, example Hopf fibration not Hopf fiber bundle.

Elliptical curve over complex numbers is a Riemann surface of genus one with base point, or quotient of complex of lattice In complex, or smooth algebraic curve degree 3. Torus can be used to study complex numbers.

To get the properties of exclusive disjunction from ring sum and conjunction (or meet) from ring product given a Boolean ring, which is a ring of idempotents, apply truth table onto rings of ints modulo 2. 1 + 1 = 0, so exclusive disjunction.

Join: is union both are less than supremum in lattice. Join is supremum.

Meet: intersection is infimum, both are at least that in lattice.

Hasse diagram: diagram representing partially ordered set.

Plus construction (see Scholze lecture): A+ is the Lan(r^op) Ran(s^op) A. Step 1, apply right point wise Kan extension along the opposite of functor s^op : C -> J sending opens U on small site C to maximal sieve (set of all morphisms with codomain U). Step 2: apply left pointwise Kan extension r: J -> C as Grothendieck construction of functor Cov: C^op to Pos or category of partially ordered sets. sending opens U to set of covering sieves.

Global section functor on an (infty, 1) topos is a Hom functor of morphisms out of the terminal object H(\*, -) from infinity stack sheaf of C to infinity stack sheaf of a terminal object which is an infinity groupoid. The infinity groupoid is the terminal object.

Global section functor: direct image functor on Grothendieck topos, induced by canonically mapping spaces to terminal objects. It is right adjoint to the left adjoint which is the Set tensor on the terminal object sending set to coproduct of card(S) copies of terminal object which is the constant object. The left adjoint is the constant sheaf. It is constant since we lost all information by using the terminal object. Generalisation of the forgetful functor.

Etale space: sheafs on the site of opens for topological space is the sheaf of local sections on its etale space E (double cover as example) bundle such that the sheaf functor takes opens U to sheaf of local sections Gamma*U(E). The sheaf of global sections is the hom-sets on the sheaf from the terminal object to the sheaf functor. Sheaf of global function = Hom_Sh(X)(*, A), A is sheaf functor, terminal object, Sh(X) is sheaf category.

Sections are right inverses. Sections B -> A are right inverses of bundles A -> B which are left inverses of sections.. Sections typically refer to global sections, not local sections by default. In homotopy type theory, helpful for defining left injections and right injections.

Derived functors: normal functors that are presented in a category of weak equivalences (homotopy suitable setting).

Dehn twist: cut cylinder with line, glue back circle with rotation. Line becomes twisted at cut.

Mapping class group of torus: is special linear group of 2 x 2 matrices, Teichmuller space is the upper half plane. Horizontal Dehn twist, take shearing matrix A = (1 1, 0 1) giving (x+y, y) on (x, y). Vertical Dehn twist, take shearing matrix B = (0 1, 1 1) giving (x, x+y) on (x, y).

Mapping class group: group of orientation preserving homeomorphisms of oriented topological manifold, group of automorphic homeomorphisms onto itself modulo isotopy i.e. MCG := Aut / Aut0. Nielsen Thurston classification.

Classification of surfaces: connected oriented finite type surfaces can be classified by punctures, genus, boundary. Classifying spaces encoded combinatorially in category of ribbon graphs.

CW approximation theorem: for any space X, there is an induced map Y to X for some closure finite weak topology complex Y with induced isomorphism of homology, homotopy and cohomology groups.

Modular arithmetic: m divides a - b means a = b mod m, a dividend, b remainder, m divisor.

Coprime ideals: sum of coprime ideals give the full ring, There are coprime numbers, coprime ideals, coprime polynomials.

Bezout's identity: linear combinations of integers are equal to their greatest common divisor i.e. au + bv = gcd(a,b). Proof: if u and v are coprime, Z as linear combination have 1 as unit vector so linear combination au/gcd(a,b)+ bv/gcd(a,b) = 1 since primes are orthogonal vectors on integers. Multiply by gcd(a,b) to get the result. Alternatively, apply Euclidean algorithm backwards using the fact that intersections of linear combinations with the integers must have minimal element (or gcd(a, b) is minimal). Since these are linear combinations, by induction linear combinations of scalars of primes are equal to the greatest common divisor of the scalars.

Fundamental theorem of equivalence relations: classes of equivalence relations either equal or disjoint but not both and one can some the cardinality of classes of equivalence relations. Proof: if disjoint we are done. Suppose not disjoint, construct equivalence from element in one set to element in other set, so they must be equal sets (used the fact that sets have no repeated elements). For cardinality relation, apply cardinality functor from category of Sets to category of Naturals taking union into sum.

Freyd-Mitchell embedding: small abelian categories embeds fully and exactly into the category of R-modules over suitable ring R

Brouwerian counterexample: statement implies principle that is non-constructive. Example: something implies Zorn's lemma

Extensionality axiom, sets pictured as trees have unique branches

Foundation axiom, branches of sets pictured as trees cannot have infinite length

Von Neumann hierarchy, recursively take subsets of sets, taking unions at end of ordinals to define ordinals

Comprehension axiom: can always find a set of also some property, fails due to Russell's paradox

Pairing: inductively find sets of pairs of elements

Choice: pick some element from sets of elements to find a new set, this new set exists.

Projective dimension of module: minimal length of projective resolution of module over a ring. Osofosky, projective dimension of modules over ring C[x,y,z] is undecidable in ZFC. 2 if continuum hypothesis holds, 3 if it fails.

Power set cardinality, if card(X) < card(Y), note that card subsets of X < card subsets of Y is undecidable in ZFC.

Whitehead problem: 0 to Z to B to A to 0 is spit short exact sequence. Equivalently Ext1(A, Z) = 0, A and B abelian groups. Does this mean A is a free group? Answer by Shelah is undecieable in Zermelo Fraenkel axioms in set theory.

Split exact sequence: short exact sequence built in the simplest possible way (quotients)

Lex: left exact, preserving FINITE colimits. So it is weaker than left adjoints.

Rex: right exact, preserving FINITE limits. So it is weaker than right adjoint.

Solvability: permutations of roots preserving algebraic relations can be used to determine solvability by radicals.

Etale topology: gives a uniform definition of Galois groups and fundamental groups.

Galois group: covering space with fundamental group or universal covering space with algebraic closure.

Module: additive abelian groups closed under left and right linear decomposition f(ax + by) = af(x) + bf(y) of ring multiples of group elements.

Snake lemma: three tensor products _ M exact sequences columns with (module) M except for missing zeroes on 0 to Zm to Zn to A to 0 substituting A, B, C for A. This gives exact sequences of complexes and tensor products except at end of sequence of Tors and start of tensor products of A, B, C. To fill in snake belly, zigzag from Tor(C, M) to A _ M. Well defined forwards due to first column having final image zero. Well defined backwards due to rest of columns having final image zero.

Symmetry of Tor(A,B), not obvious because resolutions are taken first. Construct three sequence by on 0 to Zm to Zn to A to 0 by tensoring (already) Zs, Zt, B where 0 to Zs to Zt to B to 0 is exact. Gives well defined zigzag at last steps since final images vanish, warning not well defined at intermediates. So Tor(A,B) to Tor(B,A) is homomorphism. By symmetry, isomorphism.

Uniqueness of Tor under different resolutions: start with different resolutions, note that A to A is isomorphic. We are stuck with Z^(m1) to Z(m2) and Z^(n1) to Z^(n2) as maps called f - g. No problem, defined boundary maps by abuse of notation to be d, and lifts from Z^(n2) to Z^(m1) to be s. Consider f-g =  sd by bottom right triangle, and f-g = ds by top right triangle. Gives argument that f-g = ds + sd, the commutator sum. Therefore f and g are homotopic. Upon taking tensor products of B to give Tor(A, B) or Tor’(A,B) via the typical sequence 0 to Tor(A, B) to B^(m1) to B^(n1) to zero, due to homotopy of f-g, there is homomorphism of Tor(A, B) and Tor’(A,B). Symmetric argument makes this CANONICAL isomorphism.

Tor distributes over the left and right: proof is easy over bad isomorphism to tensor product of abelian groups for a module.

Construction of Tor, take step 1 free resolution 0 -> Z^M -> Z^N -> A -> 0. You can have M and N drawn at the top in your head, then step 2 you take tensor products with coefficients in B. You will get the exact sequence once you compute homology of this which gives 0 -> Tor(A, B) -> B^M -> B^B -> A -> 0.

Free resolution: take free modules as coefficient of chain complexes… C2 -> C1 -> C0 -> 0 as basis of i-th simplex. You can weaken this to projective resolutions for duality between projective and injectives. Take homotopy of complexes when defining Tor.

Universal coefficient theorem: compute arbitrary homologies over manifold/space M with arbitrary coefficients groups/functors, G instead of using integers. Typical example sheaf of global sections as a group functor. Let _ be tensor, then you can show that it is 0 -> Hi(M, Z) _ G -> Hi(M, G) -> Tor(Hi(M, Z), G) -> 0, which is not Hi(M, Z) \* G as one naively thinks.

Standard counterexample for Hom sets over the module integers modulo two, take sequence from 0 to Z to Z to Z/2 to zero is exact. Take Hom functor integers on Z/2 so it must be 0 to Hom(Z, Z/2) to Hom(Z, Z/2) to Hom(Z/2, Z/2) which is not right exact since kernel Hom(Z, Z/2) vanish but not Hom(Z/2, Z/2) which is Z/2 as standard double cover. Therefore, Ext must be a left exact functor, corresponding to the double cover obstruction. See Borcherds video for homological algebra. Further, the same counterexample can be used to show Tor is only right exact, 0 to Z to 2Z to Z/2 to 0 is exact. Take tensor products in Z/2 coefficients, you get Z/2 to Z/2 to Z/2 to 0 is exact, so this is right exact. This exemplifies the tensor hom adjunction, and also the tor-ext adjunction. Tensor is left adjoint to the right adjoint which is hom. This is one example of the Eckham-Hilton duality.

Constructing Tor: (1) take free or projective resolution of a sequence of abelian groups, (2) take functor/tensor product, (3) take homology. Gives Tor group with “coefficient” of some functor F. Similar construction for Ext but with injective resolutions.

Probability laws are natural transformations from random variable functor to measurable functor.

Random variable: are Set endofunctors A^{omega}. Measurable function from sample space to measurable space. Motivation: you want a different measures.

Borel sigma algebra: set in topological space formed by open sets using countable unions, countable intersections, and relative complements.

Sigma algebra: closed under countable complements, countable unions, and countable intersections.

Preimage of sigma algebras are sigma algebras: prove using the fact that preimages preserve intersections, unions, and relative complements.

Permutation matrix: matrix that is exactly 1 in each column and row. Named because multiplication by permutation matrix permutes the rows and columns.

Reducible matrix: if there exists a permutation matrix such that conjugation (by transpose) oby this permutation i.e. R^T P R, for P permutation matrix gives an upper triangular block matrix, then the matrix is reducible. Intuition is that upper triangular matrix is more or less solved.

Irreducibility gives invariant distribution: row reduction gives an outcast subgroup of nodes, with no arrows pointing out of it, if you think of each row as some node, therefore, we have the existence of a stable distribution.

Weak ergodicity: time average goes to ensemble average.

Primitive Markov chain: exists positive s such that (P^s)_{ij} > 0  for any pair (i, j)

Ergodicity theorem: let {X_m} be irreducible finite Markov chain, then the average of f(X_m) i.e. 1/n sum_{0 to n-1} f(X_m) tends towards the sum of the product of the unique invariant distribution and f(i) as n tends towards inifinity.

Poisson process: {N_t}_{t >= 0} increasing, right continuous, integer valued process. Defined by properties: initial value at zero is zero, then N_t has stationary independent increments, i.e. for totally lineared ordered nonnegative time 0 <= t1 <= ... <= tn, we have N_t2 - N_t1, N_t3 - N_t2 ... being independent.

Ito isometry: expectation of integral of square of the expectation of the function with respect to Wiener process is equal to the expectation of the square of the function with respect to time i.e. Exp(int^T_S f(w,t) dW_t)^2 = Exp(int^T_S f^2(w,t) dt). Proof using simple functions, split into dummy variable, then split into autocorrelated part and uncorrelated part. Apply independence of e_j e_k delta W_j and delta W_k. Also we have B(t)^2 not equivalent to B(t) for Brownian motion B. It is useful because it preserves measure.

F_t adapted: a measurable function is F_t adapted if f(t, -) is F_t measurable.

Natural filtration:  the filtration that records all the information then at that time.

Adapted (in statistics): information of the process is precisely and completely available at the same time. It is an non-antipating process.

Ito integral: consider the diffusion term sigma(X_t, t), then consider the typical Riemann integral definition, where the integral from 0 to time t of sigma(X_s, s) dW_s is the limit as subdivisions go to zero of the Riemann sum of sigma(X_j, t_j)(W_t_j+1 - W_t_j). There are three possible choices for the integral which is either have the left endpoint integral (for the example of integrating from 0 to time T of W_t dW_t) i.e. sum of W_tj (W_tj+1 - W_tj) = 0 (this corresponds to Ito's integral).

White noise: derivative of Wiener process in the sense of distribution. Has constant power spectral density.

Coloured noise: has non-constant, power spectrum density.

Wiener process derivative: comprises of drift term and diffusion term.

Diffusion term in probability: dertivative of the white noise.

Locally ringed space is topological space by some stalk. Ringed space such that all presheafs are local rings i.e. colimits of global section functors of opens. By Gelfand duality, this corresponds to maximal ideals.

Subringed space is locally isomorphic to opens (on some site) cut out by (\*\*) functions on the opens.

Embedding: very loose way to say adjoint to forgetful functor with extra stuff

Symmetric monoidal category: a braided monoidal category where braidings of tensor product in the same product gives the identity on the tensor product. Or, monoidal tensor products have commutativity up to natural isomorphism.

Braided monoidal category: a monoidal category with a natural isomorphism of tensor products with their indices swapped that gives commutativity using some hexagonal diagram (due to using two categories). This natural isomorphism is called the braiding.

Monoidal category: vertically categorified category where the tensor product is a functor from the product of categories to the category itself with nice properties, (need to define 5, associator, left unitor, right unitor, triangle identity, pentagonal identity because you are working with two category.

Proof that right adjoints preserve limits, the one I understood is the proof here https://ncatlab.org/nlab/show/adjoints+preserve+%28co-%29limits: start with the fact that hom adjunction is naturally isomorphic. This is obvious, by definition of adjunction HomC(L(d), c) is naturally isomorphic to HomD(d, R(c)). You will want to pick c to be the limit, since R is the right adjoint. The second thing is that Hom functors preserve limits. Lastly apply Yoneda's lemma, natural isomorphism of Hom sets of objects give isomorphism of objects. Apply the first to second to somehow take out the limit. Apply Yoneda's, the limits are preserved and are naturally isomorphic under action of right adjoints. Formally dual for colimits.

Hom functors, takes product of morphisms in opposite category and category (order is important) to category of set, specifically pairs of morphisms to hom-sets. This preserves limits, taking pairs of (colimit in opposite category, limit in covariant category) to limits in set. Contravariance in first variable C^op \* C means it preserves colimits in the first variable, but C^op reverses this so it also preserves limits. In a sense, the definition of Hom functors ensures that it preserves limits.

Sheaf cohomology can be thought of as obstructions when you have an abelian group on a space and try to patch things locally on abelian groups.

Sheaf cohomology (Wikipedia gives best definition): right derived functors of left exact functor (here, the functor becomes the “coefficients”of the cohomology) of the sheaves of abelian groups on a space to abelian groups. Implies vanishing on negative sheaf cohomology, and also the zeroth cohomology group is given by the group of global sections of the left exact functor on the space.

Enough injectives: for every sheaf there is an injective sheaf with injection from sheaf to injective sheaf. This is proved knowing that category of abelian sheaves form an abelian category. Abelian category Mitchell embeds into category of modules over ring. Nice Kunneth, snakes.

General working example for pullbacks and pushforwards in motivating clients homology, consider a continuous map of topological spaces from Y to X, there is a pullback of sheaves over abelian groups f^\_ from Ab(X) to Ab(Y) which requires sheafification first over colimits, however it is better described by the equality between stalks of the pullback composed with its presheaf functor to the stalk on the image of the element. Pushforward of sheaves is easier in this case from f\_\_ from Ab(Y) to Ab(X), where the composition of the pushforward with the (pre)sheaves functor on a topological space X gives the the global sections functor on the preimage of the topological space. The pullback is exact, the pushforward is only left exact. The composition of the right derived functor on the pubsforward on some space X gives the sheafification of opens to its cohomology on the inverse images with coefficients in the (pre)sheaf functor. Note that inverse images of a sheaf is typically only a presheaf, need to sheafify again.

Motivation for cohomology, the following are equivalent exact sequence of presheaf/sheaf functors is exact if it is exact in stalks, however the global sections functors only give a left exact sequence. The easiest example considering these presheaf functors with integers as the kernel, sheaves over the reals as the image to the sheaves and sheaves over the cokernel is the unit circle. There is an exact sequence of stalks, given by the double cover as the real image of the integers over the circle as a quotient space, but there is no canonical lift of the identity residing the circle to its double cover. This gives a counterexample to how global section functors (which are continuous maps between the circle to the reals or the double cover or continuous maps between the circle to the circle) are exact.

Cohomology from the abelian sheaf functor to the global sections of abelian sheaves functor can be defined as a right derived functor of the zeroth cohomology of underlying sheaf functor to the global sections functor of sets. This has so called enough injectives for snake lemma.

Topological group. Group with left actions and inverses which are continuous (function which gives opens in domain induced by preimage of the function).

Categorical inverse limit on pairs of objects in a category with projections onto a grading of graded objects and transition morphisms between graded objects that commutes when composed. Specifically the composition of the transition morphism with pre-projection gives post-projection with universal property that gives unique morphisms that exists to this inverse limit. This is also known as a direct limit in category theory. Typical example is the infinite sequence of preimages with closeness at the end (or decidable if you use Stone duality).

Anima: generalisation of homotopy types

Presheaf is a functor from the opposite of category of opens to sets. Note that the opposite of a category of opens hard to define. Closest thing is spatial frame which is Stone dual to sober topological spaces.

Presheaf with functor F# such that for union of open covers, there is a canonical isomorphism of opens that gives the equaliser of morphisms between product of sections to the product of section (set-theoretic) intersections (overlap). This equaliser is glueing or descent.

Sheafification: left adjoint to the fully faithful inclusion of the category of sheaves into presheaves. You can use an adjoint functor theorem. Follows from the key step of the preservation of all limits from the definition of Zariski descent.

Separated presheaf: sections F(U) include into product of section of covering opens U_i for any cover.

Stalks are colimits of sections of opens for elements in opens. (Local). Stalks are direct limits of over open subset containing a point.

Sections are the sheaf functors applied on opens.

Left adjoint and right adjoint being the same functor is not an equivalence, consider endofunctor of A-modules taking the module to the zero ideals Hom(0,M) is naturally isomorphic to H(M,0) but these are not equivalence of categories.

Forgetful functors always have left adjoint which is “free” to get back all your structure. The left adjoints have various examples, free groups and polynomial rings are OK, completion of metric spaces and universal enveloping algebras are not OK examples.

Kan extensions are simply induced functors from F\* : Set^B to Set^A given functor F from A to B. Ends describe Kan extensions explicitly.

Special adjoint functor theorem: example: consider inclusion as functor from compact Hausdorff spaces to topological space, it has small homsets for both, Tychonoff theorem gives preservation of finite products, equalisers exist so finite limits are preserved. Subobjects exist, since injective continuous (injective monics) exist and are small, so compact Hausdorff spaces are well powered. Cogenerating set is small, and is unit interval. Therefore by the special adjoint functor theorem, Stone Cech compactification exists as left adjoint to this functor of inclusions

Inverse limit: https://math.stackexchange.com/questions/38517/in-relatively-simple-words-what-is-an-inverse-limit

Ergodic theory, semi group actions with no (additively structured) inverses, use this as the basis of modelling dynamics and absorbing states in ergodic theory. See Erdos notes.

Sign of permutation is inevitable, proof is consider a n sphere, boundary is (n-1) sphere which can be constructed in simplicies/CW complex, but spheres can be realised as sphere spectrum, which correspond to the integers as group under addition forgetting the spectra properly, integers as a abelian group has two automorphisms, trivial and negations therefore there is a well defined homomorphism from symmetric group of n to symmetric group order 2. Related to Tor.

Example, take model of group object. We have group, topological group, Lie group, semi direct product. Category of points of topoi is isomorphic to models of theory.

Ultraproduct, Cartesian product modulo ultra filter, filter is family of subset of power set 2^I, I is some indexing or grading, closed under superset and non empty intersections, the following are equivalent filter is ultrafilter, no filter greater than that filter, proper subsets are closed by inclusion or the complement inclusion. Ultraproducts are defining things in first order logic,

Makkai conceptual completeness, for a functor of (coherent) pretopoi, if the induced contravariant functor on models of pretopoi is an equivalence of categories, then the former functor is an equivalence of categories

Boolean ring: it is a ring of idempotent, 0 and 1 are idempotent so it is canonically isomorphic to ring of integers modulo 2. Now, consider 1 + 1 = 0 using the fact that it is a ring and must have additive inverse 1. If you drop additive inverse and have 1 as an absorbing element 1 + 1 = 1, you get (default) disjunction, and it is a Boolean semiring. It is commutative, proof: start with a + a = 0, by substituting a + a with (a + a)^2, then consider x + y, you should get xy + yx = 0 using the same trick, recycle trick to get xy + (xy + yx) = xy. Boolean ring is characteristic 2, so xy = yx.

Boolean algebra: is a ring where every element is idempotent.

Frame: Stone dual to topological space that is a partially ordered set lattice with some defining distribution of conjunction and the existence of either supremum or infinum for every set

Stone spaces: compact Hausdorff spaces which are totally disconnected. Cantor topology is the prototypical example of a Stone space.

Isbell adjunction and Isbell duality, space is geometry, quantity is algebra, take the smooth space and consider its colimit, the left adjunction taking smooth spaces to smooth rings, as copresheafification, consider a smooth algebra, taking its spectrum or sheafification gives its limit which is a smooth space as right adjoint.

Six functor formalism, three adjunctions. You want two adjunctions first, direct image to inverse image for morphisms as adjoints, direct image with compact support with exceptional inverse image or Verdier duality adjoints for separated morphisms, lastly it's the symmetric monoidal tensor product with internal hom as adjoint. See Scholzes notes.

Separated morphism, diagonal morphism is a morphism mapping a space X to its diagonal X with product in Y is such is a closed subspace of the diagonal X to Y.

Diagonal: canonical isomorphism to the self Cartesian product

Internal hom is basically internally defined morphism as object or a generalisation of non set as that identity, however they just define it as right adjoint to symmetric monoidal tensor product Analogous Ext and Tor. Symmetric monoidal Tor means internal Ext. Ext measures defect in how set exactness, Tor measures defect in tensor product exactness.

Direct image with compact support, consider morphism of schemes, consider sections such that restrictions of support to opens are nice.

Pontrjagin dual: easy example is additive on integers to circle group, take products of roots of unity gives Fourier theory. Circle group is compact and connected, integers must be discrete and torsion free by Pontrjagin duality. The exponential maps gives self duality of the additive reals (sums of powers of exponential). This gives a duality between abelian discrete groups like additivity on integers to compact commutative topological groups like the circle group.

Eckhmann-Hinton duality: The most basic duality by reversing arrows in category theory.

Fuks duality: take endofunctors of compact pointed (important for suspensions) Hausdorff spaces. Duality is expressed between loop space and suspension space. Endofunctor of loop space gives suspension space. Endofunctor of suspension space gives loop space. This works heuristically for: homotopy dual to cohomology, mapping cylinder to mapping cocylinder, fibration to cofibration.

Tannaka duality: monoid with its module category are dual, considering automorphisms/endomorphisms of some forgetful functor called the fibre functor that gives the monoid structure. Just apply Yoneda's lemma using the fact that the fibre functor is endomorphism.

Proof sketch for G-set with Tannaka duality (like Cayley's theorem), C as Set^G or GSet Aut(F) = Set^(SetG)(F,F) = Set^(SetG)(SetG(G, -), SetG(G, -)) = SetG(G, G) = G Abusing notation for GSet and isomorphism due to Yoneda's lemma.

Makkai duality: syntax of first order logic (pretopoi) corresponds to the semantics of first order logic (ultracategories). Further, opposite category of small pretopoi maps to ultracategories, ultrafunctors of from ultra category to set has the structure of a small pretopos

Koszul duality, generalising the fact that d^2 = 0 encodes a commutative law and d^2w (differential) = 0, recall that this is case for some long sequences, one can get that having free graded comm algebra on the special linear group into a differential graded algebra is the same as making it into a Lie algebra (Jacobi identity is indeed = 0), duality having free graded Lie algebra on special linear group into a differential graded algebra makes it into a commutative algebra (d^2 = 0 encodes a commutative law)

Ergodicity: all states are accessible from one another. One can lose ergodicity with irreversible decisions. Take some measurable space, impose either actions on monoid of measurable space with measurable functions (random variables) or Markov kernels (don’t understand this), then a invariant measure is ergodic if the measure obeys some zero one law (measure which are only zero and one)

Stabiliser of a group element a is a set such that left action of group element in group G is absorbed into a by a ga = a

Künneth formula, takes products of cohomology to tensor products of cohomology correcting by Tor groups. Like distribution law for Ext and Tor.

Universal coefficient theorem, generalisation of Künneth formula in stable homotopy theory where cohomology or Ext is replaced by suitable spectra, and tensor product or Tor is replaced by smash product

Compatification, include the point at infinity means consider that (or assume that) something is decidable in infinite time is under consideration

Neighbourhood means it is possible to do logical inference in finite time.

Refinement of open cover means better experiment than the open cover itself in terms of efficiency of information obtained.

Open cover refers to decidable experiment in finite time, compact means admits open covers referring to decidable by one experiment.

Example of verification in finite time corresponding to semidecidable logic, verify something is open in finite time, closed set not so because of points in the boundary requiring infinitely many computations.

Stone duality, poset lattice correspond to topology, with poset lattice interpreted as a form of logic, this corresponds to topology being defined as a semidecidable logic, where arbitrary unions correspond decidable disjunctions, finite intersections correspond to decidable conjunctions in finite time.

Pro object: projective, projective limit is older term for categorical limit. Contrast to ind objects or indcutive object, corresponding to inductive limit, old name for colimit.

Profinite sets by Stone duality: profinite set is a pro object in the category of finite sets, using Stone duality these are equivalent to Stone spaces, or compact Hausdorff totally disconnected topological spaces i.e. closed under topology, where distinct points have disjoint open neighbourhoods, with only connected subspaces as singletons or totally disconnected space, which are topological spaces with sets and a collection of sets with sets closed under arbitrary unions and finite intersections. For me, I just think of counting apples, apples as neighbourhoods, and core of apples as singletons.

Profinite set and simplicial stuff: simplicial object in the category of compact and totally disconnected topological spaces.

Etale cohomology, you want a topological or etale topology with arbitrary direct limits and finitely inverse limits, reminiscent of the definition of a topology with arbitrary unions and finite intersections. This topological notion gives the right correspondence for topoi.

Morphism of topos should have the same intuition as continuous functions, preimages

Giraud axioms: defines a topos, need flatness unramified so that you don’t have a double cover where one half winds to infinity to map nicely onto the circle.

Etale space, geometrically corresponds to some double cover. The circle is some terminal object that all other objects (looking like etale space) maps into the terminal object, analogous to how double cover maps onto circle.

Prefix free definition of Kolmogorov complexity, constraints on what counts as a definition only. Practical outcomes, products become direct sums of complexity up to additive constant O(1). More importantly, probability of 2^-K converges for prefix free Kolmogorov complexity of K.

Grothendieck's typical question: two examples. (1) if we have a functor from schemes/rings to set, what scheme or ring does it represent? Similarly if we have a spectra, what cohomology theory does it represent by Brown's representability theorem in connected CW complex with base point?

Complete varieties, define them in such a way such that it is easy to generalise. Define proper maps of scheme, pick base scheme a field, then if proper map of schemes exist preimage is complete variety, easy to generalise if you can easily replace the base scheme.

Example of base scheme to define families of schemes, reverse currying, take elliptic curve y^2 - x^3 - ax - b. Instead of working over C2, work over C4, then have a, b fixed point. The inverse image of the fixed point is a family of schemes.

Morphisms of schemes are primary object in Grothendieck's philosophy, the idea is you want to define maps to a base scheme, and every scheme maps to the terminal object the spectrum of the integers. This way when you have some definition of a property of the morphism, you can replace the base scheme to get something else

Z[t]/t^2 thickening of affine line with nilpotent everywhere, K1 contains invertible elements, can tell it is NOT A1 homotopy invariant by picking certain invertible elements that is in one but not the other

Brown representability: all cohomology theories can be represented by spectra, need pointed connected spaces, CW complexes to state LES.

Wedge sum, glue together pointed spaces at the point.

Cayley's Theorem, one of my favourites because once you understand Cayley's Theorem, you understand Yoneda embedding and Yoneda's lemma. Note: not trivial, requires key step. Consider underlying element of group x, mapping to left action gx. IMPORTANT: groups are closed, so this is bijection, since this is a bijection on the same set, it is a permutation, so groups must be isomorphic to permutation groups (or subgroups of symmetric groups) under composition of permutations. Yoneda's: considering homset(b, a) mapping to natural transformations nat(hom(a, -), hom(b, -)). This must be an isomorphism, since compositions of morphisms are morphisms (we used the assumption of a locally small category here, this is large enough to only form a set). Therefore, define this as an Yoneda embedding (if on sets), and all small categories are embed into the category of functors of defined on that categories, which are represented by pre-sheaves or representable functors.

Groups as symmetries of something given by Cayley theorem, closure of left action is key step.

Subgroup of unital associative magmas with inverses preserved. Same unit, same magma operation.

Free abelian group, group by composition of basis elements

Chain complex has free abelian group (have generators as basis) on n simplex with sign alternating boundary maps preserving orientation (clockwise or counterclockwise). Related to Tor.

Nerves, take functor from n simplex to category. Nerve of 0 is object, nerve of 1 is morphism, nerve of 2 is pairs of morphisms. Fully faithful embedding, take forgetful of partial order structure of nerves to get back category

Smooth morphism of scheme, approximated by affine space at any point, no nilpotent, but regular scheme. You want finiteness condition (presentation whatever that means) and flatness. Since this is a morphism of schemes, it is relative and defines a smooth scheme. That is the beauty of Grothendieck's morphism oriented way of thinking. IMPORTANT POINT. YOU WANT THE FIBRES TO BE REGULAR. Example maps between regular schemes can fail to be smooth. Example V(xy) from affine plane to affine line. But the affine plane and affine line are regular schemes!

Regular, think differential geometrically, consider dimension of Zariski tangent space is equal to the Krull dimension (computed using chains of noetherian stuff, max length) of local ring (local rings/ maximal ideals / points)

Krull dimension: supremum of lengths of strict inclusion chains of prime ideals. Example: field has Krull dimension zero. field k[x1 to xn] has Krull dimension n.

Height (Krull dimension) of prime ideal: the supremum of all lengths of all chains of prime ideals contained in the prime ideal.s The height of the prime ideal is the Krull dimension of the localisation of the ring at the prime ideal for a prime ideal in the ring.

Noetherian ring, Krull dimension: a ring where every prime ideal has finite height.

Fully faithful, get from cohomology to abelian group by taking cohomology of a point

Subobject classifier: basic idea is instead of subset object of a set X, pick a set X then pick a map called a characteristic map chi, the subset is now a characteristic map chi, this is Grothendieck philosophy, use a machine/morphism instead of the thing itself.

A ring is a monoid with tensor product of abelian groups.

Galois extension, normal means linear affines, separable means no nilpotents.

Galois extension is a normal separable extension. Normal means decomposed to linear factor, separable means no repeated roots or factors. Automorphism fixing some point. Automorphism of field extension (recall you have some subfield, of a field extension) is an endomorphism (recall idempotence) that is an isomorphism (preserve structure), Galois group is exists for these, on the automorphisms of a field extension. Analogous to linear algebra, Jordan blocks with nontrivial multiplicity.

Subfield and subgroups are bijective, that is the fundamental theorem of Galois theory.

Prime spectrum: colimit of some sort of chain of suspensions. Reminds me of stalks, which are colimits of neighbourhoods of functions.

Separatedness, cannot be represented by two disjoint open subsets. Generalise to sites!

Higher inductive types are machine readable homotopy theory. Call yourself again when you define some homotopic object. Example is circle with a base with a type called circle (recursively) and a loop with a type base == base. For 2 spheres, same exercise, use base2 as twosphere, but use idpath of base2 instead of ==. Example, univalence axiom can have this loops as the integers. Interval also work the same logic, interval is defined inductively where zero and one has type interval, then segment is of type zero == one. Suspension, define north and south inductively as susp X, then define meridian as the X -> north == south.

However, you can derive finite fields of non prime integers, for example F4 using irreducible quadratic x^2 + x + 1 as quotient of F2

Rings of integers modulo integer must have prime characteristic, prime powers do not have invertibles, classic example is 2 \* 2 is not invertible in Z/4.

Fermats little theorem by induction using binomial theorem with some lemma that makes the relevant terms vanish

K-theory: (1) vector bundles, pick nice things like infinity-ring or spectra (2) sheafify with site, Zariski or Nisnevich are common options

The type of functions is denoted by a witness a to a morphism of propositions A -> B so we have a : a -> B.

A type witness pair, a is a witness of proposition A (proposition as types) we denote this by a : A.

Bool as a two type can be thought of as a type of propositions.

Equality is analogous to the homotopy path lifting property.

Function type is analogous to Cartesian product since both can used as primitives to construct a type theory.

Spectrum: representation of cohomology by Brown representability theorem

Fields: every element is invertible, every module (vector space) over fields are free or have basis (need Zorn's)

Smash product generalised tensor product which is a product that is bilinear since a ring is a monoid with tensor product of abelian groups. Tensor product corresponds to Tor.

Field extension, easy define some subfield with some subset, then the main field is the field extension. Also, the subset is adjunction to the field extension. From field to field extension, if it is a ring homomorphism preserving ring structure, must be an injection.

Skew field, non-commutative field

Eilenberg-Steenrod axioms for cohomology: contravariance, homotopy invariant, excision, suspension isomorphisms, disjoints to products, dimension axiom.

Contravariance, maps X to Y induces maps the other way round

Excision: cohomology of Y vanishes on X, then it must come from reduced cohomology of X mod Y as quotient group. Somehow can be used to prove the Freudenthal suspension theorem.

Homotopy invariant, preserves homotopy which is some interval map that is a continuous idempotent endomorphism.

Suspension isomorphism, cohomology of space is isomorphic to suspension of a space up to shift by one.

Disjoint unions of spaces form products of abelian groups under cohomology

Dimension axiom, get back abelian group taking zeroth cohomology of a point, vanishing otherwise.

Total singular complex in May's book is the same as a CW complex, proof of S(X) has extension property.

Square of stable infinity categories Cartesian. You have D(R) D(R[1/f]) D(R[1/g]) D(R[1/fg]) being commuting as Cartesian. D is derived category of a ring. Note that the quotient looks like Zariski descent already.

Motivic homotopy theory, use affine line instead of unit interval in definition of homotopy.

Retracts are continuous idempotent (or misleadingly, projections) endomorphisms. Projections are similar.

Deformation retracts are continuous homotopic idempotent endomorphisms. Difference is notion of time.

Cobordism: you draw two spaces, draw some cylinder in between two of them, that is a cobordism somehow. Natural space like thing that looks like a morphism

Group completion of finite sets gives sphere spectrum. Barrett-Priddy-Quillen theorem.

Bott periodicity, take complex k theory of point of higher degrees. Of even degrees it is integers, vanishes for odd degrees. Not sure how you get the right way round?

Symmetric spectra, some centrality, defined by some suspension, unit isomorphism, stable homotopy groups, multiplication maps. Take some chain of smash products must be equivariant (domain and codomain acted on by the same group) both acted on by symmetric group. A monoid of this is a symmetric ring spectrum. With pointed simplicial sets.

Types, you have witness k of a type K. Denoted by k : K. K is proposition, in some universe with type ambiguity Ui : Ui+1 vanishing to avoid paradoxes. Propositions, are analogous, set objects which are analogous to points.

Family of types is known as a context.

Types of maps corresponds to proofs corresponds to functions on sets corresponding to function spaces.

Simplicial set is a presheaf on the simplicial category with finite non empty totally ordered sets as objects and non decreasing monotonic maps satisfying the cosimplicial identities.

Kan condition, compatible by deletion of adjacent, and a simplex delete a vertex and get back any vertex. NOTE: in May this is called Kan extension, but modern literature saves Kan extension for categorical notion.

Compact, every limit point is point. Or with Stone duality, any decidable proposition is computable within finite time.

Suspension. Draw two points at the top. Make suspension. Somehow there is some sigma and somehow you can spam it till infinity.

Spectra, some cohomology theory, fully faithful from abelian group. Generalise abelian group. Examples. Spectra means I can use geometry

Propositions as types, you want types to be points.

Higher inductive type. Motivation! Apply homotopy theory methods in logic. Most exciting part, thing I care about.

Motives. Realisation from some nice category to explain other cohomology theories.

Ring is an abelian group with a monoidal structure that interacts with the abelian group via the tensor product.

Tensor product and smash product in spectra.

Magma means set with binary operation. Unital associative magma, monoid. Unital associative invertible magma, group.

Exercise: draw Spec(C[x,y]). Three types of prime ideals. Maximal points. Non-closed 1D points that look like curves that contain maximal closed points so it is irreducible, and a generic point, if you localise you invert everything that is not in C[x,y].

Exercise: draw Spec(R[x]). Line affine line, with ramification points of complex conjugate pairs.

Mapping from Z -> Z[i] gives mapping from Spec (Z) \leftarrow Spec(Z[i]). This gives three types. Ramification points, no primes, splits into two.

Principal ideal domain corresponds to the spectrum looking like an affine line. How is this related to Z as PID from classification of surfaces?

Picard groups corresponds to a group of line bundles. This assigning a vector space 1D to each point. Group completion of Dedekind domain gives ring of integer and Picard group

Group completion of circle S1, give trivial Z and Mobius band Z/2 since two mobius bands give circle

Group completion needs Zariski sheafification ahead of time to work on some projective modules thing.

Sheafification: intuition is that the best approximation of a sheaf such that the stalks are the same, so inverse image of a sheaf f_pre^{-1} G and sheafification f^-1{G} agrees for small open sets.

Ideal class groups corresponds to Picard group schemes of the ring of integers.

Discrete valuation ring corresponds to Sierpinski two point space.

Chinese Remainder Theorem, giving a function on a disconnected space is the same as a giving a function on its connected components for disjoint union of subvarieties. This corresponds to the product of the spectrum of two schemes which gives the disjoint union of schemes.

Exercise: draw Spec(C[x,y])/(x,y). Gives picture of local ring at one point.

Spectrum of zero ring is empty since zero is not a prime ideal and zero is not an integral domain. Hartshorne define it this way.

Kernel of surjective map from rings to fields correspond to maximal ideals.

Localisation of quotients and taking of quotients of localisations are equivalent, and they both give a residue field. What is the geometric interpretation of this?

Stalks of sheaves represent localisation of A-module at prime p or local rings.

Skyscraper sheaf is like the Dirac delta distribution.

Mapping from Z -> Z[x] gives mapping from Spec (Z) \leftarrow Spec(Z[x]). Fibers are finite field. Horizontal lines are quadratic residues. Fiber at zero is the ring of quotients, invert anything nonzero.

Fibres of O-module of locally ringed space at point p correspond to F_p / m_p F_p.

Glueing is flat descent. Categorically: 0 -> F(U) -> product of F(U_{i}) -> product of F(U_{ij}) is exact. There exists an exact sequence of products of overlapping open covers in topological space. Motivates the definition of site: where we generalise with fibre products, and open covers are generalised to sites.

Tangent space: assign polynomial its linear term in Taylor's series at point a, take all equations describing variety X, linearise them at a, take the common zero locus. Approximates local dimension. Oh this is magical reading it again.

A regular local ring is an integral domain: a variety that is regular at a point should not consist of several components that meet in this point. This corresponds to the points being able to be approximated by affine varieties at that point, see also definition of smoothness, but they approximate it by Euclidean space with Euclidean topology instead.

Valuation of an element: order of vanishing of a local function on a curve at a point. Note: works on any integral domains and quotient fields, so can be in any abelian group and not just integers. Example: for a k to be a field of rational functions of variety X around smooth point a, the valuation can be thought of as an order of a zero or pole at smooth point a in the variety.

Fields are zero dimensional regular local rings i.e smooth schemes modelled by affines with Krull dimension zero.

Discrete valuation rings are one dimensional regular local rings.

Singular curve: some sort of self crossing in the curve. Nonsingular means no crossing.

1-dim regular local rings: local properties of smooth points on curves.

Dedekind domains: key examples are irreducible smooth curves in algebraically closed fields.

Picard group of Dedekind domain corresponds to how far the Dedekind domain is from unique factorisation domain. See also K-theory of Dedekind domain giving the direct sum of the integers with its Picard group.

Prime factorisation: Decomposition of varieties into pieces that cannot be subdivided further. Prime factorisation also encodes orders of vanishing of function f of all points of a irreducible smooth curve X. Example: X = V(y^2 - x(x-1)(x - \lambda)) in Gathmann's notes. Exercise: draw this Pick general linear function l, general line crosses at three points which are maximal ideals so (l) = P_1 * P_2 * P_3, special linear functions l' COINCIDES so (l') = P_1' P_2'.

However, recall that the underlying valuations on the local rings are defined originally not only on these discrete valuation rings, but also on their quotient field. Geometrically, this means that we can equally well consider orders of rational functions, i. e. quotients of polynomials, at a smooth point of a curve. These orders can then be positive (if the function has a zero), negative (if it has a pole), or zero (if the function has a non-zero value at the given point).

Affine varieties are "shapes". Varieties are rings of polynomial functions. They are also closed sets in Zariski topology.

Disconnected: disjoint union of closed sets in Zariski topology is empty.

Dimension of variety: supremum of chain inclusions of irreducible closed subsets / subvarieties X.

Condensed formalism, care about compact (all limit points are points), Hausdorff (disjoint opens exist), totally disconnected )

Codimension of Y in X, supremum of chain inclusions of irreducible closed subsets / subvarieties from Y to X. Local dimension at this point. Local dimension of irreducible variety is the same at every point.

Pure dimension: valid only for Noetherian topological spaces, every irreducible component has same dimension which is n. Affine varieties with pure dimension 1 are curves, pure dimension 2 are surfaces, more than that hypersurfaces. Examples where definition of pure dimensions breaks down includes a line (variety) passing through a plane (variety)

Subvariety Y on fixed variety X: ideal of all functions on X that vanish on Y. Specifically, radical ideals. Ideals of subvarieties are always radical and exact on algebraically closed fields.

Morphism of varieties: ring homomorphism with source and target reversed. Made automatic with presheaves as contravariant functors from category typically of rings to category of (open) sets. Sections of presheaf are elements of ring of functions on open sets.

Sheafs allowing gluing of presheaves and conditions on it are local.

Germs of (pre)sheaf at point a, functions defined on small neighbourhood, these are local functions. Examples: rational functions with nonvanishing denominator at point a.

Stalks of a (pre)sheaf at a point, like localisations of presheaf at some point.

Passing from ideals to varieties reverses inclusions. Smaller zero ideal generates whole space. Vanishes on whole space.

Localisation makes more elements invertible by allowing fractions, geometrically it is zooming in on a variety at a local point.

Spectrum of integers. Points of all prime ideals, with a fat point with the zero ideal.

Full space: zero ideal.

Empty set: (1) as ideal or the unit ideal. Useful in showing (quasi)compactness of Zariski topology?

Intersection of subvarieties: sum of ideals.

Union of subvarieties: product or intersection of ideals.

Difference of subvarieties: quotient of ideals. Strictly, the difference Y \ Z is in general not a variety, so the exact geometric operation corresponding to quotient ideals is taking the smallest subvariety containing Y \ Z.

Disjoint subvarieties: coprime ideals.

Fibered products correspond to tensor products. Exercise: draw fibered products.

Vector bundles are equivalent to class groups. Exercise: make sense of this. Also, prove integers as principal ideal domain from homology of torus and classification of surfaces.

Lattice of integers correspond to the adjoining a root onto the integers.

Homology or cohomology show how far it fails under localisation. Exactness give some Euler characteristic +2, F - E + V - 2 = 0. Mike Hopkins add holes become zero, easy way to remember is to divide the a torus in the regions. 4 barriers, 4 regions, no vertices, so zero.

Zero germ corresponds to localisation of maximal ideal at point p being zero. See also stalks.

Images of varieties: contraction of ideals.

Inverse images of subvarieties: extension of ideals.

Prime ideals: irreducibles or points.

Maximal ideals: closed points.

Not every ring is the coordinate ring of a variety, so for general rings we have to find an algebraic argument (Zorn's lemma) that ensures the existence of maximal ideals.

For every ideal in a ring, a radical of an ideal consists of the intersections of prime ideals is shown by Zorn's lemma. This corresponds to the geometrically obvious statement that the variety is the union of its irreducible subvarieties.

Fractions: rational functions that are local functions well defined at a point.

Localisation: restricting function to arbitrarily small neighbourhoods q. Like defining differentiability and continuity.

Localisation as u(as' - a's) = 0 for some u in S, S multiplicatively closed. Gathmann gives an immediate way to remember geometrically: Pick point a = (1, 0), (y/1) and (0/1) must agree for variety X = V(xy) but fails since (y * 1 - 0 * 1) is not equal to 0. This is fixed by introducting x so x(y * 1 - 0 * 1) = xy = 0.

Noetherian: finite descending inclusion chain of varieties towards empty. Make subvariety smaller by dropping irreducible component or reduce dimension of subvariety. Decomposition of a subvariety into finitely many irreducible subvarieties is always possible for Noetherians.

V(x,y) is y = x is a point.

V(xy) is xy axes.

Embedded components: subvariety contained in another subvariety. Example is (0) as fat point contained in line for the spectrum of integers, isolated points. The corresponding algebraic statement is that P_2 contains another prime ideal P_1 occurring as a radical in the decomposition; we will also say that P_2 is an embedded and P_1 an isolated prime ideal.

Artinian: finitely ascending chains of varieties. So Artinian coordinate rings are finite unions of points. Not true for Noetherian. Algebraically, this means zero ideal is always product of maximal ideals.

Prime and irreducible elements. Consider coordinate ring R = R[x,y]/(x^2 + y^2 - 1). Irreducible. Since it is a circle, not a product of two lines. Lines are linear polynomials in R[x,y]. It is still irreducible in R since lines must cross from inside to outside. This is not prime in R since it consists of two points. Exercise, reproduce example 8.7 in Gathmann.

Irreducible: cannot be written as union of closed sets in Zariski topology.

Ring extension map C[x,y] -> C[x,y]/(f) (smaller ideal to larger ideal) is morphism of varieties pi from larger variety to smaller variety. Drawing only the real points, we have examples of points V(xy) with morphism pi to the real line (V(x)). Exercise: reproduce Gathmann 9.4 as exercise. Inverse images of pi are fibers. Geometrically, this is an infinite fibre at x = 0. Try examples of y^2 - x^2 giving two point fibres except at origin, and xy - 1 giving one point fibres except empty fibre at origin. The precise geometric correspondence is more complicated.

Normal domains: Coordinate ring of irreducible varieties. Quotient field are rational functions well defined except at isolated points where denominator vanishes. Example: C[x] is normal, rational function is ill defined as a pole but cannot satisfy monic relation since its highest order pole cannot be cancelled by lower order poles. R[x,y]/(y^2 - x^2 - x^3) is not normal, looks likereducible two lines V(x+y) V(x-y) at origin approaching +1 and -1 at origin.

Noetherian normalisation: example of V(x_1x_2 - 1) fails lying over at origin. Coordinate transform to tilt it to V(y_2 - y_1^2 - 1), x_1 = y_2 + y_1, x_2 = y_2 - y_1. Lying over is OK. See Gathmann notes.

Finite ring extensions: surjective geometric maps with finite fibers preserving dimension. See example 9.19 in Gathmann.

Sum of radical ideals are not radical. Easy: take tangent of V(x^2) and V(x)

Blowing up: replace origin with a projective space to see inside it.

Regular local ring is always an integral domain (no zero divisors): variety is locally irreducible at every smooth point.

Fat points: See Spec(K[x]/(x^2)). There is a fat point at the origin on an affine line you can only see linearisations, on a plane it will start to stick out more.

Local rings: rational function with well defined values at point and does not admit similar evaluation maps since the denominator of the fraction might vanish there i.e. unique maximal ideal.

Projective curves: add point at infinity for parallel lines to intersect. Embed each point (x_1, ..., x_n) to (1, x_1: ... x_n) as affine coordinates, the reamining points are (0, x_1: ... x_n) as points at infinity so P^n = A^{n} \cup P^{n-1}. as affine and infinite part. Analysts call these Riemann spheres.

Flatness: Let f : X -> S be a morphism of schemes, and assume that S is reduced. (i) If S is a smooth curve then f is called (geometrically) flat if no component of X is mapped to a single point in S. Here by component we mean an irreducible or embedded component, i.e. (in the affine picture) the subvarieties of X occurring in the primary decomposition of the ring that defines X.

Weak Nullstellensatz shows that the “traditional points” are present as points of the scheme, carries over to any algebraically closed field. If the field is not algebraically closed, traditional points are glued together into clumps by Galois conjugation, as in real affine line and the affine line over F_p.

Quasicompact and quasiseparated if and only if X can be covered by a finite number of affine open subsets, any two of which have intersection also covered by a finite number of affine open subsets. I notice that affines causes the word quasi.

Consider the case A = C[x, y]/(xy) and f = x. What is the localization A_f? The space Spec C[x, y]/(xy) “is” the union of the two axes in the plane. Localizing means throwing out the locus where x vanishes. So we are left with the x-axis, minus the origin, so we expect Spec C[x]_x . Exercise: what natural isomorphism is there?

Suppose we have a function (ring element) vanishing at all points. Then it is not necessarily the zero function! Why, nilpotent. The translation of this question is: is the intersection of all prime ideals necessarily just 0? The answer is no, as is shown by the example of the ring of dual numbers k[\epsilon]/(\epsilon^2): \epsilon is not equal to 0, but \epsilon^2 = 0. Any function whose power is zero certainly lies in the intersection of all prime ideals. Functions are not determined by their values at points: the fault of nilpotents.

If a ring has no nonzero nilpotents, we say that it is reduced. Compare to irreducible.

Projective n-space is the union of lines through origin in dimension n+1.

A geometric point of a scheme X is defined to be a morphism Spec(k) -> X where k is an algebraically closed field.

A geometric fiber of a morphism X -> Y is defined to be the fiber over a geometric point of Y, i.e., the fibered product with the geometric point Spec k -> Y.

A morphism has connected (respectively. irreducible, integral, reduced) geometric fibers if all its geometric fibers are connected (resp. irreducible, integral, reduced). One usually says that the morphism has geometrically connected (resp. geometrically irreducible, geometrically integral, geometrically reduced) fibers.

A k-scheme X is geometrically connected (resp. geometrically irreducible, geometrically integral, geometrically reduced) if the structure morphism X -> Spec k has geometrically connected (resp. irreducible, integral, reduced) fibers. Recall Grothendieck's philosophy where you want to define the structure morphism to get these properties over a base spectrum/scheme Spec k. We will soon see that to check any of these conditions, we need only base change to k.

Site: a structure that enables descent not by using intersections of subsets in descent with fibre products. See condensed formalism intro by Scholze.

Zariski cotangent space of a local ring (A, m) is defined to be m/m^2; it is a vector space over the residue field A/m.

The dual vector space is the Zariski tangent space. If X is a scheme, the Zariski cotangent space Tv at a X,p point p in X is defined to be the Zariski cotangent space of the local ring (O)(X,p) (and similarly for the Zariski tangent space TX,p). Elements of the Zariski cotangent space are cotangent vectors or differentials; elements of the tangent space are tangent vectors.

Schemes are topological spaces with a sheaf of unital rings whose colimits over all values of this sheaf on open subsets over every point called stalks that must be local rings or rings with a unique maximal ideal.

Locally ringed space: sheaf + topological space