UNDERSTOOD

Integral ring homomorphism preserves closed point under Isbell adjunction: if p from A to B is an integral homomorphism, Spec p from Spec B to Spec A mapping closed point to closed point since if D in D’ and D’ is a field, D is a field following from integral extension of integral domain. This gives the motivation for calling it integral ring homomorphisms. https://math.stackexchange.com/questions/424408/when-is-the-image-of-a-closed-point-closed-under-a-morphism-between-schemes

Application of the Lemma on Spec map induced by ring Hom: consider example of affine line on the integers being the set of prime ideals of poly ring, let f from affine line on Z to Spef Z denote the continuous map induced by the canonical ring homomorphism from Z to Z[T] then we have a partition where the affine line on Z is made up by the union of the preimage of the zero ideals and the union of all primes by the preimage of pZ for every prime in Z. This is called a partition of the affine line on Z. Studying it, we can take the localisation at zero ideals to get a canonical homeomorphism between the preimage of the zero ideal and set of prime ideals of Q[T] denoting the affine line. Let p be a prime number, then an ideal is in the preimage of this map f of ox if and only if p is in p, so Z[T]/(p) gives finite field algebra F_p[T], from 1(b) we have a homomorphism between the preimage of f from pZ and the coordinate ring or the affine line over a finite field. This brings affine lines over Q and finite fields into a single space.

Lemma on Spec map induced by ring Hom; let phi be a ring homomorphism from A to B, let f be the Spec phi map from Spec B to Spec A then it is (1) continuous (2) if phi surjective then then f induces homomorphism from Spec B and closed subset V(ker phi) of Spec A; (3) phi is localisation morphism A to localisation S^{-1} A, then f is homeomorphism from Spec(S^{-1} A) onto subspace { p in Spec, p and S disjoint of Spec A}. For (1), one could argue via Isbell adjonts that these are the morphisms of their respective categories. Another way is directly consider this, let I be an ideal of A, let IB be an ideal of B, generated by phi(A), it is clear that the preimage of f on V(I) gives V(IB) since the preimage of an open is an open, we have that f is continuous; (2) if phi is surjective; f as a map on Spec is injective and under restriction to kernel serve as a continuous bijection on the level of varieties of kernels from Spec B to V(Ker phi), the map is closed since it sends a closed set V(J) to a closed map V(preimage of J) the map is closed and f is a homeomorphism; (3) recycle part b on the localisation morphism and unwind the definitions.

Lemma on radicals: let I and J be two ideals of the commutative ring A, then (1) the radical of A can be defined as the intersection of ideals p in the Zariski closed set V(I), also (2) V(I) is in V(J) if ideal J is in rad(I). Proof: forward where radical is in intersection of ideals p is obvious, converse, trick is to replace A with A/I, I is zero ideal so that V(I) is Spec A. Suppose f is in the intersections of ideals, then we have f to have nilpotents, so that we can show opposite containment. Suppose contrary, f has no nilpotents, take localisation at A_f. This must be nonzero since no nilpotents. Let p’ be a prime ideal in the localisation at f since it is nonzero (recall stuff about associated primes), this induces a prime ideal p in Spec A, with f not in the prime ideal p, but f is in the intersection of all prime ideals, so f must be nilpotent. For part 2, pick J as I, then pick I as the full ring.

Affine line over k is not Hausdorff: proof consider set of generic point in V(I) if this is the case then the ideal I is in the zero ideal, the algebraic set cut out is the affine line, therefore the closure of the generic point is the whole affine line, this means there exists a nonclosed point {0}. The topological space is not Hausdorff, but the affine line over k is separated as a scheme.

Affine line over k worked example: generic point is 0 ideal, points are max ideals k[T], the affine line over k is defined to the spectrum of k[T]. Proper closed sets are the finite sets. Subsets form varieties V(I), where I is a nonzero ideal, then the V(I) can be formed from the set of prime ideals P_i k[T] for each P_i(T) irreducible factors. Note that this generic point is not closed since 0 is not a maximal ideal of k[T].

Elementary open set Spec A: set D(a) or at the set of all prime ideals of A not containing a, where a is an element of the prime ideal.

Intuition for localisation and losing fg: intuitively, localisation involves inverting some stuff and each thing inverted could need a generator (its inverse). So if you invert a finitely generated submonoid you're good, but if you invert anything else (like the complement of a prime ideal when you localise at a prime in the commutative case) you can lose fg.

Motivation for associated graded construction: turns arbitrary local Noetherian rings into finitely generated graded rings.

Hilbert function of R: dimension in R/I of I^n / I^{n+1} of ring R, similarly for module dimension in R/I of I^n M / I^{n+1} M, can be expressed as binomial coefficients. Arbitrary intersections of powers of I^j = 0 are useful to know no elements are forgotten, motivated Artin-Rees lemma for this.

Blowing up Eisenbud intuition: stick soda straw into surface topologically a 4 manifold; then blow up a little bible 2 sphere at the point.

Artin-Rees lemma: let R be a Noetherian ring, I in R be an ideal and M’ in M be finitely generated R modules, if M = M0 containing M1… is I-stable filtration (feels like inverse limit) then induced filtration under intersection M’ containing M’ intersect M1 in M’ intersect M2 is also I-stable. These are I-filtration, and I-stability means IM_n = M_{n+1} for sufficiently large n.

Initial form of poly: consider f in M, let m be largest number so f in M_m, the initial form of f is in(f) = f modulo M_{m+1} in quotient M_{m} / M_{m+1} motivation is to have an interesting map on sets from M to associated graded filtration M.

Natural map from Hom(X, Spec R) to Hom(R, G(O, X)): start with ring hom from A to sheaf of global sections, affine covering of ring Hom X = union of open B_i, inducing maps to A to open B_i copy Hartshorne case for X = Spec(B) before, using uniqueness from localisation stalks, see Kidwell’s answer since it actually works on arbitrary locally ring spaces: https://math.stackexchange.com/questions/56854/on-the-adjointness-of-the-global-section-functor-and-the-spec-functor

Well ordering principle: nonempty set of natural numbers has least element.

Left derived functor in the language of cocartesian fibrations: convert functor f from categories C to D into a cocartesian fibration p : eps to [1], localise eps, if localisation esp’ of esp remains cocartesian over [1], we say f has a left derived functor. It can also be derived as the right Kan extension, right derived functor can be defined as the left Kan extension of localisation? Need infinity categories, see Hinich’s paper “What is a Derived Functor” for this to make sense. See also Dwyer-Kan localisation.

Secondary A-modules: let A be commutative ring, an A-module m is said to be secondary if M is nonzero and for each a in A, the endomorphism p_a from M to M defined by p_a(m) = am for m in M is either surjective or nilpotent, if M is secondary then P = rad(ann(M)) is a prime ideal, and M is said to be P-secondary. Nonzero quotients of a P-secondary-module is P-secondary (equivalence relations only eliminates cases for endomorphism).

Examples of secondary A-module: A is integral domain, quotient field K is (0)-secondary A-module, A is local ring with maximal ideas P and if all element of P is nilpotent, then A itself is a P-secondary A-module.

Secondary presentation: expression of secondary modules as finite sum of secondary submodules M = N_1 + … N_n, this representations minimal if the prime ideals P_i = rad(ann(N_i)) are all distinct and none of the N_i is redundant.

Flat functor: functor to set is flat if it is the filtered colimit of representable functors. Example: module F: C to Set is flat if and only if the tensor product is left exact. Localisation is a flat functor. Example, take localisation to be defined as filtered colimit, then show using Lazard's criterion that it is a flat functor.

Flat functors and points of pre sheaf topos: If C is finitely complete, F is flat if and only if it is left exact and preserves finite limit, so tensor product is left adjoint. To generalise this for a small category, the category of topos point of the pre sheaf topos Set^{C^op} or the geometric morphisms from Set to Set^{C^op} and the natural transformations between them is equivalent to the category of flat modules of C.

Sequential colimits: filtered colimit whose diagrams indexed by partially ordered set of natural numbers.

Germs in terms of filtered colimits: elements in filtered columns in Set and Gap are classes of equivalences called germs. Filtered limits in Set and Top are given as families of compatible elements called threads.

Artinian ring dimension definition: Noetherian ring of Krull dimension 0.

Finite modules have filtrations such that successive quotients are cyclic modules: let R be a ring, let M be a finite R-module, there exists a filtration by finit eR-submodules such that each quotient M_i / M_i-1 is isomorphic to R/I_i for some ideal I_i of R. Proof by induction on number of generators of M, since M is also finitely generated, let x_1 to x_r in M be generators, let M' = Rx_1 in M by definition, then M / M' has r - 1 generators, induction hypothesis applies. Clearly M' is isomorphic to R/I_1 and so forth, with I_1 defined as {f in R | fx_1 = 0}.

Blowup algebra / Rees algebra: let R be a commutative ring, let I be an ideal contained in R, the blow up algebra associated to the pair (R, I) is the graded R-algebra Bl_I(R) = oplus_{n >= 0} I^n = R ++ I ++ I^2 ... where the summand I^n is placed in degree n. Let a in I be an element, a^(1) the element a seen as an element of degree 1 in the Rees algebra, the affine blow up algebra R[I/a] is represented by an expression of the form x/a^n with x in I^n. This feels very localised, two representives x/a^n and y/a^m define the same element if and only if a^k(a^m x - a^n y) = 0 for k >= 0. This feels liek a generalisation of localisation.

Finite locally free module of rank r: let R be a commutative ring, and let M be an R-module. We say M is finite locally free if we can cover the prime spectrum of R, Spec(R), by standard opens D(f_i) for i in I such that M_{f_i} is a free R_{f_i}-module for all i in I and fi we can choose the covering such that M_{f_i} is isomorphic to a free module R_{f_i}^{+ r} of rank r.

Finite locally free module: let R be a commutative ring, and let M be an R-module. We say M is finite locally free if we can cover the prime spectrum of R, Spec(R), by standard opens D(f_i) for i in I such that M_{f_i} is a free R_{f_i}-module for all i in I and fi we can choose the covering such that M_{f_i} is finite free.

Locally free module: let R be a commutative ring, and let M be an R-module. We say M is locally free if we can cover the prime spectrum of R, Spec(R), by standard opens D(f_i) for i in I such that M_{f_i} is a free R_{f_i}-module for all i in I.

Coherent module: TFAE (1) finitely generated and every finitely generated submodule of M is finitely presented over R for M and R-module, R a commutative ring; (2) every finitely generated ideal is finitely presented as a module.

Coherent ring: coherent as a module over itself.

Inverse system: inverse system over the partially ordered set indexed by naturals. Given ring and R-mdoules M_1 <- M_2 <- M_3, composing successive maps, then lim M_i is limit in category of R_modules. More over f_12 : M_1 -> M_2 where f_12 * f_31 = f_32 when this makes sense. Collection of all inverses systems form a category.

Cohen-Macaulay rings: Noetherian local ring R is called Cohen-Macaulay if it is Cohen-Macaulay as a module over itself.

Cohen-Macaulay module: let R be a Noetherian local ring with unique maximal ideal, let M be a FINITE R-module, we say M is Cohen-Macaualay if dim(Supp(M)) = depth(M). This has good properties, in local Cohen-Macaulay rings, any maximal chain of prime ideals have length equal to the dimension.

Prime localsiations of a regular local ring are regular: this is not that easy to show, and a lot of effort is spent to prove this fact. Let (R, m, k) be a ?Noetherian local ring: the following are equivalent: (1) k has finite projective dimension as an R-module; (2) R has finite global dimension; (3) R is a regular local ring. Consequentyl, global dimension of R equals dim(R) = dim_k(m/m^2) for maximal ideal m. 

Integral ring extension: let p: R to S be a commutative ring map, an element s in image S is integral over R if there exists a monic polynomial P(x) in R[x] such that P^p(s) = 0, where P^p(x) in S[x] is the image of P under p: R[x] to S[x]. The ring map is integral if every s in image S is integral over R.

Symbolic power: let R be a ring, let p be a prime ideal for a ring, for n >= 0, the nth symbolic power is the ideal p^(n) is equal to the kernel of the map R to R_p / p^n R_p. 

Definition of prime ideals using symbolic powers of R/p^(n): let R be a noetherian ring, p be prime ideal, n > 0, then Ass(R/p^(n)) = {p}. Proof: suppose q is asscoiated prime of R/p^(n) then p is in q. On the otehr hand, consider x in R, x not in p is a nonzerodivisor on quotient R/p^(n). If y in R and xy in p^(n) = R intersection p^n R_p by definition of asscoaited power, then y is in p^n R_p, hence y is in p^(n).

K_0 group K_0'(R): every finite R-module M there is an elemenet [M] in K_0'(R), for every short exact sequence 0 -> M' -> M -> M'' -> 0 of r finite R-modules, have the relation [M] = [M'] + [M''], K_0'(R) has elements [M] is generators, then relations K_0'(R) among generateors [M] are Z-linear combinations of the relations coming from exact sequences as above. Note that the collection of all finitely generated R-modules have to be checked to be a proper class.

Simple module in terms of length: TFAE: (1) M is simple; (2) length_R(M) = 1; (3) M = R/m for some maximal ideal m in R; https://stacks.math.columbia.edu/tag/00IU 

Jacobson ring: use the definition of Jacobson ideal for every radical ideal I (equal to its radical i.e. I = rad(I) and not just I in rad(I)), is the intersection of all maximal ideals. 

Length of module over M: (1) supremum of chain n for 0 = M_0 in M_1 in M_2 to M_n = M, M_i not equal M_{i+1}. Use injection for inclusion in this case; (2) supremum of lengths of chains of submodules. Modules of finite length are finite. Length is additive in short exact sequences.

Radical / semiprime ideal: radical ideal is set of elements r such that r^n in I for some natural number n. I is in rad(I) since I is less strict, only allowing case n = 1. Radical or semiprime ideal is when ideal equal to its own ideal. Radical of primary ideal is prime ideal. 

Locally nilpotent ideals: an ideal I of comm. ring R is lcoally nilpotent sucht that for every x in I, there exists natural number n such that x^n = 0 or x is nilpotent.

Nilpotent ideals: I^n = 0 for natural n.

Invertibility of 1+I in R: let R be ring with Jacobson radical rad(R), let ideal I in R be an ideal, TFAE: (1) I in Jacobson radical; (2) every element 1+I is a unit in R; (3) every element of R which maps to a unit of R/I is a unit. Proof: suppose f is in Jacobson radical, then f is in all maximal ideals m of R, so 1 + f is not in maximal ideals for m of R, the closed subset V(1+f) of Spec(R) is empty, so 1+f is a unit and nonzero. Conversely, suppose 1+f is a unit for all f in I, if m is a maximal ideal and SUPPOSE I is not in m or Jacobson radical, then I + m = R by definition of maximal ideal, so 1 = f + g for some g in m and f in I by definition of the elements of the equation, g = 1 + (-f) is not a unit, contradiction so I must be in M. This is a good exercise to work out the meaning of results and unravel the definitions, especially what it means for units to not be in V(1+f), as well as characterisation of maximal ideal. For final statement, let f in R map to unit R/I, find g in R mapping to f mod I by definition of R/I, hence fg = 1 mod I by composition, fg is unit of R, so f is unit.

Trick with maximal ideals: if something is not in Jacobson radical, then I + m = R full ring since m is maximal ideal.

Units and prime spectra: if a variety V(f) in Spec(R) is empty, this implies f is unit and nonvanishing. Recall that maximal ideals corresponds to points.

Internal hom in R modules: this was very powerful on a multiplcative closed subset to define localisation as a directed colimit. Let R be a commutative ring, M and N are R-modules, then Hom_R(M,N) is the set of R-linear maps from M to N, comes with structure of abelian group with ring hom (x+y)m = x(m)+y(m), it is also an R-module with scalars. Hom_R defines an additive functor from the category of R-modules Mod_R from Mod_R^op * Mod_R to Mod_R.

Flatness with module maps and equational criterion for latness: TFAE (1) M is flat; (2) if f is module map from free R-module R^n to M, and x in Ker(f), then there are module maps such that there are module maps h: R^n to R^m and g: R^m to M such that f = gh and x in Ker(h), prove by consdering exactness of R^n -> R^m -> M -> 0, so x is in Ker(h)

Weak homotopy equivalences: maps that induces isomorphisms on the homotopy groups. Space you can pick yourself.

Lazard's criterion: let M be an R-module, then M is falt if and only if it is a colimit of a directed system of free finite R-modules. FORWARD: Colimit of directed system of flat modules is flat, directed colimits is exact since tensor product is let adjoint preserving colimits and directness, hence if M is colimit of directed system of free finite modules, then M is flat; CONVERSE: module can be written as colimit of directed system of finitely presented modules (we used R is commutative here) idea is to make set of ordered pairs (J, N), J finite subset of I and N is finitely generated submodule R^J intersect K, E can be made into directed preorder using morphism (J,N) less than or equal to (J', N'), this is a thin category, define this ordered pair as a quotient or simplicity M_e = R^J / N, f_ee' is natural map M_e to M_e' to be the natural map for e <= e', then this induce colim M_e to M. Stacks give the next two steps by case analysis, using a finite basis (using the fact F is ree) to show M_e' = R^J' / N' is isomorphic to M, the argument is very subtle, need a bit of work to understand. https://stacks.math.columbia.edu/tag/058G 

Example of localisation as flat directed colimit: R -> R -> R are multiplication by S, example pick R = Z, and s = 2, we have Z to Z to Z to Z, which is isomorphic to Z to 0.5Z to 0.25Z and so on, colimit is localisation Z[1/2] in Q. See Eric Wofsey's answer: https://math.stackexchange.com/questions/2665044/ring-localization-as-directed-colimit-of-finitely-generated-free-module 

Localisation as category: object set is multiplicatively closed subset, morphism s to t is an element u in S such that us = t, identities and composition is well defined since S is multiplicative, u: s -> t is a morphism (or in fact a morphism object), then there is a unique homomorphism of A-algebras A_s to A_t. The colimit has the same universal property as S^{-1} A hence they are isomorphic. Construction works for arbitrary commutative rings (note, we used us = t, so morphisms are sections). Careful, this is only a preorder, reflexive and transitive, not symmetric.

Preorder on multiplicatively closed set: multiplicatively closed set have a natural preorder, whose colimit is the localisation.

Class number: size of class group

Class group isomorphism: canonical isomorphism to the Galois group of the maximum unramified abelian extension

Localisations are flat by Lazard’s theorem: first show that it is a filtered colimit, then by Lazard’s module is flat if it is a colimit of a directed system of free finite R-modules so localisations are flat.

Double dual functor is naturally isomorphic to identity functor: proof by considering double dual of vector spaces giving the same space, double dual of linear maps of finite dimensions to get the same linear map due to the fact that these admit representations by matrices.

Definition of equivalence of categories: given a covariant functor it gives equivalence of categories if it is fully faithful and F is essentially surjective i.e. isomorphism of objects b and F(a) for object a in category A and object b in category B.

Canonical morphism of localisation considering (1, 1/2, 1/3… ) in Q * Q * Q: this is only injective, consider morphism sending (k_n)/s to (k_n/s) via this map so k_n / s = 1 / n for all n more than or equal to 1, then s is a divisor of of n for all n, a contradiction, this is at most injective, and this is a localisation, so localisations of do not commute with infinite products in general.

Coproduct all but finitely many terms: reduce it to base case of cardinality functor: product of infinite terms, it will stay infinite under cardinality, coproduct will add all these terms, and if finitely many it will be okay so noncoincident with products.

Automorphism group of sets: these are just symmetric groups.

Automorphism group of vector spaces: general linear group.

Connected groupoid: automorphism groups of the object is isomorphic but not canonically isomorphic.

Functor of maps versus functor of points: consider contravariant functor of pre sheaves to maps sending morphism from b_1 to b_2 to morphism of hom-sets mor(b_2, a) to mor(b_1, a). This is why Vakil calls it functor of maps to A. But A is fixed object, so functor of points.

Examples of unique isomorphisms: easiest one is initial object, if there are two initial objects, and all stuff map from initial object, there is a map mapping from initial object 1 to initial object 2, and vice versa, determining isomorphism. This phenomena applies to terminal objects.

Vakil’s warning of localisation notation: A_(p) means you are allowed to divide by elements not in prime ideal (p), but A_f means you are allowed to divide by f. So A_f is not equal A_(f)

Localisation is injective if multiplicative subset contains no zero divisors: exercise in Vakil but I wrote this myself: if S contains zero divisors, then kernel of this map is isomorphism classes of the zero divisors due to torsion, so nonempty kernel so not injective.

Lasker ring: commutative ring where any ideal admits coprimary Lasker decomposition. Noether showed Noetherian rings are Lasker rings.

Proof of Lasker Noether theorem: M is contained in finite product of coprimary modules. If not true, pick maximal submodule N by Zorn’s so that M/N not in product of coprimary ideals. May assume N = 0 without loss of generality just by quotienting out. Notice M is not coprimary, then it will be contained in product of coprimary ideals, so it has two submodules M_1 isomorphic R/p_1, M_2 isomorphic R/p_2, p_1 not equal p_1. ann(x_1) is P_1 and ann(x_2)  is P_2, We find that M_1 and M_2 disjoint. Take exact sequence M_1 intersection M_2 to M to M/M_1 ++ M/M_2 (using coincident direct sum of product). The kernel of this exact sequence is 0 since M_1 intersect M_2 is zero. So each of these two is contained in product of coprimaries so M must contain in coprimaries, contradiction.

Implication of Lasker Noether theorem from limit definition to original form:  pick M = R/I, then R/I = M is in product of (R/I_p), so (R/I_p) is coprimary, then I_p is primary in Lasker’s sense, so I must be the intersection of I_p if you do some exact sequence I_1 intersect to I_p to M to product of (R/I_p).

Lasker Noether theorem: M is finitely generated module over Noetherian. Ring R, coprimary means M has at most one associated prime. M is contained in direct sum of coprimary modules over associated primes of M.

Contrast primary modules and coprimary modules due to history: (1)  original version if ideal I of ring R, then ideal I is a finite intersection of primary ideals J; (2) suppose N submodule of R-module M, then N is a finite intersection of primary submodules; (3) the module M is contained in the product of coprimary ideals M_p, (2) implies (3), pick N = 0, so 0 is intersection J_o, so the idea is to use some category theory, injective natural map from M to product of M/J_p, J_p is a primary submodule, the whole M/J_p is coprimary.

Primary submodule in Lasker-Noether: X is called primary submodule if rm in X implies m in X or r^n M in X for some n > 0, Lasker’s definition of a primary submodule. It is a property of the way X is embedded in M, so it is a property of the quotient M/X over Y. If r is zero divisor of y i.e. ry = 0 for some nonzero y, then r^ny = 0 for some n > 0, to call Y to be coprimary.

Definitions of coprimary in finitely generated module over Noetherian ring: TFAE (1) at most 1 associated prime; (2) rm = 0 implies m = 0 or r^n M = 0. For (2) implies (1), suppose nonzero n, m is in M, put prime ideal P = Ann(M), not assume P is prime, then by condition (2) this means P is contained in annihilator of M. Now assume P is prime, Ann(M) is in Ann(m) = P so radical Ann(m) is in P, so P is equal to radical of annihilator M by two way inclusion so at most 1 associated prime. For (1) implies (2), can assume Ann(M) is zero because if it isn’t zero, quotient out and carry on as before without loss of generality, put P as only associated prime of M, contains Ann(m) whenever m is nonzero, since maximal element are associated prime, since one associated prime, it must contain Ann(m), now need to show P is nilpotent, to make the other condition. Suppose some a in P is not nilpotent for the sake of contradiction, then the localisation M[a^{-1}] is nonzero, if x in M is zero in M[a^{-1} so xa^n = 0, for some n. so M[a^{-1]] = 0 implies a^n is in Ann(M) or a^n nilpotent, we have contradiction, so localisation at M[a^{-1}] is nonzero, then associated prime of localisation is nonzero, pick T in Ass(M[a^{-1}]) since this is nonempty, pick T in Ass M[a^-1],let Q be the inverse image of T in R, these are both primes, if T is prime, Q is the inverse image of T, Q is the union of all ideals Ann(m) in Ann(ma) in Ann(ma^2), use Notherian so Q is in Ann(ma^n) for some n, so Q is in Ass(M), but a is in P, a not in Q, so P is not equal to Q, so M has at least two associated prime, contradicts assumption that there is one associated prime, so Lasker’s condition holds for nilpotent. This proof for definitions very involved.ß

Support of module: set of primes with localisation at point p, stalk of M at point p nonzero or M_p nonzero, or set of primes containing Ann(M). This is much more crude than the support prime.

Calculation for supports: (1) R = Z, M = Z/12Z, Ass(M) = Supp(M) = (2) and (3); (2) pick M = Z, Supp(M) is Spec Z, Ass(M) = 0; (3) pick M = Z ++ Z/2Z, Supp(M) = Spec Z, Ass(M) = (0) and (2).

Support is closure of associated primes of M in Noetherian comm. Rings: proof: suppose p in Ass(M), then P = Ann(a) for a in M by definition contained in Ann(M) and contained in Supp(M). Suppose P in Supp(M), M_p nonzero by definition look at Ass(M_p) nonempty. So we have q is in Ass(M_p), and q is in Spec(R_p) we have f from R to R_p, and inverse from f^{-1} from Spec R_p to Spec(M), look at f^{1}(q) is in Ass(M) is contained in P so p is in closure of f^{-1}(q)

Module as something living on its support to see examples of embedded primes and isolated / minimal primes: consider M = k[x,y]/(y) and is the x axis, living on its support. Consider M = k[x,y]/(y^2, xy), and Ass(M) = (y), (x,y). Minimal ones are isolated or minimal like (y), and (x,y) contains (y), and is an embedded prime looking like some nilpotent there. So module is sitting at this point, more of it is sitting on the embedded prime. This Spec M recall is the xy axis with double point at intersection.

Coprimary decomposition: break up modules, each one associated with one element of Ass(M). Fails for general rings, counterexample is M = R/(y^2, xy) for more general rings, best we can do is only submodule so R/(y^2, xy) is included into R/y ++ R/(x,y), it is only a submodule of coprimary modules, so this is coprimary decomposition. Historically it was thought of as the Lasker Noether theorem for ideals.

Lasker Noetherian theorem: if ideal I of Noetherian R, then I is an intersection of finitely many primary ideals.

Primary ideals: ideal that makes the Lasker Noether theorem works it its invited by Lasker, defined by if xy in J, then x in J or y^m in J, m integer strictly more than 0. Lasker’s proof is like 100 pages, Noether gave a super short proof.

Structure theorem of abelian groups and associated primes: take A = A_0 ++ A_2 ++ A_3 so associated prime Ass(Z^n) = (0), Ass(A_2) is A_2. The others are all unique except A_0 due to embedded prime nature of (0).

Dedekind domain that is nonfactorial not UFD: Z adjoined root five with maximal ideal (1-root5 and 2), annhilator of this ideal is (0) and cannot be built up in a chain.

Trick to determine algebraic numbers: just square it until you find a suitable equation.

Prime ideal basic definition: if a not in I and b not in I then ab not in I and it is an ideal of commutative ring.

Proof of definition of nilradical to be intersection of all prime ideals: we are done if x is in nilradical must be in intersection of prime ideals by definition of prime ideal, otherwise suppose x is not in prime ideal, then we consider maximal element of collection of ideals not containing 1, x, x^2… by Zorns, we check that this is a prime ideal M, consider M + (a) and M + (b) must contain M and the product of these two ideals contains a power of M so M + (ab) contains M strictly so ab is not in M, M now satisfies classical definition of prime ideal.

Exact sequence of associated primes: consider the exact sequence from 0 to A to B to C, note that Ass(B) is not the union of Ass(A) and Ass(C) due to cohomology reasons. Counterexample is the typical exact sequence of 0 to Z to Z to Z/2Z to 0, where Ass(A) and Ass(B) is (0) but Ass(C) is (2), we can at least show that Ass(B) is contained in the union of Ass(A) and Ass(C). Suppose R/p is isomorphic to submodule X of B by definition of associated prime and lemma on isomorphism to quotient domain X, there are two cases: (1) X and A are disjoint so X is a submodule of C so the prime ideal P generated from p is in Ass(C); (2) case 2, X and A are not disjoint, pick nonzero x in X, and a in A, the annhilator of a denoted by Ann(a) is prime ideal P, because Ann(x) of x in R/p is an integral domain by consequence of it being a prime ideal, so P is in the Ass(A), by case analysis P is in the union of Ass(A) and Ass(C). A corollary is that Ass(M) is finite if R is Noetherian, also one can construct chain of inclusiosn of the form M_{i+1}/M_{i} is isomorphic to R/(p_i) so Ass(M_i) is contained in the set of prime ideals which need not be equal because of repetition (typical example is prime power decomposition of composites in Z.)

Multiplicity of R/p in M in finite length modules: multiplicity of R/p in maximal chain. It is additive for modules of finite length. For exact sequence 0 to A to B to C to 0, we have the Mult(R/p, A) + Mult(R/p, C) =  Mult(R/p, B). This is false for finitely generated modules, fails for the nontrivial cohomology Mobius band example where we have an exact sequence 0 to Z to Z to Z/2 to 0, computing the multiplicity gives 0, 0, 1. This is due to the fact that tensor product with Z/2Z fails to preserve exactness. Multiplicity of R/0 is only additive when Ass(M) has no elements smaller than R/p.

Associated primes alternative definition: (1) set of prime ideals that are annihilator of elements of M; (2) or ideals p, where p is prime such that R/p is a submodule of M, this definition comes from a corollary we want but we need to show that for finitely generated module M over Noetherian ring R, if M is nonzero than Ass(M) is nonempty.

Associated primes in geometry: controls where primes are geometrically.

Finite length vs finitely generated in thinking about associated primes: consider inclusion of chains of ideals from 0 in M0 in M1 in M2 all the way to Mn which is M, where M_{i+1} / M_{i} is simple equal to the residue field generated by the maximal ideal. The analogue for this decomposition requires Noetherian hypotheses.

Decomposition of finitely generated groups: it can be decomposed to the free group on n as well as the cyclic groups of power prime order. Motivated if we can break up modules into Noetherian rings quotient out by a prime ideal.

Lemma on finitely generated module has submodule isomorphic to quotient ring by prime ideal: supposed module is nonzero, pick ideal p in R maximal among ideals by Zorn’s due to finite generation R/p is in M, careful this is not yet prime. This p is defined to be the annihilator of element a, for element a in M, now show that P is isomorphic to R/p which is prime; if not prime you can find x and y not in P, xy in P by nondefinition of prime ideal. Consider image x’ of x in M then consider the annihilator of x’, this contains P, y so is strictly larger than P, contradicting definition of the annihilator by picking the ideal that is maximal among the ideals, so P is prime.

Decomposition with lemma of annihilator of finitely generated module in Noetherian ring: we have 0 in M1, and M2 is nonzero, it can be shown that M1 = R/p1 for associated prime p1. Define M2 = M/M1 containing R/p2. M2 is the inverse image of R/P2 from M to M/M1, so that M2/M1 is isomorphic to R/P2 by construction, construction terminates due to this being a Noetherian ring.

Motivation for prime avoidance: ideal contained in finite union of prime ideals is contained in one of them. This feels like some sort of preservation of projections of prime ideals from finite union of primes as a limit? But I’m not sure.

Primary ideals in PID: if you think of Z, the primary ideals are powers of prime ideals in principal ideal domains, this corresponds to composites being product of prime powers.

Irreducible algebraic sets and prime: forward by considering union of zeros for fg in I, so either f or g must vanish on algebraic sets X and be in I, conversely, suppose X is union of two properly smaller subset, each Xi is smaller there must be fi vanishing on X but not x, so f1f2 in X we have f1f2 in X but neither fi is in I.

Cayley Hamilton in Eisenbud: ring R, ideal I of ring R, let M be an R-module generated by n elements, let phi be an endomorphism M, if phi(M) is contained IM, then there is a monic with p_j in I^j (free module or ideal of powers of j) such that p(phi) = 0 is an endomorphism.

Proof of Cayley-Hamilton in Eisenbud: write phi(m_i) up to n generators as linear combination of a_ij m^j then replace it with matrix (x1-A)m = 0, multiply both sides with matrix of cofactors so det(x1-A)1 m = 0, define the characteristic poly where det(x1-A) vanishes.

Reduction of filtered complex for finite dimensional vector spaces: the idea is to get a C_{i} fd vector space then we have C_{i} is isomorphic to (C_{i} / U) ++ U. Pick U = C_{i,n-1} to keep breaking down U into smaller pieces. This reduction procedure defines the associated graded complex.

Filtered complex: chain complex where 0 = Ci0 in Ci1 and so on with boundary maps respecting dC_{i,p} in C_{i-1,p}. The letter p denotes the filtration degree.

Idea behind grading of chain complex: break down homology computation independently, sum them up to get the full homology

Graded chain complex: given C_{i-1} to C_{i} to C_{i+1} in some chain complex, if it can be decomposed into a direct sum of R-modules (of commutative rings) ++ C_{i,p} that respects graining in the sense that dC_{i,p} must be in C_{i,p}.

Integral closure; ring of all elements of S integral over R is integral closure, or the normalisation of R in S, normalisation comes from using leading coefficient as 1.

Normal domain: domain that is equal to its normalisation

Integral extension of R; R-algebra that contains a copy of R as R * 1 if every element of S satisfies monic polynomial with coefficients in R.

Integral extensions of affine rings: maps of affine algebraic sets that are finite and proper.

Intuition for proper maps of affine algebraic sets: preimage of every set that is compact in the classical topology is again compact, it is essentially a continuity or limit preserving condition.

Normalisation as generalisation of algebraic integers: let K be a number field, finite extension field of Q( then the set of elements of K that satisfies monic integers with coefficients in C for the ring of algebraic integers. The study of these started commutative algebra.

Affine rings: (reduced) finitely generated commutative ring over algebraically closed field

Integral equation of s over R; let S be in R-algebra or p(x) be a poly with coefficients in R, an element s in S satisfies p if p(s) = 0, this element s is integral over r if it satisfies a monic polynomial with coefficients in R, p(s) = 0 is called an equation of integral dependence. If all elements of s are integral over R, then s Itself is integral of R.

Monic poly: poly with leading coefficient 1, don’t understand why is it called monic. Very confusing.

Central idempotent: idempotent and in center of ring. Useful for non commutative algebra. A commutative ring is equal to its center.

Infinite direct products is not isomorphic to infinite direct sums: infinite direct sums is a subgroup of the infinite direct product, identifying finitely many terms as zero. Therefore, not every module can be decomposed as a direct product of R-modules.

Irreducible ideal: not the intersection of bigger ideals, very simple definition. Intersection gives multiplication see case of 2Z and 3Z giving 6Z. Recall this analogy works because of the definition of a categorical product.

General form of Chinese Remainder Theorem: exercise 2.6 in Eisenbud, there is a isomorphism between finite quotient of R over intersections of all ideals Q_I where Q_I are mutually coprime to each other, to the finite product of quotient individual ideals. The map of rings are projection maps, p(x) = 0, by definition of quotient x must be in all of these ideals, so x is in intersection. Let m be maximal ideal of R, only one Q_I is in the maximal ideal, otherwise the maximal ideal is the full ring by contradiction. Now localisation preserves quotients, and the map p is surjective since they are surjective on the level of quotients. https://math.stackexchange.com/questions/4051727/exercise-2-6-general-form-of-the-chinese-remainder-theorem-from-eisenbuds-com for more constructive method.

Constructions of localisation: (1) first is any subset of R, then you constructs R[u_x] / ( ux_u - 1) for u in U, the quotient gives the multiplicatively closed subset, this is what is meant by adjoining inverses in the freest possible way; (2) then one can impose that (or alternatively from the start) that R[U^-1] be for ring R, and multiplicative closed subset U, where we have m1/u1 and m2/u2 is identified under v(m1u2 - m2u1) for v in and u in U, m in R

Spec(R) disjoint union of two closed gives product of varieties: disjoint union of varieties means sum of ideals in V(I1 + I2) give (1), must be in nilradical or intersection of prime ideals. By Chinese Remainder Theorem, quotient of R/I1 intersect I2, and R/I1 * R/I2 for reduced ring. Case of nonreduced ring: consider idempotent in R/I1 * R/I2, lift to element e of ring R, e is not idempotent at first, but not that e(1-e) is in R/I1 intersect I2, so is nilpotent consider e^n(1-e)^n = 0 and 1 = e + (1-e), raise both sides to power 2n one side of terms is  1 = e^2n + 2nC1 e^2n-1 (1-e) + ... 2nCn e^n (1-e)^n + ... (1-e)^2n, Notice that the first n terms are multiples of e^n and the rest are multiplies of (1-e)^n. Letting x be the sum of the first n terms we therefore have x(1-x) = 0. Notice also that x = e modulo I1\capI2, hence x is a nontrivial idempotent. So R = R/(x) x R/(1-x)

Koszul complex motivation: find finite free resolution of R/(x1 to xn), the sequence x1 to xn is a regular sequence, and the ring can be written like this, very fun you can now apply Tor and Ext or other derived homological stuff here.

Koszul complex: finite free resolution with exterior powers of binomials for free R-modules, if sequence is regular (just one permutation, not all permutations are regular) you can get exact Koszul complex, but you need R to be local ring (unique maximal ideal) to get from exact Koszul complex backwards to have all permutations of regular sequences is regular. Local ring is needed to apply Nakayama’s lemma, then you get the converse.ΩΩ

Regular sequence definition: x1 nonzero divisor then R/(x1), x2 nonzero divisor, then R(x1, x2) x3 nonzero divisor.

Proper ideal contained by maximal ideal: consider set of ideals containing proper ideal not containing 1 ordered by inclusion such that this set is nonempty, and let L be in M is totally ordered subset then union of all ideals belonging to L is an ideal of ring A, belongs to M, least upper bound of L is in M, apply Zorn’s, maximal element exist, so maximal ideal exists.

Residue field: reserved for field due to quotient of commutative local ring A by unique maximal ideal m = radical of A.

Coprimality of ideals: I + I’ = 1, same definition as ax + by = 1.

Coprimality in pairs: there is natural isomorphism between A/I_1…I_n to product A/I_1 * … A/I_n by induction on natural injective map of coprime ideals is surjective by considering mod I sums to get subjectivity.

Factorial ring: same as unique factorisation domain, an integral domain with no nonzero divisors with elements neither 0 nor unit expressible as product of prime elements.

Principal ideal domaisn with prime ideals: prime ideals look like (0) or pA (by definition) and latter are maximal ideals.

Polynomial ring over n variables in field k is unique factorisation domain: proof by?

Faithful module: a faithful module has 0 annihilator, comes from induced maps being injective.

Determinant trick on finite A-modules to prove Cayley Hamilton theorem: suppose M is an A-module generated by n elements, and that p is in the set Hom_A(M,M), let I be an ideal of A such that p(M) is in IM, then there is a relation of the form p^n + a_1 p^{n-1} … + a_{n-1} p + a_n  = 0 for A_i in I^i. (Left hand side is characteristic poly) Proof: let M = Aw_1 + … Aw_n, then by assumption p(M) in I(M) there must exist p(w_i) = sum of a_ij w_k, rewrite this with Kronecker delta symbol so sum of (p d_ij - a_ij)w_j = 0, coefficient of this system of linear equations is square matrix of A’[p], commutative subring of endomorphism ring E of M generated by the image A’ of A together with p, let b_ij denote its ij cofactor, d the determinant, multiply by b_ik, sum over _i, dw_k = 0, so d M = 0, since M is nonzero, so d = 0 as an element of E. Expand determinant d gets relation. Pick M free module, I = A, this is Cayley Hamilton theorem. f(X_ = det(X d_ij - a_ij)

Nakayama’s lemma via determinant trick: set p = 1, so a = 1 + a1 up to an = 0, aM = 0, a 1 mod I, if I is in radical of A, then a is a unit of A (invertible element), multiply both sides of aM being 0 by 1/a gets M = 0.

Minimal basis: set of generators which no proper subset generates the module.

Simple module: no submodules other than 0 and M itself. See simple object.

Composition series of M: descending chain of submodules M0 contains M1… contains Mr = 0 if every M_i / M_{I+1} is simple, r is length of composition series, if composition series exist, length of M is invariant corresponding to Jordan-Holder theorem in group theory.

Module of finite presentation: exists exact sequence of A^p to A^q to M to 0, generated by q elements with linear relations of sum a_i w_i = 0 for (a_1 to a_q) in A^q holding between w_i generated by p elements.

Subrings of Noetherian ring and Artinian ring need not have the same property: Q is artinian not Z. By Hilbert’s basis theorem k[x,y] is noetherian but {xy^g, g >= 0} is not finitely generated over k, chain of ideals is (xy) in (xy, xy^2, xy^3). This also show the power of Hilbert’s basis theorem and the idea in generating polynomials that can be recursively defined to have the correct degree.

Exact sequence of Noetherian and Artinian A-modules, middle term is Noetherian and Artninian: suppose 0 to A to B to C to 0 is an exact sequence of modules, A and C Noetherian implies B Noetherian, proof in Matsmura by applying infectiveness of natural map.

Artinian ring is Noetherian: prove A has finite length of A-modules. It has finitely many maximal ideals, if not just take descending filtration of products p1 in p1p2 in p1p2p3 contrary to Artinian. Finite set of prime ideals, set full product as radical of A, descending chain stops in finitely many steps, so there exists end of ideal chain I^s  =  I^{s+1}, then consider length of chain of M/p_i M for sequence A in p_1 in p_1 p_2 terminating in I in I p_1 in I p_1 p_2 all the way to I^s =  0, this chain is finite so sum l(A) of these terms is also finite.

Extended ideal: f from A to B in ring him, I ideal of A, J an ideal of B f(I)B is extended ideal of I to B, J intersect A for f^{-1}I of a is contracted ideal of A. Extension and contraction are adjoints in this sense I^{ec} in I, and J^{ce} in J. This is canonical bijection.

Primary ideal: all zerodivisors of B/J are nilpotent. Passes of subrings, Contraction of primary ideal is primary, radical of primary ideal is prime ideal.

Height of prime ideal: dimension of localisation at prime ideal p.

Coheight of prime ideal: dimension of quotient of A by prime ideal p.

Dimension of A inequality: height + coheight is less than or equal to A.

Saturation of prime ideals: strictly increasing or decreasing chan of prime ideals is saturated if there are no prime ideals strictly contained in consecutive terms.

Catenary ring: for any prime ideals p and p’ p in p’, there exists a saturated finite length chain of prime ideals starting from p ending at p’, all such chains have same finite length.

Prime divisors of an ideal: associated primes of A-module A/I

M-regularity of value: non zerodivisor for M

Zero divisor for module: nonzero x in module such that ax = 0, otherwise it is M-regular.

Associated prime ideal of module: prime ideal that is the annihilator ann(x) for some x in M.

Flat versus faithful: every exacts sequence of A modules then the tensor product with M over Rin A is flat, faithfully flat means this is now iff. Works for long and short exact sequences, right exactness of tensor products reduce this to exact sequences of form 0 -> N_1 -> N. If f is ring homo, B is flat as A-module, then this is a flat homomorphism, B is a flat A-algebra. Localisation is always flat. 

Local homomorphism of local rings: f is A to B ring him of local rings (A, m) and (B, n), it is local how if f(m) in n.

Free module is obviously faithfully flat: F is free, and S sequence of A module, then short exact sequence is just sum of copies of short exact sequence equal to cardinality as basis of F.

Purity of submodules: submodule N of M is pure if 0 -> N tensor E -> M tensor E is exact for every A-module E. Examples: any direct summand of M is pure submodule.

Completion of M from topological motivations: Family of submodules such that for a < b M_a is in M_b indexed by directed set, take this as system of neighbourhoods of 0 so now M is a topological group, this is a linear topology and is Hausdorff if intersection is 0, and M/intersection of M in index is separated module associated with M. Inverse limit of this sequence from M in M_1 in M_2 … is the completion of M. Completion is motivated by topology. M/M_i is discrete in subspace topology, M_i is clopen, M - M_i is union of cosets so is open so M_i is closed. M_i in M is open. Topology defined by I^nM as a topological group is called the I-adic topology, completions of it is I-adic completions. Motivation is similar to P-adic completions.

I-adic completion lemmas: there is the Hensel’s lemma  to prove finiteness of module and Artin-Rees lemma and KRull’s intersection theorem, all of them are motivated by I-adic considerations.

Zariski ring with ideal of definition: ring where every ideal of A is a closed set, I in rad(A), I-adic completion A’ of A is faithfully flat, where A has the I-adic topology. Noetherian local ring with m-adic topology is a Zariski ring.

Extension ring of A: if A is a subring of B, B is an extension ring of A, defines extension object.

Integral extension ring: let B be an extension ring, if every element of B is integral over A i.e. b is root of monic poly with coefficients in A, then B is an integral extension of A. 

Integrally closed domain: let A be integral domain, integrally closed in field of fractions A/p

Normal ring: for every prime ideal p of A localisation A_p is integrally closed.

Valuation ring: integral domain R such that every element x in its field of fractions satisfy x not in R implies x^{-1} in R, or R^{-1} set of inverses of nonzero elements, union of R and R^{-1} is field of fractions. 

Trivial valuation ring: integral domain is equal to field of fractions.

Zariski space: set of valuation ring of a field

Valuation ring centre: valuation ring R of field A contains A in field K as a subring, we say R has a centre in A, prime ideal m_R intersect A is center of R in A.

Value group: ideals of valuation ring formed total order under inclusion for ideals and R-modules, give G opposite order given by inclusion, this is an abelian group (xR)(yR) = xyR, adding infinity and stuff and a homomorphism called the value group of the homomorphism from K* to subgroup H. These are value groups (need better definition then in Matsumura.

Discrete valuation ring: valuation ring whose value group is isomorphic to Z. Discrete refers to elf act that the value group is a discrete subgroup of R, not to dow with m-adic topology of local ring being discrete. Used to define Krull rings.

Dedekind ring or Dedekind domain: integral domain for every nonzero ideal is invertible. 

Regular local rings by Serre: Noetherian local ring of finite global dimension.

Idea of Noetherian normalisation: coordinate change of x1x2 - 1 not finite over C[x1] to become finite with coordinate change x1 = y2 + y1, x2 = y2 - y-1 using a C[x]-algebra homomorphism.

Filtered ring: definition in Serre, is a ring with family of ideals A_n filtered in Z satisfying: A_{0} = A, A_{n+1} is in An ApAq in Ap+q. This gives ring structure onto the filtration.

Filtered module over filtered ring: A-module M with family of submodules for filtration to make it into a ring, M0 =  M, M_{n+1} in M_n BUT A_p M_q  =  M_{p+1}

Filtered modules form additive category (NOT AN ABELIAN CATEGORY): important point, homological algebra applies, morphisms are A-linear maps u from M to N where u(M_n) in N_n. Therefore injective and surjective morphisms are usual, kernel and cockerel exist with induced filtration. There exist bijective morphisms that are not isomorphisms.

Induced filtration on submodules of filtered module: if P (probably because projective) is A-submodule of filtered module M, induced filtration on P is filtration P_n defined by intersections P_n =  P intersect M_n.

Quotient filtration: let N = M/P be quotient of filtered module with module P, filtration (N_n) where N_n  =  (M_n + P)/P is in image of M_n. Careful for notation, this does not mean localisation.

Primary decomposition theorem: every submodule can be written as intersection of p-primary submodules Q(p) of M, when p is the associated prime ideal of Ass(M/N). This generalises prime factorissation into unique p-primary submodules or making it from primary components.

Embedding of module M to limit of E(p) for p associated prime of M: E(p) is defined to be the case where Ass(E(p)) = p, for every p in Ass(M). Use analogy in case of Z that module is composite number ideal, p is prime number in primary decomposition of of the module, and E(p) has unique associated prime, and is product of (p) some how i.e. E(p) is some sort of p prime power ideal.

P-primary submodule of M: let p be in th prime spectra of A, submodule Q of M is called a p-primary submodule of M if Ass(M/Q) = {p} or the set of associated primes of quotient module M/Q oney has that p primary submodule.

Associated primes, is in set of prime ideals {p_1 to p_m} of increasing sequence of submodules M0 = 0, Mn = M and is in support of M, with the same minimal elements: consider prime ideal in spectrum of ring A, the localisation is nonzero if and only if one p_i is contained by the prime p_i, so the support of M contains prime ideals of sequence, same minimal elements. If prime ideal is in associated prime of module M, module M contains submodule N isomorphic to A/p, N intersect M_i is nonzero if m is in this intersection then module Am is isomorphic to A/p_i, so p = p_i so Ass(M) is in {p_i to p_n} at least. Finally if p is minimal element of Supp(M , support of localisation of M at p is reduced to unique maximal ideal pA_p of A_p, note that Ass(M_p) is nonempty and clearly in Supp(M_p) so pA_p is in Ass(M_p), and Ass(M_p) is compatible to localisation, so pA_p is in Ass(M), and support and Ass(M) share same minimal elements. Work through Serre Theorem 1 in Local Algebra.

Embedded element: nonminimal element of Ass(M)

Associated primes is finite: proof it is contained in the support of M.

Motivation of associated primes: in Z, decompose composite (n) to associated prime ideals of powers (p_i^d_i), p_i is associated prime, then these prime ideals are primary components, so associated primes generalised unique factorisation to arbitrary rings, increase sequence of submodules due to Noetherian-ness is important, finiteness is important and other stuff… see Harvard notes.

Increasing sequence of submodules M0 to Mn such that Mi / M_{i-1} isomorphic to A/p_i, p_i in spectrum: if M is nonzero, there exists submodule in associated prime isomorphic to A/p_1, p_1 prime, if M1 != M_1, inductively apply same argument to M_2 of M_2 containing M_1 such that M_2/M_1 is isomorphic to A/p_2, so on and so forth, obtain increasing sequence, this is Noetherian, so this sequence stops.

Nonzero module have nonzero associated primes: nonzero modules have maximal element since the ring is noetherian, so there are nonzero associated primes.

Maximal elements of set of annihilators of nonzero elements of module are prime ideals: let P be the set of annihilators of nonzero elements of module M, then every maximal element of P is a prime ideal. Consider nonzero element of module M, whose annihilator p (recall it is the kernel of module of localisation) is a maximal element of P. If xy is in p, and x is not in p, then xm is nonzero, since x is not in annhilator, and m is nonzero, so xm is nonzero. The annhilator of xm contains p (since it is bigger, p does not annihilate xm), and it is therefore equal to p, since p is the maximal element of the set of annihilators of nonzero element say definition. Since yxm =0 as a result of y in Ann(xm) = p, p is prime ideal if p is a maximal element. See Serre Local Algebra Proposition 5. Key step is showing annihilator of xm contains p, maximality gives equality.

Associated prime ideals to a module: prime ideal associated to module TFAE (1) if there is a submodule such that it is the domain generated by the quotient of the prime ideal over the ring (this definition makes sense when you think of prime numbers, and submodules as prime powers); (2) exist element of module of M whose annihilator (kernel of module to localisation) is equal to prime ideal (makes sense if you think of prime in element that makes it vanish) same as Gathmanns definition of associated prime ideal is prime ideal that can be written as root(I:a) for a in ring R is prime. Prime ideals associated to M is Ass(M), these are the associated prime ideals of module M

Natural map from module to limit of localisations for associated primes is injective: suppose M nonzero, there is submodule or maximal ideal m in M nonzero by corollary 1 or associated primes, let ideal be annihilator(m), since m is nonzero, this is proper ideal and not fully A. Let m be maximal ideal containing I, if m is zero in M_m, there exists a in maximal ideal m such that am = 0, contradicting Ann(m) in maximal ideal. Therefore, each nonzero m and ideal M, there exists at least one maximal m such that m is not zero in localisation so map from M to product of localisations of associated primes is injective. Don’t understand motivation of this.

Association is compatible with localisation: let S be multiplicative group closed subset of A, let p be prime ideal such that S and p is disjoint, localise S^{-1} p of S^{-1} A to be associated to S^{-1} M, we need prime p to be associated to M. Proof: let p be associated prime of M, by definition there is a m in module M whose annhilator is P, by definition of annihilator being some localisation, it is the annhilator of the element m/1 in localisation S^{-1}M is S^{-1}p which is in associated prime of localisation Ass(S^-1 M}. For converse, suppose S^{-1} p is annhilator of quotient element m/s in localisation S^{-1}M, m is in M, s is in S, if a is the annihilator of m, then localisation re equal up to prime ideals so S^{-1} a = S^{-1} p so a is in p, implyingg existence of s' in S such that s’ p is in A, so the annihilator of s’m is prime ideal p, and p is in associate d prime of M.

Quasicompact noetherian space: quasicompact means admits filtered colimits mapping out of it, open cover admits finite subcover with diagram indexed by small category. Colimit is cover, filtered colimit is finite sub cover. Hausdorff for full compactness.

Spec(A) of A is quasicompact noetherian space: proof, noetherian gives quasicompactness.

Irreducible component of F: let F be closed subset of Spec(A), every irreducible subset of F is contained in maximal irreducible subset of F, these are closed in F, each subset is called irreducible component of F, this is finite (due to Noetherian hypothesis) union of these is equal to F. Irreducible components of Spec(A) are algebraic sets V(p).

Minimal prime ideals: the prime ideals that span the all irreducible components of Supp(M) are the V(p), Spec(A) has irreducible components V(p), this forms the set of minimal prime ideals of A. Let M be finitely generated prime ideal, with annihilator a (kernel of map to localisation at ideal a). They have the following property: p contains annihilator a, and is minimal, p is minimal of Supp(M), module M_p is zero and is of finite length (fg, support contains only maximal ideals)

Annihilator definition in terms of localisation: kernel of map to localisation.

Support of a module: set of prime ideals such that there is nontrivial localisation under module M so M_p is nonzero. It is a closest subset of the spectrum of ring A, where M is an A-module.

Exact sequence give union of supports: if 0 -> M’ -> M -> M’’ -> 0 is exact sequence, then Supp(M) = Supp(M’) union Supp(M’’), this gives a geometric intuition of spliting, and so unions of closed subsets hint form exact sequences somehow? Proposition 4 in Serre.

Support intersection of quotients: let P and Q be submodules of fg module M, then Supp(M/P intersect Q)) = Supp(M/P) union Supp(M/Q).

Support of tensor products: let M and N be two finitely generated modules, under Isbell duality Supp(M tensor N) = Supp(M) intersect Supp(N), apply the fact that if M tensor N = 0 iff M = 0 or N =  0 to Nakayama’s lemma at localisation Mp and Np which are nonzero by definition of the support, so it must be the support where both M_p nonzero and N_p nonzero. 

Corollary of support of tensor products: Supp(M/tM) = Supp(M) intersect V(t), for M finitely generated A-module, t and ideal of A. Proof: by tensor products, M/tM = M tensor_A A/t. By Nakayama's lemma, both supports are nonzero so intersection. Supp(M) and V(t).

Equivalent characterisation of quotient as tensor product: let M be finitely generated A module, and t and ideal of A, then M/tM = M tensor A/t.

Nonzero localisation of prime ideals (Proposition 3, Serre): consider p prime ideal of A, TFAE M_p nonzero and p in V(a). Suppose M finitely generator, annihilator of A_p module M_p is a_p so p is in V(a). The set of p in Spec(A) is the support of module M, closed subset of Spec(A).

Not leaving commutative algebra: I realised prime spectrum is set of prime ideals, so you haven’t exactly left commutative algebra when you are doing algebraic geometry. Common misconception about dualities, you are simply using intuitions and structures from geometry to do commutative algebra when doing algebraic geometry.

Nakayama’s lemma history: it came from Krull and Azumaya based on what Nakayama said.

Typical residual class ring and quotients: ideal, so quotient is residue class ring, prime ideal, so quotient is domain, maximal ideal, so quotient is field.

Results on spectrum: spectrum is set of all prime ideals, consider a is ideal of a, then set of p in Spec(A) such that ideal a is in prime ideal p is the variety on from ideal a denoted V(a) [this is abuse of definition, this isn’t a variety, merely the Zariski closed sets]. By Isbell adjunction, intersection of ideals becomes union of varieties. Spec(A) is noetherian if A is noetherian, increasing filtration of opens stops or is absorbed. If F is nonzero closed set in spectrum, then F is irreducible or nonunion of two closed sets distinct of F and there exists prime in prime spectrum such that F is the variety generated by a prime ideal or F is the closure of prime ideal.

Radical of ideal: set of x in comm ring A, existing n(x) >= 1 such that x^n(x) in a is an ideal called the radical of a.

Serre’s noetherian module:  module is noetherian if TFAE: (1) ascending chain of submodules stops/filtration absorbs indefinitely; (2) nonempty family of submodules of M has maximal element; (3) all submodules are finitely generated, so submodule and quotient modules are noetherian.

Serre’s noetherian ring: ring is noetherian if it is neoetherian module as a self module TFAE: (1) ascending chain of ideals stops or as indefinite absorbing filtration; (2) nonempty family of ideals has maximal element; (3) all ideals finitely generated, so poly rings and formal power series over the ring are also noetherian.

Finite length module: module has finite length if it has Jordan Holder sequence. For noetherian case, module is finitely generated, support only has maximal ideals.

Serre’s definition of prime ideal: quotient of commutative ring with prime ideal is domain. A domain is defined to be embeddable in a field.

Serre’s definition of maximal ideal: ideal, quotient of commutative ring with maximal ideal is a field and is distinct from the ring

Semilocal ring: set of all maximal ideals is finite. Leads to local ring with unique maximal ideal. Local ring is motivated by A - m =  A* to define multiplicative group of invertible elements.

Multiplicity of an ideal of a local noetherian ring with respect to a finitely generated A-module E: coefficient n^r / r! In the polynomial light function from n to the length_A(E/q^nE). This definition lets you define the multiplicity of the homology modules of the Koszul complex constructed on E, this can be used to study local algebra.

Jacobson radical: intersection of all maximal ideals. Motivation 1-xy invertible for every y in A means x is in Jacobson radical.

Nilradical: intersection of all prime ideals. It is naturally contained in Jacobson radical. All maximal ideals are prime (fields are stricter than domains)

Nakayama’s lemma (Serre’s proof): let M be a finitely generated A-module, and q be ideal of A in Jacobson radical r of A, if smallest submodule by a product of q qM = M i.e. idempotent action on M, then M is 0. Or simply, if an ideal in the Jacobson radical is an idempotent action on a A-module to generate the submodule, the A-module must be zero. Suppose module is nonzero, it has a quotient which is a simple module isomorphic to field generated by the maximal ideal, then mM is clearly not M, which is contrary to the fact that the ideal is a subset of the maximal ideal. Fails for say (2)Z = Z, cannot be killed by odd integers, so you need Noetherian hypothesis.

Nakayama corollary on N + qM: if N is submodule of M, such that M = N + qM, and q is contained in Jacobson radical, then M is equal to M. Apply Nakyama’s to qM.

Localisation (Serre), an defining annihilator using localisation: S^{-1}M is the set of fractions m/s, using identifications s’’(s’m - sm’) = 0 as existence condition. Maps A to S-1M and M to S-1M is natural with fractions a to a/1 and m to m/1. Kernel of map to localisation defines the annhilator of Ann_M(S) set of m in M such that there exists s in S where sm = 0. Prime ideals of localisation are the same ideals after localisation.

Flat by Serre: A-module F is flat if M -> F tensor_A M is exact.

Local ring as localisation: let p be prime ideal of A, take S to be complement A - p (another definition, this must be multiplicative group) then localise A_p and M_p, local rings with maximal ideal pA_p and pM_p. If M nonzero, exists prime ideal p with M_p nonzero. Generally, if N submodule o fM, x is element of M, x is element of N iff it is locally where image of x in M_p belongs to N_p for every prime ideal (proof by applying above to (N+Ax)/N, use Nakayama’s).

Set of nilpotent elements as characterisation of Jacobson radical, definition of reduced ring: suppose x is non-nilpotent element of ring A, take multiplicative group to be set of powers of x (think of torsion), then localisation at multiplicative group is nonzero, therefore has a prime ideal that does not contain non-nilpotent x. Therefore, intersection prime ideals of A (Jacobson radical) is set of nilpotent elements of A. So if Jacobson radical vanishes, ring is reduced.

Nakayama corollary on vanishing of tesnor products: if A is local ring, M and N are finitely generated A modules, then tensor product vanishing means M is 0 or N is 0. Proof: m be maximal ideal, by definition k is field A/m, set quotients M’ = M/mM and N’=N/mN, if tensor product vanish, M’ tensor N’ vanish, so either 1 is zero by Nakayama M is 0 or N is 0.

Definition of Tor in terms of free resolutions: consider comm ring R, and M with N, R-modules. Then we have the free resolution F_{i+1} to F_{i} to … F_{0} to M to 0 as a free resolution of the module M as an R-module, form complex with tensor of M, the Tor_i^R(M, N) is equal to the kernel of the F_i ** N to F_{i-1} ** N, image of F_{i+1} ** N to F_{i} ** N, where ** denotes tensor product in N.

Example of flatness of vector space over residue field: let the coordinate ring S = R[x] / (x^2 - t), fiber over prime ideal (t - a), with nonzero a in field k, then it is isomorphic to the Cartesian product k^2 with k[x] / (x^2 - g), fibre over ideal (t) is k[x] / (x^2), t - t so f = 0 when you consider fibres over the ideal (t), fibre over (0) is k(t)[x] / (x^2 - t) field of degree 2 over residue field, k((0)). Over each prime, the fibre over prime ideal is a vector space, dimension 2 over the residue field k(p), free R-module on generators (1 + x^2), prove by showing ax^2 + b = 0, this means a = 0 and b = 0.

Example of facilities with differing properties: take a family of curves xy - a = 0. Hyperbola is smooth to a singular union of two lines. This fails to be locally trivial at a = 0.

Residue field of a ring at prime ideal P over point p: this corresponds tho a localisation at point p.

Locally trivial: in manifolds, take the neighbourhood U of a topological space X, the open set U is isomorphic to a family phi(U), where phi is a fiber from the topological space X to base space B

Separated morphism: map to fibre product over base scheme is a closed immersion under Zariski topology. Scheme is separated if morphism is separated over base scheme Spec Z. 

Diagonal map as characterisation of Hausdorff: draw spaces as lines X and X, diagonal is diagonal line, consider neighbourhoods U, V of points (x,y) projected down to X and X lines as axes. If diagonal is closed where you have closed neighbourhoods as a block in the space, then you can find open neighbourhood of the U x V in the space, so U and V is Hausdorff

Diagonal morphism recycled in line of double origin being not separated scheme: draw line of double origin in Zariski topology, looks like two horizontal and two vertical copies of affine line, consider diagonal morphism, should have two points out of the four points, there are two additional points not cutting the diagonal in the closure of the diagonal map, so maps to fibre product under Spec Z is not closed immersion!

Separable morphisms are not separable schemes: consider separable morphism between line of two origins to line of two origins, the morphism is identity map, so this is a separable morphism of schemes.

Quasi-separated morphism: if the image of the diagonal map to fibre product of schemes is quasi compact, need some screwy example with ring of infinitely many generators for this to work. Noetherian schemes are quasi-separated schemes after all.

Motivation for Tor: universal coefficient theorem to construct homology, end of exact sequence contains Tor. Next other motivation for Tor is constructing exact sequences, Tor appears on start of seance when you tensor by M. 

Tor comes from chain complexes: take homology group of complex, for it to be defined at a particular abelian group, then tensor product with the abelian group is done first, then you take homology of that.

Tor is derived tensor product so the answers are kinda obvious: Tor(Z, G) is 0 for Z integers since Z is the prototypical group, Tor(Z/mZ, Z/nZ) = Z/(m,n)Z which is just like tensor product and we also have Tor(Z/mZ, Z) vanish for all finitely generated abelian groups. Recall you can make fg ab groups into direct sum of cyclic groups. Just think of it is tensor product the results should look similar, in fact you can try with direct sum of abelian groups, it will work. Strangely Tor(G, K) is isomorphic to Tor(K, G) in general, but this is rather mysterious. However, this is not a natural isomorphism between Tor and tensor product, depends on choice of generators.

Affine space of plane curve to demonstrate moduli space and flatness: idea is family is just a morphism or a fibre, take B to be the affine space of polynomials sum of (a_ij)(x_i)(y_j) in Einstein notation, then consider dimension to be (n+1)(n+2)/2, take affine N+2 hyperspace with coordinates x y and {a_ij}, now consider projective morphism from this N+2 hyperspace onto the original space B. Consider subspace X this sum = 0, this is a subspace of the total space affine N+2 space. Restrict this projective morphism to morphism domain X, the fibre is a plane curve whose equations corresponds to that point. WARNING, you can instead end up with planes = 0 aka trivial solutions that are not points. This is a powerful example, and one can generalise to various other ways of thinking since families varying under parameters are everywhere.

Bad definition of families of algebras parameterised by prime ideals: let S be an algebra over ring R (so R equipped with ring homomorphism) for every point define fibre translated via Isbell would give maximal ideal to be defined as for maximal ideal P in S (R/P)-algebra (S/PS), for arbitrary primes i.e. irreducible varieties we have quotient field K(R/P), so it is K(R/P) tensor S as a K(R/P)-algebra, recall that the quotient field is generated by the localisation of the whole ring - prime ideal of the multiplicative closed subset. Now you have R[x,y] / sum (a_ij)(x_i)(y_j) as algebra of plane curves. Fro good definition, you want flatness of S as algebra over R-modules, this way the K(R/P) tensor S has monomorphism preserved from the quotient field K(R/P). This monomorphism is for topological reasons, consider the fibre parametrising the family, then consider affine neighbourhood of point U, and affine neighbourhood V of pushfoward/preimage of fibre of point p(x) such that the fibre restricts to a map from U to V. This can only work if on some level the tensor product preserves monomorphism.

Flatness of modules: criteria is done by measuring the amount of torsion with the derived functor Tor. This is how you remember Tor is useful for flatness, and Tor is useful on tensor products. Motivation for derived functors.

Fibres for parametrisation in base space: idea is you have variety, fibres are presages of points, now you have families that vary because of points. Construct moduli spaces and then you can classify all sorts of stuff.

Subspace of Y under subspace topology is Hausdorff if total space X is Hausdorff: Y is isomorphism classes of monomorphism under inclusion into X, points in X are separated by disjoint neighbourhoods that are open in X, these are open in Y by intersection with Y (finite intersections are open). Using the fact that under subspace topology, these are open in Y, so pairs of points in Y is separated by open neighbourhoods in X.

Abelian group of homomorphisms of M to N as R-modules: these are the internal hom of category of R-module homomorphism, these are commutative groups since [rk]m is either r([k]m) or k(rm) by function composition and k in the abelian group of Homs. Did not know the Hom functor can form abelian group. Hom preserves kernels and is left exact. This means Homs in R from module M to fixed object is exact.

Flatness on subobject: isomorphism classes of monomorphisms induced by tensor product can be made, subobjects are preserved by tensor product if there is flatness.

Flatness of modules: if for every monomorphism of R modules, the induced map on tensor products with F is again a monomorphisms. Alternatively flatness is the condition such that when tensor products preserve right exact sequences, tensoring with flat module on left preserves all exact sequences and all kernels and cokernels. Most interesting case is when flat module is an R-algebra (hint can use this ring homomorphism in defining the R-algebra to good use)

Localisation of Noetherian ring is Noetherian: proof follows from ideal I in localisation is a equal to preimage of localisation of functor * localisation, ideal is generated by images in localisation with generators in preimage of localisation functor of I, since R is Noetherian, this preimage of localisation functor of I is finitely generated, so ideal in localisation is finitely generated.

Ideals coincides with extension of its contraction: ideal of localisation is extension of ideal in localised ring, this is Eisenbud 2.2, use statement 1 to show that ideal is localisation of its extension (show on natural map, apply forgetful functor to show preservation of intersections, inclusions as it preserves limits, then primarily follows by domain checking arguments), for the second part check that multiplicative closed subset act as nonzero divisors of ring / ideal… need some computation here I don’t get it.

Formal duals of localisation maps from Spec(RS-1) to Spec(R) with localisation functor R to RS-1: example of standard open immersion of forming Zariski topology in algebraic varieties.

Localising with Isbell adjunction: restricting it to the complement of subspace Y included into X such that elements of S vanish when you localise at S, this looks like zooming in onto the space, but only seeing the surroundings. So you only see what is nearby in neighbourhood but not what the object is, compare this quotient where you see what is inside the thing, everything else vanish. In commutative algebra side, it means the relation is equal and made zero, in geometry it means what you see is left because that is the curve = 0. Isbell adjunction visual gives the name of localisation.

Preimage of localisation functor (map from ideal I to preimage of localisation of ideal I) is injection of ideals of localisation to ideal itself preserving inclusions, intersections, and prime ideals: ideal is contained in the localisation, reverse inclusion, consider quotient r/u in I, r in ring, u in multiplicative closed subset, r is obviously in localisation. Preservation of inclusions and intersections since this operation works on the map of sets, applying forgetful functor on localizations, localisation induced injection between quotient R/preimage of localisation I to S/ full I. If I is prime ideals, S/I is a domain, then quotient of R by preimage of I is a domain, so preimage of I is prime.

Domain vs integral domain: domain is ring has no nonzero divisors, integral domain is just commutative domain

Universal property of localisation: now that I understood that presentation exact sequence by generators and relations, the universal properties follows by considering the adjoining of inverses in the freest possible way( then have uniquely defined extension.

Localisation of morphism: I was thinking if you can define localisation object, it is a morphism of residue field-modules given a map of ring-modules. Localisation is a functor from ring modules to residue field modules. If the ring-module is finitely presented or in the exact sequence of presentation F to G to M to 0, where F is the relations is a finitely generated ring module, then every homomorphism is preserved under localization. Direct sums and tensoring is preserved by localisation, tensoring preserves direct sum as left adjoints preserves colimits.

Local ring in terms of prime ideals: it corresponds to the residue class field of the ring at the prime ideal that vanishes at x, or you invert the set ring - prime ideal that vanishes at x to get all the stuff that do not vanish at maps.

Prime ideal in terms of multiplicative closed set: ideal is prime if ring - prime ideal is multiplicative closed set. This definition is very powerful, I was just wondering if we can generalise this to prime objects, where prime object is a subobject such that the quotient object of monomorphism classes preserves limits in some sense. Anyways this definition of prime ideal makes the definition of the residue class field of R at P obvious, it is the localisation at ring - prime ideal.

Total quotient ring: consider any ring (need not be commutative), take localisation at multiplicative closed set of nonzero divisors 

Quotient field of integral domain: localise at R - (0) for 0 in ring.

Graded module: module with decomposition indexing by the integers as abelian groups such that RiMj is in M(I+j) for graded ring

Motivation behind graded module: action of group on linear forms of poly ring see how dimension of space of invariants vary.

Hilbert function: function that gives dimension of decomposition of graded modules when you put an index.

Hilbert polynomial: idea is if you have finitely generated graded modules with r generators, the Hilbert polynomial agrees for large s with a polynomial of degree less than r. Small s, need to be careful about cohomology groups and Euler characteristics. The Riemann Roch theorem is the computation of the Hilbert polynomial for a certain class of modules. The data in Hilbert polynomial is presented in Chern classes.

Nullstellensatz with projective varieties: projective varieties correspond to radical homogenous ideals excluding the irrelevant ideal. Apply Nullstellensatz but you just need radical of homogenous ideals is homogenous. Proof, consider lowest degree component of sum of homogeneous ideals, subtract it from any f in radical ideal, each homogenous component of f is in radical of f, so radical of f is homogenous.

Projective varieties in algebraic varieties: these are the conical algebraic sets in affine (r+1) space.
 
Projective closure: smallest projective set intersecting affine n space of interest. I realise this is a sort of limit, very interesting.

Quotient space cannot be made into variety: take set of orbits of affine line, fails because set of orbits is nonzero points and zero or two points. See discussion on Eisenbud page 38.

Geometric invariant theory basic idea is to try and approximate quotient space with some algebraic variety or scheme.

Closure in topology: Union of limit points and topological space. All neighbourhood of limit point contains point in topological space

Nullstellensatz categorically: category of reduced affine varieties with morphisms regular maps over algebraically closed k is formally dual to the category of affine k algebras with arrows reversed.

Quotient space: apply definition of quotient objects set of orbits with natural projection (some sort of limit) taking elements to their corresponding orbit.

Nullstellensatz as a prototype for duality: adjunction between formation of algebraic set and idealisation is equal to radical ideal. So in some sense there is imperfection in the duality since I(Z(I)) = rad(I) so it is an equality in duality up to radicalisation. If it is a perfect correspondence then a(b(a)) = a which makes an and b identity and inverse of each other in some sense. Need reduced, finitely generated and algebraic closed hypothesis.

Maximal ideals are points: by Nullstellensatz, nothing smaller than a point so it is truly maximal. Relations are purely due to polys.

System of poly has no solution if linear combination of poly is 1: proof is by Nullstellensatz, algebraic set forms empty ideal by hypothesis; then 1 must be in radical ideal formed by generators of polys. Converse is obvious if equal to 1 then no solution by linear algebra.

Homogenous element: element of abelian groups in direct sum decomposition of graded ring

Homogenous ideal: ideal generated by homogeneous elements.

Homogenous components of f: decomposition of poly in graded ring,

Rational representations: entries in representation of special linear group are rational functions.

Fermats last theorem to motivate ideals: you want unique factorisation, so you make ideal elements of the ring, so ideals are generalisation are primes, unique up to multiplication by units, since unique factorisation is up to units anyway.

Modules from adjoining roots; adjoining root of polynomial f(x) = 0 to field k

Primary decomposition as unique factorisation: Lasker’s generalisation of unique factorisation which was very powerful in linear algebra with nonnegative dimension.

Relations to form quotients for presentation: same logic as making equivalence classes recall if you have polys fi vanishing on generators, then you have fi g = 0 so the quotient module is R/(fi) for finite fi; one can do an exact sequence view instead, see Eisenbud page 17, element m corresponds to homomorphism from R to M sending 1 to m, now make many copies of R^A as direct sum called G where A indexes the generators, the relations are kernel of maps from G to M, this is a homomorphism of free modules, now you can generate the free module F = R^B for B indexing of relations, let F be the kernel of the map to generators G to the module M to 0. This sequence is exact, and is called the free presentation of M because you made free modules out of the generators and relations, if indexing sets A and B are finite, F and G are finitely generate free modules, then this is a finite free presentation, it is finitely generated if A is finite set, it is finitely generated in B is finite set.

Rank or finitely generated free module: number of copies of the ring used to form the fg free modules.

Annihilator of a modulo I: consider ring element a, I in R an ideal, we have map from R/I to R/(I+(a)), kernel is generated by one element so forms R/J, J is the annihilator of A modulo I, so there must s an exact sequence 0 to R/(I:a) to R/I to R/(I + (a)) to 0.

Ring of symmetric functions: take symmetric group and act it on poly ring, containing elementary symmetric functions.

Krull intersection theorem: (1) corollary: for Noetherian maximal ideal, intersection of powers of ideals is 0. Counterexample if not Noetherian would be 2-adic integers; (2) let A be Noetherian ring, I and ideal of A, M a finitely generated A-module, then the intersection of I^n ‘ are elements such that there exists a in I where (1+a)x is 0, x is element in module.

Analogy between spectra and derived category: spectra is analogous to derived category of Z. Motivates homological algebra.

Analogy between spectra and algebraic topology: spectra is the cohomology theory of CW complexes.

Spf of homotopy group functor: it is the direct limit of the spectra of the homotopy groups of spheres R^{CPinfty} where.

Example of single object generation in derived categories: derived category D(Z) is generated by the integers Z, there is a symmetric conoidal structure with unit.

T-structure with heart is analogous to abelian groups: consider example of homology functor from the derived category on Z to abelian groups, for the homotopy functor from spectra to abelian groups, this is the homotopy group functor so Z is in the heart of the derivaed category of D(Z), but the sphere spectra is not in Sp^heart.

Formal group over ring R: related to the formal scheme over Spec R equipped with abelian group structure such that it varies Zariski locally on R.

Grothendieck rule for defining properties of schemes: learn all these tricks, then recycle definitions define properties of schemes either on (1) underlying topological space, (2) property of structural sheaf, (3) for Y-scheme, then structural morphisms of schemes, (4) ring Homs on structural sheaf; (5) structural sheaf of points for stalkwise/germ properties; (6) structural sheaf of open neighbourhoods or open covers for local properties; (7) modules over structural sheaf of opens; (8) using isomorphism classes of sub schemes or affine subschemes. This is also useful in making definitions, using suitable forgetful functors to have definitions agree on the forgotten structure, or to define it on the structural morphisms to form algebras, define it on points for completeness, or define it on open neighbourhoods if you want locality.

Spec is continuous for ring hom A to B: Spec is contravariant on varieties of ring hom, represented by inverse function, since preimage of variety generated by ideal in B is equal to variety of ideal in A so is continuous. If ring hom is surjective, this is homomorphism since it becomes a continuous bijection, if continuous bijection then the preimage mapped is the variety generated by the kernel of the ring hom. See Qing Liu chapter 1, 2.1.7

Spec is homeomorphism onto intersection of localisation if we consider localisation of ring Hom: the proof does not make sense to me algebraically, but it makes sense to me geometrically, you are localising at the point, so it is the subspace where the prime ideal intersects the ideal S. See Qing Liu chapter 1, lemma 2.1.7

Radical ideal equal to intersection of prime ideals in variety of ideal: radical ideal belong to intersection by definition if you consider products of ring elements, the other round of the intersection replace A with A/I assume I is 0 then V(I) is prime spectrum, now show I is nilpotent, consider localisation at non nilpotent f for contradiction, induced prime ideal in Spec A such that f is not prime ideal, contrary to belonging in intersection. Or alternatively use binomial theorem?

Reversal of containment of varieties: say variety generated by I is contained in variety generated by J, then J is in the intersection of ideals of I since radical ideal equal to intersection of prime ideals. See Qing Liu 2.1.6

Integral ring Hom: a ring homomorphism is integral if every element is integral over homomorphism domain where monic poly in poly ring in homomorphism domain vanishes under the action of the ring Hom in codomain. 

Integral condition on schemes: a scheme is integral of structure sheaf in any opens is an integral domain.

Integral at point of scheme: a scheme is integral at point x if local ring due to structural sheaf at point is reduced and has a single irreducible component passing though the point.

Krull dimension of scheme: supremum of chain of irreducible closed subsets of X in underlying topological space of scheme. Empty set has negative infinity dimension by convention. 

Purity of Krull dimension: all irreducible components of underlying top space of scheme had pure dimension of the Krull dimension if the share the same supremum of irreducible closed subsets.

Codimension of closed subset in topological spaces: infimum of codimension in X of irreducible components.

Finiteness of A-algebra: A-algebra is finite over A0 if it is finitely generated as an A0-module.

Noetherian local ring properties if Krull dimension 0: local ring has maximal ideal is nil radical, torsion of maximal ideal gives 0, and this is Artinian local ring as well.

Noetherian normalisation lemma: for nonzero fg algebra over field k, exists nonzero d and injective homomorphism of poly ring in field k of d generators into A, proof by defining the algebra as quotient of poly ring and some ideal, induct over n to d generators, using integral condition to arrange for a monic poly to be made using S_(n-1) variables, this canonically induces a injective homomorphism from poly ring over n variables by induction k[S]/(I intersect k[S]), with finitely many terms due to finiteness condition. 

Quotients of fg algebra over maximal ideal for field k is finite algebraic extension: proof, Noetherian normalisation suggests finite injective Hom from A0 to A/m, A0 is poly ring of d variables, suppose d more than 1 for contradiction where A0 is a poly ring and not the field, consider integral equation for 1/T1 for case d=1 this is invertible in A0 which is a poly ring so 1/t is a possible variable in A/m since A/m is a field which is the key step, this is impossible because poly (cannot have negative power), so A0 is a field only and not a poly ring, and A/m is finite over k, or a finite algebraic extension of k.

Closed point of Spec A: consists of maximal ideal

Principal open subsets: let f be poly in A, it is open subsets of the exclusion Spec(A) / V(fA)

Sheaf definition in terms of descent of complexes: Qing Liu has this nice definition for sheaf if you have complex of modules U with presheaf F, consider complex of right R modules from presheaf if U to limit if single indexed family open to to limit of presheaves of open intersection, the presheaf is a sheaf if this complex is exact.

Section agreeing in terms agree in whole section: Qing Liu likes to wlog t = 0 then all germs of sections s on x is zero, open covers as x varies (subtle use of fact that this is colimit) so colimit is 0 or s = 0

Isomorphism of morphism of presheaves if it isomorphic on the level of germs; use the same trick on vanishing of germs, then use sheaf descent on intersections, see Qing Liu 2.12

Sequence of sheaves is exact if it is exact on stalks: follows from the fact it is an abelian category and complexes make sense.

Structure sheaf: sheaf of rings endowed on a topological space, where each point on the topological space is a local ring with unique maximal ideal

Affine scheme: topological space to be some spectrum of a ring, the structure sheaf to be structure sheaf of that ring.

Schemes and open subschemes: ringed topological space on open covers such that pairs of structure sheaf and open covers are also affine schemes. Open subsets of schemes are schemes because of this definition called the open. Likewise for affine open subset of schemes are also affine schemes

Morphism of ringed topological space: consists of continuous map (much like def of ring homomorphism) in the level of topological space and a morphism of sheaf of rings that is contravariant such that stalks are local homomorphism on maximal ideals. Morphisms of schemes are morphisms on the level of ringed topological spaces so that is why this is important.

Open immersion of schemes: respectively closed if morphisms of ringed topological spaces are isomorphisms (for every point in top) and an open immersion for the continuous map in question.

Residue field: the quotient of the structural sheaf with its maximal ideal associated with the local ring.

S-scheme or scheme over S: scheme endowed with structural morphism, same definition as algebras but over schemes. 

Projective schemes: fix ring A, consider graded A-algebras over direct sum of free A-modules B graded (see definition of projective module), now associate this with a projective module. Define a scheme over this algebra to get projective schemes.

Noetherian scheme: a scheme is Noetherian if it is finite union (colimit) of affine open such that structure sheaf of affine open is Noetherian ring.

Locally Noetherian scheme: a scheme is locally Noetherian if every point has a neighbourhood that is a Noetherian subscheme. Local ring of Noetherian schemes is Noetherian is trivial by definition, similarly for affine opens, use finite unions and Noetherian property so structure sheaf is also Noetherian.

Affine variety in terms of affine schemes: affine scheme associated with the finitely generated algebra over an algebraically closed field k.

Reduced scheme at point x: a scheme is a reduced scheme at point x if structural sheaf at point x is reduced ring with 0 as only nilpotent

Reduced scheme: a scheme is reduced if it is reduced at every point x

Irreducible scheme: a scheme is irreducible if underlying topological space is irreducible where disjoint unions of closed subsets implies one of them must be the whole spaces.

Noetherian scheme has finite number of irreducible components: case 2 is cover with finite affine opens, it has finite irreducible, now apply for case where scheme itself is affine, check intersection of prime ideals on affine scheme using Noetherian condition to verify maximal element which is the radical ideal cannot be prime by considering structure sheaf of the Noetherian affine scheme.

Fibres product of S-schemes: define as limit of certain universal property making span diagram commute.

Base change by other S-scheme S, let S be scheme, X an S-scheme, then base change by S’ to S  is second projection of fibre product from X * S’ to S’. Same with base change using tensor products instead of fibre products

Morphism of finite type: if f is quasi compact and the canonical contra variant homomorphism of structure sheaf of affine opens makes the structure sheaf into a suitable finitely generated algebra.

Scheme of finite type: defined if structural morphism is of finite type, similar logic as algebras

Geometrically integral, reduced, connected, irreducible: an algebraic variety is geometrically reduced/integral/connected/irreducible if the associated algebraic variety over its algebraic closure (extension of algebraic variety quotient out by base field) is also reduced/integral/connected/

Frobenius morphism of schemes: morphism of schemes induced by ring homomorphism of structural sheaf from a to a^p for schemes of finite field of order p prime

Separated topological space: topological space is separated if underlying topological space with diagonal map with the product topology is closed

Separated schemes over scheme Y: a morphism f from scheme X to scheme Y made into a fibre product over scheme G is a diagonal morphism of f, scheme is separated over Y if diagonal morphism is closed immersion (motivation of closed immersion!) scheme is separated if separated over integers.

Morphism is closed: morphism of topological space is closed if it maps closed subset of X to closed subset of Y covariantly.

Morphism universally closed: morphism is universally closed if it closes under arbitrary base change.

Morphism is proper: if it is of finite type, separate and universally closed

Y-scheme is proper: scheme is proper if structural morphism is proper.

Conditions of Nullstellensatz: (1) need Noetherian so you can apply poly trick of reducing it to degree = number of generators, so finitely generated or Hilbert basis theorem, (2) need no nilpotents so you don’t have double solutions due to torsion, (3) need algebraically closed so that solutions exist and rules out examples like x^2 + 1 = 0. 

Radical ideal: ideal generated by reduced ring so a^m is in ideal, radical ideals in alg closed field corresponds ideal generated by algebraic set on ideals (double ideal of ideal indicates redefinition of equivalence) give three condition finiteness

Infinite field, only poly that vanishes is 0 or no torsion: basically make a poly of n variables to be a poly of n-1 variables, with the last free variable as terms forming that n-1 poly, consider case of poly in one variable in scalar, there is no way this vanishes of the free variable is nonzero, induction applies to this base case. See Eisenbud page 32 for proof

Subtraction trick in Hilbert basis theorem: start with the axiom of countable dependent choice, pick basis of poly, finite since Noetherian, now suppose there is poly with degree higher than finite number of generators, express it as linear combination of other number of generators with x^(n-m) for m number of generators, reduce it down to zero or derive contradiction on minimality. Same trick can be used to prove definition of submodule being all finitely generated as definition of Noetherian module (subobject obviously preserves Noetherian as isomorphism classes of inclusions as monics)

Cone project down: leave projection

Cocone project down: to leave amorphous mix of projections

Connectedness in topology: homotopy groups up to something is trivial, home out of it preserve coproducts, effective epi from space to terminal object 

Example of connected top space: Homs out of it preserve all coproduct I.e sum of top space. step 1 of proof identity map maps to 0( induction on remaining component either component. Itself or almost 1 due to Hom(X,0) = 0 by induction.

Pointedness: global element and object where global element is formed by morphism from terminal object to object. If terminal don’t exist pick Honeda bending

Context and groups: equivalent to infinity groupoid.

Projective covers as basis: makes sense, projective are direct limits, projective means projections, so really it is a different kind of cover, one that you get by taking products

Pontrjagin duality on finite abelian groups: obviously formal dual if you have abelian and finite compositions of group morphisms, fails for torsion abelian groups since finiteness condition is needed for abelian to work properly, you need some sort of projective conditions for it to work.

Exactness, acyclic, and zero complex: theorem in Weibel that gives condition on exactness where all homology right R-modules vanish.

Split exact sequence of vector space: idea is to decompose into double boundary + homology, so we have C_n = B_n ++ H_n ++ B_n-1, where ++ is direct sum, then make exact sequence that way.

Homology and cohomology of tetrahedron: note that one consider free modules over number of edges, surfaces, then use rank nullity on the incidence matrices to determine kernel and images of differential maps.

Alternative definition of complete category: consider functor category as power category C^I, if I is small, and it preserves limits so C^I is complete.

Additive / abelian categories on monos: very nice to have kernels, monomorphisms and monics be basically the same on some level, see Weibel. Furthermore, existence of 0 object very important, Hom is right adjoint, preserving limits, need something like AB4 i.e. cocompleteness to have direct sums preserved as well.

Total complexes: idea is to have differential maps become anticommutative so that self product of sums of differential maps decompose from (dh + dv)^2 = dh dh + dh dv + dv dh + dv dv. Then do the obvious thing of setting dh dv + dv dh = 0 as definition you get dh dh + dv dv. Note that dh dh and dv dv = 0 due to definition of original chain complexes.

Chain complexes: idea is to just spam differential maps of modules, also cool trick is to define homology as right R-modules in category mod-R and not groups, it is nicer. See Weibel.

Monics and epics equality definition: idea is to have sections unequal under action of epics as retract, or to have retracts unequal under action of monics as sections. Monics and epics becomes monomorphisms and epimorphisms under suitable forgetful functor in set.

Endomorphism monoids: Examples: base of enrichment is commutative monoid, we have endomorphism rigs. If it full abelian groups instead it is endomorphism rjngs. If it is commutative R modules then it is endomorphism R algebra.

Power object: object with monomorphism such that there exists a unique morphism for every other object and every monomorphism into their Cartesian object there is a unique morphism to make the monomorphism is a pullback. If the object of choice is the terminal object, its power object is the subobject classifier. A power object in set is precisely a power set.

Topos: a category with finite limits and a power objects for all objects.

Comma object of a pair of morphisms in a cospan in a two category: object equipped with projections to feet of the cospan and a two morphism that fills this commuting square. Reminiscent of pull backs

Cyclic object: c-valued presheaf in the cyclic category. Definition by Alain Connes

Cyclic category; between simplices and symmetric sets.

Pullback on sets: subset of Cartesian product of two sets.

Pullback as fibres product: consider A and B fibre bundles over base object C. Then a pullback so a product in the category of fibre bundles over C.

Pullback as diagram limit: limit of a cospan diagram, if the limit exists a commutative square is formed and the limit is called the pullback, limits have universal property so are unique up to unique isomorphism.

Pullbacks dually: as pushout in opposite category.

Base change as induced functor: induced pull back functor of over categories.

Connected vs continuous: continuous preserves all small limits, connected preserves all small colimits

Complete category: has all small limits

Cocomplete category: has all small colimits.

Finitely generated object: object in a locally small category whose corepresented functor preserves filtered colimits of monomorphisms 

Fibration: morphism element in a bundle. See definition of bundle as pairs of total base and fibration.

Tensor product misconception: quotient of free product of vector space, with Cartesian product as basis. This is quite subtle. Another misconception, the Cartesian product is contained in the tensor product, false because the identity map on Cartesian products is not bilinear!!!

Exponential object: internal Hom in a Cartesian closed category. Cartesian so that products and multiplications make sense, closed so that internal hom exists.

Closed and internal Hom: internal Hom useful for Yoneda stuff, closed comes from Cayley’s theorem, Hom object group action spam still keeps you in the group.

Differential object: object in a category with translation equipped with a morphism to its translation called the differential. This is a special case of suspensions from one object to one point.

Category with translation: a category equipped with an auto equivalence functor called the shift functor.

Connected object: hom functor out of the object to a fixed point preserves all coproduct. Colimit of connected objects is connected. Example try binary coproducts are bijections if connected, if disconnected then this is not bijective.

Initial object is not connected: so empty space should not be connected

Filtered object: object equipped with a filtration either an ascending or a descending one.

Descending filtration: sequence of morphisms as a graded object.

Free object on C with respect to functor U: an object x satisfiint the universal property F(x) would have if F is left adjoint to U and U is the forgetful functor.

Free cocompletion: passing a category to its presheaf category, by freely adjoining colimits (think freely adjoining) sums. This is the Yoneda embedding.

Interval object: complain diagram with equal feet in the category with I and point any two objects, 0 and 1 are morphisms.

Cartesian interval objects: the feet of the cospan are terminal objects, in categories with finite limits.

Integers object: an object in a Cartesian closed category with a terminal object equipped with a morphism from the terminal object to it and an isomorphism called the successor such that there is a unique isomorphism out of it satisfying some coherence conditions (please fill in details here) as a universal property. Generalise to closed symmetric monoidal category using the tensor unit, that need not be a terminal object.

Internally inhabited: typical example is inhabited set: the unique map to the terminal object is a epimorphism. A set where the statement “that there exists an element in the set is true”. Needed to generalise beyond classical logic.

Enough injectives: every object admits a monomorphism into an injective object.

Enough projective: every object admits an epimorphism from a projective object, or every object admits a projective presentations, or projective resolutions exist.

Universal property of Yoneda embedding: ithe Yoneda embedding of a small category to a small category of presheaves is universal among functors from S to cocomplete categories.

Free cocompletion in enriched category theory: if V a base of enrichment is complete, cocomplete, symmetric(c monoidal closed, and S is a small V enriched category, then the enriched presheaf category is a free V cocompletion of S.

Braided object: an object B in a monoidal category equipped with an invertible morphism a on tensor product satisfying the Yang Baxter equation which is (a B)(B a)(a B) = (B a)(a B)(B a) where composition by brackets is composition and silent composition inside brackets denotes the tensor product.

Yang Baxter equation: algebraic reflection of isotope of braids.

Choice object: object such that axiom of choice holds when making choices from B. A projective object is an object A such that the axiom of choice holds when making choices indexed by A.

Descent object: given a morphism from X^ to X in the category C, it is a p local object where the induced map or the descent morphism, C(X, A) to C(X^, A) is an equivalence. Equivalence means one may be replaced by another in all contexts under consideration. Hence, if you have a context you can form an equivalence class.

Compact object: object is a corepresentable functor from a locally small category that admits filtered colimits to set preserve filtered colimits. Homs out of the object to a fixed object preserve filtered colimits. Example: open cover has finite subcover definition of compactness is generalised here, having finite subcover in this case is having filtered colimits, filtration in subset (or subobject relations)

Pro object: not a projective objects. Consider a small category, consider the Yoneda embedding of the opposite category. This is a full subcategory inclusion if you consider the opposite functor. Objects of this subcategory are pro objects.

Normal subobject: a monomorphisms is normal or conjugate to some internal equivalence relation or it facts through the monomorphism of the internal equivalence relation. Defined based on the fact that a normal subgroup is a kernel of a homomorphism of groups as collections of equivalence classes of the unit to some (necessarily unique by proof) congruence.

Noetherian object: if the ascending chain of subobjects of the Noetherian object is stationary, only finitely many inclusions in the chain are not isomorphisms in C. Exercise, define Noetherian rings, Noetherian topological space, Noetherian categories in the same way.

Locally small object: full subcategory of the slice category on the monomorphism is essentially small. Easier: isomorphism classes of monomorphisms with target A or the subobjects of A form a set.

Colocally small object: locally small object in the dual category. Isomorphism classes of quotient objects of the object form a set.

Projective object: with respect to epis it has the left lifting property, means for any morphisms of projections into an object and epimorphisms into an object the morphism factors through an epimorphism via a left lift diagram. An object is projective precisely if the Hom functor to a fixed object preserves epimorphisms.

Injective object: injective precisely if Hom functor from a fixed object preserves monomorphisms.

Tiny object: hom functor fixing target preserved all colimits / coequalisers, stronger than projective objects.

Suspension object: in an infinity 1 category admitting a terminal object it is the suspension object which is the homotopy pushout. Mapping cone of the terminal map. Dually, there is the loop space object.

Strict ind object: essentially monomorphic Ind object, represented as the apex or colimit of a small filtered diagram.

Strictly pro object: representable as limit or small cofiltered diagram.

Sind object: formal sifted colimit taken in category of presheaves or the free completion objects.

Small object: compact by regular cardinal.

Semisimple object: coproduct or direct sum of simple objects

Simple object: precisely two quotient object, the terminal object and the object itself. If abelian you can use subobject instead of quotient object and you can use a zero object.

Ring object: object in Cartesian monoidal category with addition, zero, multiplicative identity and additive inverse.

Simplicial object: presheaf functor from the simplicial indexing category. Similar definition to a graded object.

Quotient object: it is a coequaliser of an induced pair of morphisms into an object made congruent as an internal equivalence relation.

Lie algebra object: a object in a symmetric monoidal k linear category with braiding such that it is an object and a morphism called the Lie bracket from the tensor product with the equivalence classes using the Jacobi identity and skew symmetry. Braiding is needed here for the Jacobi identity’s

Internalisation example for topological group: a group object internal to the category of topological space is a topological group. The category of topological space must be Cartesian for the unital associative and inverse diagrams to make sense. Ring is monoid object internalised in the category if abelian group, algebra is an internal object internalised to the category of vector space, a strict monoidal category is a monoid internalised to the category of 1-categories. Almost all structures can be internalised in a topos.

Group as representable functor: a group is a presheaf on the category of groups that is representable in the presheaf of sets

Internalisation restrictions: what sort of category is it for example, for example for group objects one need a Cartesian category for unitality, associativity and inverses to make sense, it must admit all small products and not just tensor products.

Boolean prealgebra object: internal to finite complete category (admits all finite limits, lex category), it is a bicartesian closed preorder object with for all elements with s and t. S means source, T means target. Composition by source gives implication of a to b as global elements (implication), the target gives either a is false (vacuously true) or b is true as target (true).

Boolean algebra object: Boolean prealgebra object that is also a partially ordered objects.

Subobject: TFAE (1) isomorphism classes of monomorphisms into the object, two morphisms are isomorphic if they are both monomorphisms into c and there is an isomorphism between them that when composed to a morphism gives equality; (2) consider the full subcategory of the over category in monomorphisms, this is the poset of subobjects of c, the set of isomorphism classes of this category is the set of subobjects or c. Recall that an over category over an objects as morphisms with codomain as the object and morphisms as commutative diagrams are with cocones over the objects. The product in this over category as a subcategory is an intersection or meet of subobjects, their coproduct is the union or the join of subobjects.

Bicartesian closed preordered object: also known as a Heyting prealgebra object is a bicartesian preordered object that exhibits the properties of a closure on their unit functions.

Bicartesian preordered object: also called a prelattice object. This is a preordered object that is both a cartesian monoidal preordered object and a cocartesian monoidal preordered object. This must exist in a bicartesian monoidal category. People drop the word monoidal when defining bicartesian monoidal categories.

Lattice object: Bicartesian preordered object that is also a partially ordered object.

Pointed object: object equipped with a global element. A global element is a morphism from the terminal object to that object.

Decidable object: object whose equality relation is complemented as an subobject of the Cartesian product object. Therefore it needs to at least be in a Cartesian category. This has a similar quality to separable or unramified. Decidable means one can decide equal or not equal. Also a metric space is separable if it has a countable dense subset

Dense subcategory: a subcategory is dense in a category if every object is a colimit of a diagram of objects in the subcategory in a canonical way.

Complemented object: subobject given by a monomorphism in a coherent category is complemented if has a complement or another subobject such that its intersection is the initial object and the union is the full object of the subobject.

Coherent category: regular category which subobject posets admit finite unions preserved by base change functors.

Regular category: finitely complete category (admits all finite limits) 

Global element: a morphism from the terminal object to the object. Alternatively, it is the global element of the represented presheaf of the object if the category has no terminal object I.e. C(-, x). The Yoneda embedding is fully faithful and preserves all limits. 

CoCartesian monoidal category: tensor product is coproduct, tensor unit is initial object, has all finite coproducts.

Cartesian monoidal category: tensor product is product, tensor unit is terminal object, has all finite products.

Closed monoidal category: monoidal exists and internal Hom exists and tensor Hom adjunction exists as internalised.

Example of global object: the global element of a subobject classifier is the truth value.

Cartesian monoidal preordered object: is a preordered object with internal preorder as a representable subpresheaf of the Hom fixing the source into the product with monoid objects with monoidal multiplication and a global unit from the terminal object to the object such that there is a function tau for all clinal elements a, it is preserved under s and becomes the global unit under t. Further there are suitable internal left and right unitors internal hom objects such that for all global elements, composition of the left component subobject with the left unitor gives the internal left projection, right component subobject with the right unitor give the internal right projection, and internal composition by left on the projection on the opposing unitor gives the meet of subobjects of the preorder. Dualising using means that the global unit is the join, and is careful still a morphism from the terminal object.

Semicartesian monoidal object: tensor unit is terminal object, weaker than saying tensor product is Cartesian product.

Semicocartesian; tensor unit is an initial object.

Join relative objects: cocartesian monoidal preordered object that is a partial order object

Meet relative object: Cartesian monoidal preordered object that is a partial order object.

Partial order object: preordered object whose internal preorder has an internal anti symmetric relation

Cartesian monoidal preorder object: The definition makes no sense to me though. It is probably motivated by Cartesian monoidal categories. And the definition of semicartesian which only requires the unit for the tensor product be terminals, and the defines need for left and right unitors. Left and right unitors arise from the definition of the tensor product. If something semicartesian, one can define left and right projections  to have the projections made into the tensor product into the canonical product. There is also diagonal maps, augmentations and other stuff.

Preordered object: in a category with pullbacks (need subobject on product), a preordered object has an internal preorder R on X that is injective on pullbacks of X and X, a subobject (analogy is internal Hom) of the product (s,t); with internal reflexivity internal morphism which is an object that is both a section of the s and t (left compose), internal transitive is a factoring left and right projection for through the product of X and X.

Internal preorder: representable subpresheaf of the Hom out of the product of X and X, such that the composite of the internal preorder in object Y preserves limits on Homs as a preorder on the internal Hom of object i.e. R(Y) injects into hom(Y, X x X) is isomorphic to hom(Y,X) x hom(Y,X). Question where is the presheaf?

Section: composable element on the left

(0.1)-categories, categories of open subsets of topological spaces or locales using Heyting duality, objects are propositions, morphisms are implications, limits are and, colimits are or. These are (n-r) categories.

2-categories: objects are functors, morphisms are natural transformation. Useful because instead of Hom object with internal Hom, one can recycle notions of internal Hom onto functors and internal Funct, thereby recycling (0,1)-category theory or 1-category theory to extend into larger structures. This is also small category theory, or categories as algebraic structures as well, so the analogies are deeper. They are also the horizontal categorification of monoidal categories. There is horizontal composition along objects, and vertical composition along morphisms.

Heyting prealgebra: it is a preorder which is a bicartesian closed category.

Heyting prealgebra object: preorder object that is a bicartesian closed preordered object.

Heyting algebra object: a Heyting prealgebra object that is a partially ordered object.

Algebraically J-injective object: object X equipped with structure such that for every morphism in J, there exists coprojections to X as cocone with commuting diagram (PLEASE CHECK NCATLAB)

Graded objects: objects of the functor category from the discrete (or monoidal) category S to the category C denoted by C^S.

Associated graded object: graded object which in the n-th degree is the cokernel of the n-th inclusion, and hence is the quotient of the nth layer by the next lower 1, this fits a short exact sequence

Bicartesian closed category: closed means admits all finite coproducts. It is cartesian and cocartesian. 

Proper maps: in topology, a continuous map is proper if the inverse image of a compact subset of the codomain is compact.

Torsion of G-bundles: prevents global sections (think arrows) from existing. Standard example is universal covering of the reals onto the circle.

Atlas as structural sheaf of smooth manifolds: the atlas is in some sense, maps that construct the smooth manifolds example .structural sheaf

Eigenvectors of adjugate are the same as original matrix: proof is by considering adjugate equation where adj A * A = A * adj A, apply to definition of eigenvector, use associativity.

Reductions of concept of finite completion: TFAE: (1) it has a terminal object (to form coslice categories) with admission of all binary products and equaliser; (2) has terminal object and admits all fibers and binary products; (3) has terminal object and admits all binary pull backs.

Left exact functor: morphism in finitely complete categories, this is a functor that is also called a lex functor, a Cartesian functor, or a finitely continuous functor. Lex comes from left exist, Cartesian comes from preserving binary products, finitely continuous comes from preserving fibers, binary products and binary pullbacks, similarly.

Category and functor table: categories can be paired with functors, internal logics, theory, hyperdoctrine, subobject poset, coverage and classifying topoi

Finitely complete category: a category that admits all finite limits. Also a Lex category, such finitely complete categories form a 2 category called Lex. Lex comes from the word left exactly. 

Vector space: a vector space is a vector bundle over a point. Imagine a cylinder vector bundle, now collapse this into a vector.

Dedekind finite ring: ab = 1 implies ba = 1, all one sided inverses in the ring are two sided.

Simple group: normal subgroups are trivial and full group.

Cyclic group of prime order: only simple abelian group, all subgroups of abelian group are normal, subgroup <g> must be all of G, so it must be cyclic of some order, now subgroups must be m | n, so g must be prime (cannot even be prime power order).

Projective representation: instead of GL(V), use PGL(V) = GL(V)/F*, F* is normal subgroup (closed under conjugation) of nonzero scalar multiples of identity / scalar transformation. This word has to come from geometry.

Discrete Fourier transform, oscillator representations as projective representations: take finite field Z/p, p prime, Vbe p-dim space of Z/p, values in C, take T_a f(b) to be f(b - a), and S_a f(b) to be exp(2pi ab/p) f(b), T_a is translation, S_a is shift in frequency space or the discrete Fourier transform of f, verify that T_a S_b commutes with S_b T_a by multiplicative transformation, then you can look at projective representations of p of Cartesian product Z/p and Z/p as p(a,b) = [T_a S_b].

Projective representation of SO(3): rotation group has universal cover SU(2), there ie exactly one irreducible representation of SU(2) in each dimension, odd dimension is ordinary representation of SO(e), even dimension descends to projective representations SO(3).

Split epis: for split epi e A to B in category C, there exists split mono s from B to A, we have e * s is in 1_B. We call s the section of e, e the retraction of s, B is the retract of S, and e, s is the splitting of the idempotent A to A.

Subobject: take category C, object A, it is an equivalence class of monomorphisms with codomain A, identify two monomorphisms m and m' from B to A and B' to A with th e same equivalence class if there is an isomorphism B -> B' such that m = m' f. This feels like a universal property style definition.

Quotient object: suboject of A in the opposite category. Good exercise to build out explicitly, it is an equivalence class of epimorphisms with domain A, identifying epimorphisms e and e' from A to B and A' to B'' if there is an isomorphism f from B' to B, such that e = f * e'. https://math.stackexchange.com/questions/61062/quotient-objects-their-universal-property-and-the-isomorphism-theorems/61204#61204

Examples of subojects in topology: subspaces of topological spaces are subobjects, topologies that are finer are also subobjects example B is subobject of A if B has a finer topology of A.

Examples of subobjects in monoids: category of monoid, Z is a quotient of M, because N to Z is epic.

Motivation fo regular monos and regular epis: now define regular monos as equaliser of pair of parallel morphisms, regular epis dually are coequaliser for some pair of parallel morphisms. 

Examples of regular monos: kernel of group,ring and module, which equalises f and the zero morphism.

Example of regular epis: cokernel of groups, rings, modules. Projection maps on quotient groups, rings and modules are epis.

Linear algebra specialty: direct sum of finitely many vector space is the same as the direct product of them.

First monads: endofunctors on category with unital associative binary operation under composition. (Basically, category definition, but with endofunctor, or a monad is a monoid in the category of endofunctors.)

Relation category: objects are sets, morphisms are relations.

Regular monomorphisms: a monomorphism is regular if it is an equaliser of a pair of morphisms. Example: categories with zero object or zero morphisms, it is normal where every monomorphism isa kernel, then every monomorphism is regular.

Fiber and cofibres in category of pointed objects: given morphism in category of pointed objects coslice category of basepoint /  category of pointed objects, with finite limits and colimits. The fibre of a map is the pullback of point inclusion, fib(f) -> * -> Y is equivalent to fib(f) -> X -> Y. The cofibre is the pushout of the point projection, X -> Y -> cofib(f),  and X -> * -> cofib(f).

Classifying topos for pointed object: presheaf topos on the opposite category of pointed finite sets.

Pointed object: (X, x), morphism x from * -> X, where * is terminal object. Note that there are always maps TO the terminal object.

Saturated homotopical category: a homotopy category where under localisation of wide category W for homotopical category M, all isomorphisms become weak equivalences.

Homotopy category: homotopical category under formal localisation of M under wide subcategory W.

Homotopical category: a category with wide subcategory W with composable triples such that hg gf in W means f, g, h, and hgf are in W.

Homotopy categorical of spaces: formal localisation of the homotopical category of topological spaces and weak homotopy equivalences i.e. category of CW complex and homotopy classes of maps.

Galois correspondence: a pair of adjoint functors between posets.

Torsion of G-bundles: prevents global sections (think arrows) from existing. Standard example is universal covering of the reals onto the circle.

Atlas as structural sheaf of smooth manifolds: the atlas is in some sense, maps that construct the smooth manifolds example .structural sheaf

Eigenvectors of adjugate are the same as original matrix: proof is by considering adjugate equation where adj A * A = A * adj A, apply to definition of eigenvector, use associativity.

Deformation theory intuition: formalises idea to study nonlinear problems by study linearisation at a point, then quadratic behaviour of a point.

Chern classes: vector bundles and different ways to measure how twisted they are.

Projective variety: subvariety of projective space.

Motivation for derived categories: work with complexes rather than their cohomology. Use sheaves to link algebraic geometry and algebraic topology.

Cohomology as not the true dual of homology: Hom(,Z) destroys torsion information. Take Hom at the level of dual complexes.

Ordinary double point: plane curve intersects itself such that it has two distinct tangent lines with different partial derivatives.

Kummer surface: maximum number of ordinary double points, surface of degree 4. Looks very very nice.

Motivation for projective spaces and projective varieties, connected component of affine variety is either single point or noncompact. Proof: supposed X is connected component of affine variety, functions x_i cant be maximum on X unless constant, if X is compact thant x_i equal constant a_i or X is a point (a_1, ... a_n).

Functor between groups regarded as one object categories: these are just group homomorphisms.

Sum of two independent Poisson random variable: this is easily proven by considering that the sum of the random variable is the product of the characteristic functions.

Classical Poisson approximation to the binomial distribution: exercise in Weinan, Tiejun - Applied Stochastic Analysis, trick is to take binomial variables, then construct it into a power series somehow, then you take limit, it is exponential.

Binomial distribution as sum of Bernoulli trials: prove by looking at characteristic function then if you take some sort of n-fold power (note exponential functions are to be multiplied to add the random variables), this is the property of the Fourier transform, you get the characteristic function of the binomial distribution

Category misunderstanding: I think that one of the biggest, most subtle misunderstanding in category theory is to think of categories as totally distinct worlds of math, rather than an algebraic structure in its own right. Simplest counterexample is definition of a group as a category. A category is an algebraic structure in its own right, so functors may be trapped within its own world as well. If not, you will limit the imaginations you can have functors.

Counting measure: simplest example of measure, f(x) = 1 gives cardinality of measurable sets. Therefore, f is the counting measure.

Infinite sigma algebra exercises (see Folland, Exercises in 1.2.): it contains an infinite sequence of disjoint sets, without loss of generality consider sequence not all disjoint, take sequence of set complements, with union of every other sets. Cardinality of M is at that of the continuum to define (choice function) second projection onto power set of the naturals, so it is least cardinality of the continuum.

Centraliser of an element versus centraliser of a set: same logic elements in the group that commute with all elements in the set.

Example of calculating centraliser of elements: in D4, rotations form one centraliser, cyclic group S4, flips form another centraliser cyclic group S2.

Symmetry group of a square: this is D4, consisting of rotations and flips.

Product of order of elements: g and h be element of a group G, g has order |g|, h has order |h|, then order of gh is |g||h| requires ABELIAN. Proof is by considering free group of two generators under relations of finite order. The element gh is an representing object IF abelian.

Permutation: can be thought of as an endomorphism.

Full transformation monoid: compositions of endomorphisms are endomorphisms, so for a category C it is End_C{X} as a monoid.

Euclidean algorithm remainder decreasing speed: r_{n+2} < 0.5r_{n}, proof, consider r_{n-3} = q_{n-1} (q_{n} r_{n-1} + r_{n}) + r_{n-1}.

Proving equivalence relations: simplest way is to check reflexive, symmetric, transitive. Otherwise, think about disjoint union of equivalence classes for the relation.

Logical equivalences using truth tables: if two statements have the same truth table, they are logically equivalent. Truth table is therefore some sort of invariant or representing object?

Inclusion exclusion: cardinality of union is equal to sum of cardinalities subtract away the intersection. This is done by applying the forgetful functor and taking cardinality of objects as some of norm. # (S union T) = #S + #T - #(S intersect T). For general case, induction applies, induction hypothesis holds for S the union of the first n sets, then T is the n+1-th set.

Matroid: matroid on (finite) set X with TFAE: (1) family of subsets called independent sets, empty set is independent, downward closed i.e. if J is a proper subset of an independent set I, then J is an independent set, and the exchange axiom where if I and J are independent sets, with J of higher cardinality, then the union of I and some element in J\I is an independent set;

Graphic matroid: derived from single graph, underlying set are edges, independent sets are those that forms forests or graphs without cycles.

Vector matroid: derived from collection of vectors, independent sets are those that are linearly independent. Providing equivalence of vector matroid is representation theory over specific field.

Algebraic matroid: derived from collection of elements E in K, field extension K/F, independent sets are those F(S) has transcendence degree equal to |S|, so all of S is algebraically independent.

Maximal independent set in matroid: maximal independent sets of matroid is a basis.

Free matroid: let E be a finite set, set of all subsets defines independent sets of a matroid, it is a free matroid over E, the representative object of the functor Matroid^{op} -> Set as forgetful functor.

Vector bundle intuition: idea is you want family of vectors parameterised by some space. Attach a vector space to every point so they become another space. Example: sphere be parameter for tangent bundles. Tangent space is vector bundle. This is not a trivial bundle! (Hairy ball theorem). Example of globally trivial vector bundle, take S^1 cross R to get cylinder. Generalisation of cross product of topological space with vector space.

Euclidean algorithm visual: cover a * b with square tiles, use b * b tiles first where a < b without loss of generality, stuck with r_0 * b rectangle where (a - bq) = r_0. Iterate on this step.

Constructive definition of connectedness: all continuous functions from X to {0, 1}, where {0, 1} is two point space endowed with discrete topology is constant.

Coxeter group: group with generators r_1, r_2, to r_n where (r_i r_j)^{m_{ij}} = 1, m_ii = 1, m_ij = m_ji <= is either an integer or infinity, m_ij = m_ji = infinity means no relation for torsion should be imposed. These are reflections. Finite Coxeter groups are precisely finite Euclidean reflections.

Cartesian closed: category has terminal object, finite products (not finite limits) exist in C and exponentials exist in C. For locally small categories, we have bijection Hom(X cross Y, Z) and Hom(X, Z^Y). This is the point, it is a caetgory where product of two objects can be naturally identified as morphisms of one of its factors. Motivation: sufficient to be equivalent to simply typed lambda calculus.

Birkhoff's ergodic theorem: T be ergodic endomorphism of probability space X, f from X to R be real valued measurable function, then for almost every x in X, the sum of 1/n f * T^j (x) for repeated applications of j from j = 1 to j = N in the limit i the integral of f dm, as n tends to infinity. Space averages equal to time averages almost everywhere. Left hand side feels like representation theory and Haar measure. EXAMPLE: pick f to be characteristic function where 1 if it is in subset A, zero otherwise, left hand side means how often the orbit of x (points x, Tx, T^2 x) is in A, right hand side is the measure of A. See https://mathworld.wolfram.com/BirkhoffsErgodicTheorem.html.

Wirtinger presentation: see normal presentations of groups, this is a finite presentations where relations are of the form of conjugates on word i.e. wg_i w^{-1} where w is word in generators {g_i from 1 to k}. Wirtinger presentations are used to present knot COMPLEMENTS.

Knots: are embeddings of one sphere S^1 into 3D space R^3, so we can consider knot complement i.e. use three sphere S^3.

Knot complement: S^3 \ K is knot complement.

Convex hull: TFAE: (1) smallest convex polygon containing a set of points (convexity because you want nice distance properties); (2) intersection of all convex sets containing X; (3) unique minimal convex set containing X; (4) set of all convex combinations of points containing X; (5) union of all simplices with vertices in X. Recall that set of points in Euclidean space is convex if it contains the line segments containing each pair of points.

Example of Wirtinger presentation of trefoil: fundamental group of (R^3 \ trefoil) as knot complement is generators x, y with relation (xy)^{-1}yxy = x.

Birational equivalence: algebriac varieties are isomorphic outside of lower dimensional subsets, they are birationally equivalent. Example smooth quadric of degree 2 is rational, use stereographic projection (see Indra's Pearls) and projective space P^n.

Torsion subgroup of abelian group: subgroup consisting of all elements with finite order i.e. a^n = e, n is integer. Factor group of ABELIAN group quotiented out by quotient subgroup is torsion free.

Torsion free group: every element of group except identity is of infinite order.

Affine basis: {x_0 to x_n is affine basis} if and only if (x_1 - x_0, ... x_n - x_0) is linear basis of associated vector space.

Covariant functor for torsion subgroups: covariant functor from Ab to TorGrp sending ABELIAN groups to torsion subgroups and homomorphisms to restriction to torsion subgroups.

Covariant functor for torsion-free groups: covariant functor from Ab to TorFreeGrp sending ABELIAN groups to torsion free groups made through quotienting out torsion subgroups and homomorphisms to induced homomorphism.

Spanier-Whitehead category: idea is to have Hom(X, Y) to be colimits of suspensions sum^q X sum^q Y over homotopy classes of arbitrarily high suspensions. Quite clever, but lacks desirable properties and fails Brown's representability theory.

Spanier-Whitehead duality: idea is topological space is dual to its n-sphere, where n is large enough. Sphere complements determine homology, and determines the STABLE HOMOTOPY TYPE. Example: X be compact smooth manifold, dual of its suspension spectrum is Thom spectrum of stable normal bundle.

Combinatorial species: introduced by Joyal, used to make generating functions of discrete structures like finite graphs, permutations, and trees. Category of species is equivalent to category of symmetric sequences in finite set. Let B be the category of finite sets, morphisms being bijections, a species is simply a functor from B to B.

Examples of combinatorial species: let F(x) = sum of Card F[n] x^n/n! which is the exponential generating series, (1) species of sets f_n = 1, E(x) = exp(x); (2) species of permutations, f_n = n!, S(x) = 1/(1 - x) which is geometric series. Combinatorial series feels like a way to have generating functions be like characteristic functions from probability theory, then you can design more and more combinatorial species.

Géometrie Algébrique et Géométrie Analytique: GAGA is a Serre paper, relates algebraic varieties with classes of analytic spaces, sheaves. Comparisons of category of sheaves.

Birkhoff-Kakutani theorem: topological group TFAE: G is first countable and Hausdorff; G is metrizable. Forward is obvious, see below for reasons. Converse is hard: https://terrytao.wordpress.com/2011/05/17/the-birkhoff-kakutani-theorem/. Need Urysohn-type lemma to have bounded continuous function with unique maximum, neighbourhood base, uniform continuity. Now, use this to construct a supremum norm, check that this is a metric using these properties. In general, the idea is to use a suitalbe continuous function to make a useful metric.

Metrisable topological space: a topological space X is metrisable if we can find metric from product of X * X to [0, infinity) whose open balls generate the topology. Obviously, it needs to be Hausdorff (metric spaces are Hausdorff) and first countable (countable neighhbourhood base of balls).

Category of distinct closed base points with basepoint preserving map: take functor to Set, terminal object must be [0, 1] (a theorem by Freyd).

Algebraic integers: root of polynomial equation with coefficients in the integers.

Number field: totality of the expressions constructed from algebraic number of degree n by repeated addition, subtraction, multiplications and divisions. This is the number field (or algebraic number field) generated by r. Elements of number field are roots of a polynomial. These also form a ring.

Curve complex: extend curve graph, use k-simplex whenever there are k + 1 disjoint vertices. Example, add in simplicial complex.

Curve graph: vertices are homotopy classes of essential simple closed curves, edges are disjoint.

Covering map: locally looks like projection of multiple copies of a space onto itself. Special type of homeomorphisms. Coverings are used to define new domain for analytic continuation.

Motion, isometry, congruence: a motion is a automorphism on Euclidean space preserving distances, T is bijective. This isa rigid body motion. T(x) = Ax + b, A is orthogonal matrix. In Euclidean plane, it is either rotation matrix or reflection matrix for Euclidean plane. Motion is affine linear i.e. T([1-p]x + py) = (1-p)T(x) + pT(y).

Embedding homomorphisms: consider cyclic group of 3 elements as an embedding (outer surface) of the Cayley graph of the symmetric group on 3 elements (inner graph is what happens when we have f, rf, r^2 f)

Fundamental homomorphism theorem: p from G to H is a homomorphism then the image of p is the group G quotiented out by the kernel of p. Example, consider Z/cosets of 12, gives isomorphism to cyclic group of 12 elements.

Complementary orthogonal idempotents: say x is idempotent, x' = 1 - x is idempotent, consider (1 - x)(1 - x) = 1 - x^2 = 1 - x so idempotent, x + x' = 1 by definition x(1 - x) = x - x^2 = x - x =0. Consider a direct sum of rings A = A_1 ++ A_2, where A_1 = Ax and A_2 = Ax'.

(ax + by) nilpotent if x and y are nilpotent: expand (ax + by)^N some power with binomial theorem, highest power nilpotent and vanishes taking N to be product of powers mn, so either it vanishes due to nilpotence of x, or vanishes due to nilpotence of y.

x nilpotent implies 1-x invertible in A: start with 1/(1-x) as geometric series 1 + x + x^2 + ... but it must terminate as some x^n = 0 (x nilpotent), so it must exist.

Algebra structure on R^n: bilinear multiplication map R^n cross R^n into R^n where (a,b) -> ab. Products satisfy left right distributivity and scalar associativity. Commutativity, full associativity and identity not assumed. division algebra means equations ax = b, xa = b always solvable i.e. maps from x to ax and x to xa are always surjective for nonzero a.

Homotopy group: generalisation of fundamental group Pi_i(S), S some space. Typical example is homotopy groups of sphere which are very complicated. Pi_n(X, x_0) basepoint x_0 is set of homotopy classes of maps f: (I^n, del I^n) to (X, x_0), homotopies f_t satisfies f_t(del I^n) = x_0. I^n is n-dimension unit cube, product of n copies of interval, del I^n is boundary with one coordinate equal to 0 or 1. Try n = 0, I^0 is a point, boundary empty so pi_0(X, x_0) is path components.

Sum operation in homotopy group: looks like deformation, where you have f for the first half of interval [0, 0.5], g in second half from [0.5, 1]. Additive notation for group operation is used, n >= 2 means abelian, shrink domain of f and g down, then slide around due to space and expand back to ordinary size, fixing other coordinates, then do for the rest of the coordinates. See Hatcher for figure.

Motivation for fibre bundles in algebraic topology: fibre bundles give long exact sequence of homotopy groups but not normal short exact sequences.

Tangent vectors for lie groups O(n), U(n) amd Sp(n): trick is to differentiate the defining equation A A^* = 1, where A^* is the conjugate transpose. For tangent vectors X at 1 for O(n) it is X + X^*T = 0, X is n by n real matrices. For tangent vectors X at 1 for U(n) it is X + X^*T = 0, X is n by n complex matrices. For tangent vectors X at 1 for Sp(n) it is X + X^*T = 0, X is n by n quaternion matrices. See Stillwell's Naive Lie Theory.

Functor of points: Hom(-, X): (Affine schemes)^op to Set, sending affine scheme Y to set of scheme maps Y -> X. Therefore, a scheme is the representing object of the functor of points, the functor of points is a representable functor. Yoneda lemma is weaker, Hom(-, X): Schemes^op -> Set, where X is a scheme. The functor of points is sufficient to be isomorphic to functor of points, and not necessarily the natural transformations. This functor Hom(-, X) classifies geometric objects over Y given by F. Notion is analogous to classifying space.

Worked example of functor of points, Nullstellensatz: functor sending affine variety over algebraically closed field k to set of points over k i.e. AffineVariety^(op) -> Set where X is sent to Hom(Spec k, X) is faithful (Nullstellensatz, requiring algebraically closed field and affine variety). Point of faithfulness is so that morphisms can be identified as functions on underlying sets. Faithfulness fail if j is not algebraically closed, example X -> Hom(Spec R[x]/(x^2 + 1), X) is empty so cannot distinguish morphisms. Spec R[x]/(x^2 + 1) is not empty, but morphisms are not captured by what they do to real points.

Functor of points analogy to classifying space: principal G bundle over space S (G topological group) is pullback of universal bundle EG -> BG along some map S -> G. Classifying space BG is quotient of weakly contractible space EG by proper free action of G.

Classifying space as representative object: it is a representative object of  the contravariant functor of homotopy category Htpy^{op} to category of sets. See Riehl's Category Theory in Context, example (vii) in the relevant section, takes a CW complex to the set of isomorphism classes of principal G-bundles over it.

Eilenberg-MacLane space: represented by functor of Htpy_{CW}^op to Set note that initially we have Top^{op} to Ab which is singular cohomology with coefficients, then need to pass through to nice space like CW complex to get the Eilenberg-Maclane space. Homotopy classes of maps X -> K(A,n) stand in for bijection with nth singular cohomology group H^n(X, A), X with coefficients in A for nice spaces like CW complexes.

Paths and loops are obviously representable: say we have path functor from Top -> Set, this is representable by path as continuous functions from I to X. Loops representing loop functors from Top_* -> Set, which are representable by based closed circle S1 -> X.

Examples of classifying spaces: (1) circle is classifying space of integer group, total space is EZ = reals R; (2) n-torus is classifying space for free abelian group of rank n i.e. Z + Z + Z ... n times. total space is EZ^n = R^n; (3) Wedge of n circles is free group of rank n; (4) closed compact without boundary connected surface S of genus at least one is classifying space for its fundamental group pi_1(S); closed compact connected HYPERBOLIC manifold is classifying space for its fundamental group Pi_1(N); (5) Grassmannian of n planes in R^{\infty} is classifying space of orthogonal group O(n).

Grassmannians as prototypical examples of classifying spaces: we have O(n), U(n), SO(n) and SU(n) with classifying spaces being some Grassmannian construction.

Example of classifying space for discrete group: classifying space BG is path connected topological space X such that fundamental group of X is isomorphic to G, higher homotopy groups of X are trivial. This means, BG is Eilenberg-Maclane space.

Matrix representation of complex numbers, consider R = cos theta(1 0 ; 0 1) + sin theta(0 -1 ; 1 0) in fact we just have (a -b; b a) to be exactly the same as the complex numbers.
Quaternions, we have this tricky thing called (a+id -b-ic; b-ic a-id). Pick c = d = 0 and you get back complex numbers. Computing determinant? Trace as 2a?

Pell equation: x^2 - ny^2 = 1. Forms a group of solutions with integers adjoined root 2 if you pick n = 2.

Zeta function product and sum equality: sum of 1/n^s is equal to product of (1/1 - p^{-s}), p prime. This equality is equivalent to unique prime factorisation. Hint, consider geometric series of this i.e. (1 + p^{-s} + p^{-2s} +...), then product of all the factors will be every possible term of the form 1/(product of p_i^(m_i))^s, these are distinct primes, so you get the formula. This also implies the infinitude of primes by picking s  = 1, but left hand side is infinite since 1 + 1/2 + 1/3 is infinite.

Greatest common divisor by division of remainder: a_{i+1} = b_{i}, b_{i+1} is remainder when b_i/a_i. Division of natural numbers is just repeated subtraction. Halts when gcd is constant. Euclidean algorithm gives linear representation of the gcd. i.e. gcd(a,b) = ma + nb, equal 1 if coprime.

Induction on successor function: you can use the successor function to inductively define sums and products.

Diophantus chord method: method for rational points consider circle, Q = (-1, 0) to arbitrary rational point R, we have line Y = t(X + 1), rational points on X^2 + Y^2 + 1. Quadratic formula gives solution X = -1, (1 - t^2)/(1 + t^2), it has coordinates (1 - t^2)/(1 + t^2), 2t/(1 + t^2). You can recover Euclid's formulas using substitution x/z, y/z. Generalise to cubics, see Silverman and Tate.See also demo by Borcherds in first algebraic geometry lecture.

Torsion of G-bundles: prevents global sections (think arrows) from existing. Standard example is universal covering of the reals onto the circle.

Atlas as structural sheaf of smooth manifolds: the atlas is in some sense, maps that construct the smooth manifolds.

Classification of homotopy classes of simple closed curve in torus: let R^2 -> T^2 be covering map, deck transformation group generated by translations (1, 0), and (0, 1). The fundamental group of the torus is Z + Z,, base the fundamental group at the image of the origin. Take straight line for translation p, q, take straight line from (0, 0) to (p, q), project it onto the torus. Let g be oriented simple closed curve in torus, up to homotopy, assume it passes through the image in T^2 of (0, 0), path lifts based in origin terminates at integral point (p, q), there is therefore a homotopy from straight line representative of (p, q) to any simple closed curve. If closed curve in T^2 is simple, then straightline representative is simple. Conclusion: nontrivial homotopy classes of oriented simple closed curves in torus are in bijective correspondence with the set of primitive elements of the fundamental group of the torus.

Homotopy classes of essential simple closed curves: let S(g, n) be surface of genus g and punctures n. S(0, 1) has no essential simple closed curves simlarly for S(0, 2), S(0, 3), But S(0, 4) is 4-punctures sphere, isotopic classes can be identified with Q union {infty}. How to do this, fix a sphere with four distinct points, draw arcs from x1 to x2, x2 to x1, and x3 to x4, x4 to x3. These are sliced, forming holes for the torus to form. See https://math.stackexchange.com/questions/2833072/isotopy-classes-of-essential-simple-closed-curves-in-a-4-punctured-sphere.

Deck transformation: consider covering space E -> X, a deck transformation is a bundle automorphism. Example: E -> X is universal cover, then E_x isomorphic to fundamental group of X, E -> X is a fundamental group-principal bundle, group of deck transformations. 

Notation of surfaces: typically as S(g, n, b), g is genus, n is punctures/marked points, b is boundary. Equivalently, S is the connect sum of g >= tori, with b >= disjoint open disks removed, and n = 0 points removed from the interior.

Hyperbolic metric on surface, lifts, conjugacy classes: bijective correspondence to universal cover of closed curve A is in bijective correspondence to elements of the conjugacy class of A in the fundamental group of the surface Pi_1(S), precisely lift of curve a is given by coset g<a> corresponds to element gag^{-1} of conjugacy class [a]. Note, due to the fact that hyperbolic surface, centraliser of any element is cyclic. FAILS FOR TORUS. Each closed curve has infinitely many lifts. Each element of Pi_1(T^2) = Z + Z is its own conjugacy class, centraliser of each element (i.e. the elements that commute) is the whole group (not cyclic).

Mobius transformation from upper half plane to unit disk: PSL(2, R) (key word is R) is isomorphic to Isom(H^2), where H^2 is the hyperbolic plane.

Simple closed curve: closed curve where map from S^1 -> S is injective i.e. it is embedded.

Simple closed curve classification up to homeomorphism: cut along them, Dehn twists, fully classify simple closed curves. Homeomorphisms of surfaces can be studied via actions of simple closed curve.

Closed curve on surface: continuous map from circle to surface. Closed curve with its image in S.

Essential closed curve: closed curve that is not homotopic to point, puncture or boundary component. Hint: try classifying closed curves in punctured complex plane to see what this means. Essential closed curves winds around singularity at 0.

Bijection of fundamental group and free homotopy classes: this means that there is a bijective correspondence between nontrivial conjguacy classes in fundamental group of a surface, and nontrivial FREE homotopy classes of ORIENTED (need this for Z to work properly) closed curves in S.

Multiple of closed curve: curve that runs around another curve.

Primitive group element: an element is primitive such that there does not exist g = h^k for h as another element in g, |k| more than 1. Primitive makes sense, it feels like some sort of generator.

Mobius maps: maps of the form T(z) = (az + b)/(cz + d). The idea is you want T(z) = az + b to spiral expand or contract from source, T(z) = 1/z to turn unit circle inside out. They do for the Riemann sphere what affine maps az + b do for the complex plane (affine maps motivate affine varieties). Also map z to 1/z. NOTE: ad - bc nonzero makes this map invertible i.e. natural in some sense. These form the general linear group GL(V^2). Fixed points of these are actually quadratic formula cz^2 + (d-a)z - b = 0 so consider roots. Trace is a + d.

Schottky group: free group with generators a, b (2 generators for example, arbitrary generator) as Mobius transformation. It is free if generators only cancel with their inverses (need not be true for Schottky group).

Circle pairing to derive classical Schottky group: consider loxodromic transformation pairing the disks if the disks do not overlap, outside of one disk maps to inside of the other disk, one disk is dual to the other i.e. a^{-1} = A, A^{-1} = a, fixed points are dual, successive powers shrink or expand the disk etc, see Indra's Pearls. To generalise this, use arbitrary paired shapes that are not disk.

Tiling of Schottsky disk: there are four circles, from two generators, delete the generators, so you have a torus of genus 2 i.e. two holed pretzel.

Mobius transformation geometrically: inverse stereographic projection from plane onto unit sphere, moving and rotating sphere to new location and orientation in space, reapply stereographic projection. Form Mobius group, or projective linear group PGL(2, C). Automorphism group of Riemann sphere.

Classification of Mobius maps / isometries of hyperbolic plane: loxodromic (hyperbolic if scaling map k is real), parabolic, elliptic. Definition: parabolic transformations are conjugate to translations T(z) = z + a, all elliptic transformations are conjugate to rotations T(z) = kz, |k| = 1, all loxodromic maps are conjugate the scaling maps T(z) = jz, |j| >= 1 (not typo). Trace of conjugate is same as trace of T, loxodromic maps have trace not between -2 and 2 (hyperbolic if k real) move into sink out of source, elliptic maps have trace strictly between -2 and 2 with two neutral fixed points move around in circles around fixed points, parabolic maps have trace exactly +- 2 one fixed point both source and sink.

Number of fixed points in classification of isometries of hyperbolic plane: (1) elliptic, rotation about fixed point p, there is no fixed points on boundary of hyperbolic plane, elements of PSL(2, R) with trace absolute value less than 2; (2) parabolic has one fixed point on boundary of hyperbolic plane, nonidentity elements with trace +-2; (3) loxodromic, elements of PSL(2, R), absolute value greater than 2, two fixed points on boundary of hyperbolic plane; (4) three fixed points so identity.

Metrics of surfaces: curvature chi(S) less than 0, admits hyperbolic metric, chi(S) equal to 0 admits Euclidean metric. Consistent with Gauss-Bonnet theorem, compact surface with totally geodesic boundary, integral of curvature over S is 2 pi chi(S).

Surface admitting hyperbolic metric then centraliser of nontrivial element of fundamental group is cyclic, or fundamental group has trivial center: prove using fundamental group identified with deck transformation group. Classification of isometries have same fixed points as central element, if a is centralised by b, a in fundamental group, a b have same fixed points (used the fact that it is hyperbolic metric). By discreteness of action of pi(S), centraliser must be infinite cyclic, if nontrivial than it is Z, but S will have infinite volume, contradiction. Can follow this line by line but don't fully understand this.

Topology of loxodromic transformation: see Indra's Pearls, see Riemann sphere, remove two fixed points. Easiest way is to start with a flat sheet, glue the top to bottom, left to right aligning the edges, you get a torus. Indra's Pearls considers two concentric circles, big circle glued onto small circle, then you roll up the ring and glue them.

Upper half plane group: SL(2, R) map from z -> 1/z carries i to 1/i or -i, swapping two half planes, but this is of determinant -1. So SL(2, R) is upper half plane group since it preserves the upper half plane. NOTE: SL(2, R) have real trace, so it cannot never be loxodromic.

Ordinary language is not associative: example ((the cat ate) (a fish, took a nap)).

Commute and conjugate: order does not matter, so ab = ba. I now tend to think of it is as conjugation as idempotent i.e. a = bab^{-1} (right conjugate). See Indra's Pearls, the Vision of Felix Klein, Figure 1.15. The idea is simple, (1) take a step back; (2) apply original map; (3) apply step forward again. This is so useful in real life (like a redo in case you forgot something), mathematicians give it a funny name.

Erlangen program: characterise projective geometry using group. In fact, this is the study of modular groups.

Inversion of unit circle: map from z to 1/z^, z^ is complex conjugate. See Figure 2.6 in Indra's Pearls for what happens when you invert in a circle. This is a Riemann sphere.

Stereographic projection: consider circle on sphere, stereopgraphic projection gives ellipse on the plane. This is because cone is sliced by complex plane, so it is a conic section, since this is a conic section, it must be at least an ellipse. Now, tricky, this is a circle! Needs proof. So stereographic projection preserves angles and circles.

Stereographic projection mechanics: butterfly on surface of Earth idealised as sphere, place complex plane on South pole. Long stick from you to north pole and hit plane below, that is your image (as butterfly) on plane. South Pole maps itself, North Pole disappears to infinity. This is a Riemann sphere.

Worked example of conjugated maps in Indra's Pearls: consider dynamics of z -> z + b, and T is z -> az, we have conjugate T^ = STS^-1 = ST(z - b) = S(a(z - b)) = a(z - b) + b. This map fixes point b (it is a conjugate), the dynamics is copied. This is an affine map. Therefore conjugating and composing affine maps with a nonzero forms a group (see the point fixing).

Opposite category in the generalisation of presheaves: you want sections to exist, so instead of consider morphisms g * f, asserting g exist knowing f, you want to consider f * g, g exists such that fg identify as an object (setions exist), f becomes a morphism instead of an object. A normal category will use g * f, if f exists then g exists, opposite category will have f * g, f exists, then g exists.

Fundamental group: quotient space of paths under homotopy as equivalence relation.

Representable functors: a functor C to Set if it is naturally isomorphic to Hom(A, -) for some object A of C, feels like instead of using linear maps as linear representations, we require it to be naturally isomorphic to some hom-set within the category itself. So the functor to Set for set like properties can be identified with a hom-set inside the category C itself. Compare this with linear representations from group G to GL(V), we have representation which is from Hom(A, -) to functor F as natural isomorphism. Hom(A, -) can be thought of as the group, functors F can be though of general linear group GL(V). Presheaves are special since they are the DUAL notion of this, they go the other way round i.e. a presheaf is representable if it is naturally isomorphic to contravariant Hom(-, A) i.e. these hom-sets represent the sections itself. This is very useful, recycle stuff about facts in Set to hom-sets within a category.

Representation theory as maps between object to its algebra: (1) representation of discrete groups, modules over group ring i.e. G -> GL(V), G is discrete group or group ring, GL(V) where general linear group is like endomorphisms on vector space; (2) representation of ring, ring action on abelian group i.e. R -> End(M), endomorphisms on M as R-module, where R is ring, M is abelian group; (3) representable functors, consider object A view as functor B -> Hom(A, B), now objects A, B feels like a vector space or field, and Hom feel endomorphisms, these are called the algebra. The general pattern is that a representation is a map from some object X to some algebra on another object End(Y). This feels like Tannaka duality.

Dualities: (1) there is concrete duality with dualising object i.e. representable stuff, examples are like Tannaka duality, Pontrayagin duality so "representation theory" applies; (2) adjoints, very loose form of duality, lots of examples like limits/colimits, exist/unique; (3) axiomatic duality, logic is preserve by object is changed example domain/codomain, points and lines, meets and joins.

Yoneda's lemma and representation theory: simply says that natural transformations are represented by the homset of homsets from objects to functors i.e. Nat(h_A, F) is represented by Hom(Hom(A, -), F), for object A in category C, F any functor. So natural transformations are always representable by the algebra of hom-sets under any functor from (LOCALLY SMALL) category from C to Set, locally small means set's worth of arrows locally, no monkey business with large cardinalities.

Existence of adjoint if representable functors exist: G be functor from D to C, X be object in C, G has left adjoint F if Hom_C(X, G-) is representable (by this left adjoint), the natural isomorphism gives the adjunction i.e. Hom_D(FX, Y) -> Hom_C(X, GY) is natural isomorphism.

Example of representable functors: forgetful functors are very representable. Example, forgetful functor of group to set is represented by free object over singleton generator (Z, 1). Forgetful functor of ring is represented by free object over singleton generator (Z[x], x), forgetful functor of Vect to Set is represented by free object over singleton generator (Reals, 1). Better examples, representation of hom functor is limit, representation of product of hom functors is pair of projection maps, classifying space is representing object of presheaf (functor) of GBund from homotopy category Ho_{Top}^{op} to Set.

Analogy with Riesz representation theorem and representable functors: F be linear functional in complex Hilbert space H, if F is continuous then there exists unique a in complex Hilbert space H it is equal to inner product functional <a, -> where F(v) = <a, v>. Example: continuous linear functions on square integrable functions are representable by integral inner product integrate a(x) v(x). Example: general continuous functionals are representable by test functions, this is distribution theory. For distribution theory, analogy is much deeper, this is a sheaf! You want sheaves when you have want sections of something to exist. Test functions are representing objects, that exist in a "sheaf" in some sense as global sections to represent general continuous functionals?

Flat vector bundle: vector bundle with locally constant transition functions.

Locally constant sheaves correspond to representations of the fundamental group: see also https://mathoverflow.net/questions/17786/why-are-local-systems-and-representations-of-the-fundamental-group-equivalent, COVERING SPACES are thought of as locally constant sheaves. Spanier gives an example. Consider a manifold, let X^ to X be its universal cover. Consider representations from fundamental group Pi_1(X) to GL(V), form sheaf of sections of the bundle (X^ cross V) quotiented out by the fundamental group Pi_1(X), explicitly these are sections such that continuous functions such that for continuous f: U^ to V such that f(gx) = p(g) f(x) for g in fundamental group. Notice that the representation is clearly a section gives identity on V given p as representation. Therefore, representations of fundamental groups (think of representations as maps now) are equivalent to the sheaf (presheaves are a way to ensure maps exist by considering suitabe sections) of sections of the bundle of universal covering space cross vector space quotiented out by fundamental group.

Locally constant sheaves, local systems: open neighbourhood U of x exist (locality), such that sheaf given by F|U (sections exist, with nice restrictions, glueing, local uniqueness or separation) is a constant sheaf. These are bundles.

Example of explicit isomorphism of fundamental groups: see Kuga's Galois's dream, integral of 1/{2 pi i} dz/(z-a), a is some pole looks like windings over integers and is an isomorphism. So fundamental group of punctured complex plane is the integers. The complex plane is the universal covering space itself, the cover is the exponential map.

Cardinality of number of sets: 2^m, proof is by considering permutations of yes and no.

Retracts, projections, and idempotents: retracts are topological, projections are analytical, idempotents are algebraic.

Coverings as special case of etale space: coverings are local homeomorphisms, so it is a special kind of etale space. However, not all local homeomorphisms are coverings, mainly failing at either one of two conditions: not homeomorphic to trivial fibre bundle (Cartesian product may fail) or failing because discretisation does not exist (no fully faithful left adjoint exists).

Discrete space: classical example is discrete topological space, every subset is open. Discrete space is object of concrete (no screwy stuff) category that is free on its underlying set, i.e. for forgetful functor from concrete category Sp to category of Set, has a fully faithful left adjoint called the free functor. Codiscrete means right adjoint. True for category of topological space, not true for category of metric space (no free object exist).

Covering space (wrapping space): bundle which is locally trivial (LOCALLY ISOMORPHIC, but not locally homeomorphic to trivial fibre bundle i.e. Cartesian product using local open neighbourhood) with discrete fibre (some sort of free object thing?). Continuous function is covering space if there exists open on point that is evenly covered. Pullback p over U is isomorphic to product bundle with discrete fibre E_x = p. Discrete fibre means I can spam it and consider all possibilities (see discrete in the context of discrete topological space), corresponds to fully faithful left adjunction. Canonical example is exp(i pi x) wrapping of the real line on the unit circle. See also gimbal lock for the group SO(3) being covered by the S^3 hypersphere identifible with the group of quaternions or spin 3

Locally trivial: around every point there is a neighbourhood where the bundle is isomorphic to the trivial bundle.

Trivialising open cover: pick neighbourhoods of all points U_i such that the bundle is trivial, isomorphic to a product. This is the trivialising open cover of a fibre bundle.

Pullback of covering spaces are covering spaces: see Hatcher 1.3 exercise 1, pullbacks of covering space is covering space, restriction of covering space is pullback of an inclusion into a base space.

Product of covering space is covering space: recall definition of product topology, points of product has neighbourhood that is evenly covered. See Hatcher 1.3 exercise 2.

Classical definition of covering space: covering space of a space X is a space X^ with map p: X^ -> X such that there exists a open cover {U_a} of X where p^{-1} U_a is disjoint union of opens in X, each mapped by p homemorphically onto open U_a. Note that p^{-1} U_a need not be nonempty, so p need not be surjective.

Trivial fibre bundle: Cartesian product of bundle and fibre with projection to bundle such that this is a fibre bundle. If it is isomorphic. 

Gimbal lock as covering space: consider charts on SO(3), rotation group, this is RP3, fundamental group Z/2 by covering plate trick, with S^3 covering space hypersphere S^3 (S^2 is a normal sphere) this is the group Spin(3) and there is the unit quaternions. However, we lazy want to use Euler angles, so you can use 3 gimbals. This is a map from the 3 torus (hint: 3 gimbals are 3 rotations, so fundamental group Z + Z + Z), then we have a map from the three torus T^3 to RP^3. But the torus is not a COVERING SPACE, so it fails to be a local hot due to gimbal lock. Gimbal lock means it can only move in two dimensions, it can pitch and yaw but not roll (rotate in the plane all axes lie in). Example, two gimbals same plane.

Determination / extension problem: for example h = g * f, what are all g such that this holds or this is the extension problem, given f and h. Example, pick A -> B -> C. Pick B = 1, then h is a constant map. Choosing g means to choose a single element. If h is identity, then this is a retraction problem (hint: think deformation retract as idempotence)

Choice / lifting problem: for example given g and h, what are all f, such that h =  g * f.

Example of choice / lifting problem in mapping class groups: consider lift of a closed curve. Let p from universal cover of surface S, called S^ to surface S. Lift of closed curve a to S it is an image of the lift R -> S^ of the map a * pi, where pi: reals -> circle S1 is usual covering map. Example, surface with chi(S) <= 0, lift of essential simple closed curve to the universal cover is a copy of R. Easiest to picture with winding of circle using the real line via the exponential map. So this applies to any essential simple closed curve under this condition of chi(S) <= 0. See Farb and Margalit for this characterisation.

Isomorphism as equinumerous: see Lawvere’s conceptual mathematics. Most important part of naturally is somehow preserve cardinality or same size using isomorphisms. This is why the content of the Yoneda lemma involves a forgetful functor to Set.

Yoneda lemma on points of sets: there is Nat(1 -> X, !) is canonically isomorphic to Hom(Hom(1, X), !). So a point of set X is a map from the initial object 1 to X.

Galileo using bird flight as universal property: space given level gives line, space given shadow gives plane. Suppose there is a map called time uniquely sent to flight of bird, then there is the map time to line given the level of flight of bird, and time to plane given the shadow of the flight of bird. This is correctly known as a product, line * plane = space. Try example with coproduct. See Lawvere’s Conceptual Mathematics.

Smith normal form: idea is to use Yoneda’s lemma, consider map from Z^m to Z^n, cokernel is abelian group of interest. Apply automorphisms by matrix multiplication on the left and right, these correspond to elementary row operation, Yoneda’s lemma guarantees the existence of a smith normal form. Similar logic applies for reduced row echelon form, which need not be diagonal and only permits left action. Smith normal form is always diagonal, with empty part of diagonal column, permitting left and right actions. Only works when entries form principal ideal domain.

Smith normal form of two by two, integer entries: top left is gcd of all integer entries, bottom right is magnitude of ad-bc.

Van Kampen statement: duality, amalgamated free product of fundamental group is wedge sum of two path connected topological space. This is Pontryagin duality, locally compact topological space 

Free product of groups: reason why coproduct is given coproduct. Natural definition of sum in groups, see colimit. Also naturality preserve homsets, homset of Homs of free products under functor to Set Hom(Hom(A,-),F) equivalent to natural transformations of group homs on free products to Set Nat(ha, F), F is forgetful. F(A) is canonically isomorphic to Nat(hA, F) or objects are arrows when forgetting group structure.

Free product of groups as concatenation: coproduction since you concatenate sets together to form words. So words are an example of free product.

Homotopy as an equivalence relation: same initial point and terminal point, so transitivity is confirmed. 

Homotopy class: take W(D; O) is set of closed curves (start and end points coincide) in surface D with O as initial and terminal point. Take quotient on equivalence relation of homotopy this is the definition of homotopy class.

Nullhomotopic: consider W(D; O), you can deform to point O, so it is nullhomotopic.

Plane with two points removed: wind a rope around two poles, then you can make concatenation of loops around these two poles, so fundamental group is free group of two generators. It is like making an alphabet using two poles. Felt understanding is each alphabet is a pole or a hole.

Fundamental group of R^3 - (S^1 union l): consider loops inside the circle, so S1, then loops trapped by the line also another copy of S1, so it is Z ++ Z or torus. Number of lines gives number of holes.

Row reduction and Yoneda lemma: row reduction of matrices with k rows is natural (natural transformation where morphisms are matrices) is multiplication by that operation on the k by k identity matrix. So one can replace natural transformations between matrices in row reductions, with an appropriate matrix to multiply with, by applying that operation on the identity matrix, then multiply using that. Trick: understand that natural transformations of morphisms correspond to a morphism itself. Note that for matrices, you don't need a hom-set, you can get away with a single matrix I think need to check. Not true for arbitrary categories.

Consequence of Yoneda's lemma on row operations: requirement that it must be elementary row operations, these are the natural transformations between matrices i.e. swapping two columns, multiplication by scalar, scalar multiples of one column to another are invertible since corresponding elementary matrices are invertible. Non-example includes appending a column to 1s. Applying this to identity matrix fails, then right multiplication defines different column operation, this is because this is not an elementary row operation, fails invertibility. 

Group acting via automorphisms: group A acts on B via automorphisms if there exist a left group action * from the product group A x B to B such that a * (b x_B c) = (a * b) x_B (a * c). 

Euler's identity of Riemann zeta function: decompose into infinite product of 1/(1 - p^s), p prime. Now interpret it as independent events.

Cauchy functional equations: stuff that decomposes f(a + b) to f(a) + f(b).

Fredholm theory: g(x) is integral from a to b K(x, y) f(x) where Lg(x) = f(x), L is a linear differential theorem.

Mantell's theorem: for N vertex graph, max edge without forming triangles is n^2/4. Extremal example is complete bipartite graph. This is the fundamental example of extremal combinatorics.

Turan's theorem: generalises Mantell's theorem.

Uniformisation theorem: 2D surface can be either spherical, flat, hyperbolic. Simply connected Riemann surfaces must have one of these three geometries.

Simply connected: all maps S^1 to X are homotopic. This is quite obvious but see Hatcher's Section 1.1 exercise 5 for an exercise on this.

Borsuk-Ulam's theorem: sphere crushed into a plane, two points must be the same. This is a fixed point theorem.

Leibniz's formula: looks like the sum of binomial terms of a partial derivative operator.

Unique factorisation: fix by adding ideal numbers, sets of numbers to get unique factorisation. Replace ideal of 2 with even numbers, so for the integer ring modulo 2 it is just (0, 1), so you have unique factorisation. This becomes the ideal (2) the goal is to get unique factorisation.

Principal value of the integral: limit as epsilon tends to 0 of the region excluding the small center of epsilon ball radius of p(x) / (x-c).

Hilbert transform: statement on the cyclic group of order 4 on the unit circle, example hilbert transform of cosine is sin x, and hilbert transform of sine is cosine. Differentiation works like Hilbert transforms.

Finding mollifiers that meet a constraint: the trick is to find the roots you want the equation, example: degree 6 poly such that first second and third derivatives are zero and bounded on [-1, 1], find the roots that meet this, then take product of (x - pole/zero) that meets these criteria.

Integral inner product: for reals, this is the integral of a product of functions f and g, for complex, you will need to take the product of f and the complex conjugate of g.

Function translated by y: this is the rule T_y (f) = f(x - y), useful for defining convolutions.

Convolutions: integral of sensitivity p(x) multiplied by the function translated by y T_y(f) = f(x - y). These are an integral inner product.

Convolutions when differentiated: suppose f is merely continuous but not differentiable. Then we have the derivative of the convolution of the signal f and the averaging function phi ass imply the convolution of the signal and the derivative of the averaging or sensitivity function, where the integral of the sensitivity function is 1 aka normalised. See book on distribution theory for more details:

Sensitivity of the convolution: define sensitivity of a function to be pe(x) = p(x/e)/e, take the limit as e tends to 0.

Mollifier: mapping from f to the convolution of f and pe(x), where sensitivity of a function to be pe(x) = p(x/e)/e, take the limit as e tends to 0.

Summary of Grothendieck's work on affine varieties: start with duality between classical affine varieties and nilpotent free finitely generated algebras over a field. Recall that an algebra over a field has, G be a finite group of order g, K be a commutative ring, K[G] be an algebra of G over K, basis indexed by elements of K. Now, drop as many assumptions (nilpotents exists, finitely generated, field?) to get schemes. The idea is to start with some duality, drop as many assumptions as you can, and see how much duality will hold.

Degenerations: local model gives nilpotents over a ring, these are called degenerations.

Topological vector space of compactly supported test functions: motivation is distributions, these are locally convex (convex gives valid distance measures), and complete with respect to uniformity. This is also an example of an inductive limit of Frechet spaces. 

Integers to rationals: take fraction field of integers to form rationals, this is what we call adding units or localisation at 0 (consider Spec Z)

Rationals to reals: go from the rational numbers to the real numbers by adding all limits, several constructions available like Dedekind cuts.

Dedekind completion: only completes a field, Dedekind completion fails on merely a poset.

Dedekind completion as a completion: this is a completion from a poset to a lattice

Fraction field completion: completes by filling in gaps where there should be a fraction.

Locality: holds on the space if it holds for some open cover, what about local if we use etale maps?

Subfield of C is an extension of Q: since nontrivial subring is char 0, must contain integers, so extension of rationals

Irreducible components: connected components of sufficiently small dense opens?

Reduced: no nilpotents

Irreducible: no zero divisors that are not nilpotents

Sheaf of functions: varieties with no nilpotents

Absolute Galois group: the following are equivalent: Galois group of the separable closure of field K, automorphism group of algebraic closure by inner automorphisms.

Inner automorphisms: automorphisms given by conjugation action of fixed element: we have p_g be a map from finite group G to itself such that it is (1/g)xg or right conjugate.

Absolute Galois group as an example of a profinite groups: this is isomorphic to the group of profinite integers or the inverse limit of the cyclic groups of order prime.

Profinite integer: element of the ring of product of all cyclic groups of order prime.

Profinite group as the set of sequence of residues, this is the sequence of v_i mod i.

Universal property of the profinite group: any profinite group H, group homomorphism from  integra to H, then there is a unique continuous groups homomorphism from the profinite integers of H, profinite integers feel like free group in this case.

Profinite integer representation: this is the sum of a_i i! Using factorial notation, so we have (…, c3 c2 c1)

Profinite integer constructed from the Chinese remainder theorem: is the product of all cyclic groups equal to the inverse limit of cyclic groups due to the Chinese Remainder Theorem.

Profinite integers topology: compact Hausdorff. Proof: closed subset of the infinite direct product using the Chinese Remainder Theorem. With this product topology, it is compact and Hausdorff.

Metric on the profinite integers: reciprocal if the minimum positive integer such that z is not congruent of y modulo (k+1)!. Addition of profinite integers is continuous, so the profinite integers form a compact Hausdorff abelian topological group, its Pontrygain dual is discrete and abelian.

Algebraic closure of a finite field: Galois group that is isomorphic to the cyclic group is the inverse limit of cyclic groups modulo n. So the Galois group of algebraic closure of finite field of q order quotiented out the same finite field of q order is the profinite integers.

Example of Galois group of of finite field with prime power quotiented out by the same prime: this is isomorphic to the cyclic group of order prime.

Etale fundamental group: profinite completion of automorphisms where Pi_1(X) is the direct limit of X_i / X, where X_I to X is an etale cover.

Example of an etale fundamental group: profinite integers is isomorphic to the etale fundamental group of the spectrum of finite fields. Profinite integers are therefore embedded in an algebraic torus.

Absolute Galois group of the reals: cyclic group of two elements, one is the identity, the other is the complex conjugate.

Absolute Galois group of an algebraically closed field and of variable C[x] where C is a field: it is free of rank equal to the cardinalotu if C.

Compact groups especially cyclic groups: they are used in the study of harmonic analysis by means of representation theory.

Linear representations in Hilbert space: representation is isomorphic to Hilbert direct sum of unitary representations of finite dimension.

Character table of a cyclic group: realised as rotation of 2 pi k/b about axis. Character of r is w, the character of r power is w power, so characters are that of exp(2 pi h k/n). This is an abelian group, since exponential add by multiplication.

Character table of the cyclic group of infinite order: this is the group of rotations on the plane, represented with basis exp(ina) n integer and angle a, orthogonality resolutions give orthogonal basis of Fourier series. Delta_{nm} is 1/2pi * integral of exp(-ina) exp(ima)

Character table of dihedral group of a plane of infinite order: rotations and reflections preserving the origin, contains the cyclic group of infinite order, let s be the reflection we have sr_a(1/s) = r_(-a). The dihedral group of infinite order. A then be written either as ra belonging to the cyclic group or not. This therefore looks like two disjoint circles in topological space. The invariant measure is (da)/4 pi. The average of integral of the Haar measure is the sum 1/4 pi integral of f(r) da from 0 to 2 pi of one circle, then that of f(sr) as well.

Dihedral group of order n: these are rotations and reflections such that action r with n times is 1 (characteristic r), reflections are characteristic 2 i.e s^2 is identity, then inverses are conjugate i.e sr(1/s) is (1/r). Elements can either be r^k or sr^k.

Residual class of dihedral group of order n: these are matrices [ exp(2 pi i h k/n, 0; 0, exp( -2 pi i h k/n)] for linear representations of r^k, the terms are flipped about the diagonal for the reflection.

Prime field: unique minimal subfield of a field, it is isomorphic to an element of Spec(Z)

Examples of characteristic: ordered fields like rationals, reals, complexes, algebraic number field are of characteristic zero, fields like finite fields or p-adic fields are of characteristic p.

Ring homomorphism alternate definition: the following are equivalent we have (1) one homomorphism unique from integers to any ring; (2) morphism from initial object of integers to any ring.

Structural theorem of semisimple algebra consequences: K[G] is a product of matrix algebras over skew fields of finite degree over K.

Integral over integers: let R be a commutative ring, let x be an element in R, the element x is integral of Z if nonzero inters exist and coefficient integers of sequence a_1 to a_n such that the binomial expansion of x with coefficients is equal to 0 or simply solution of polynomial equal to 0 with coefficients integers

Algebraic integer: complex number j reveal over the integers. Typical example is the root of unity.

Algebraic integer over rationals are integers: if not rational than consider binomial expansion of (p+q)^n with p/q, q more than 1 as integer and p, q for prime, gives 0 so q divides powers of p, contradicting coprimality.

Isotypic representation: direct sum of isomorphic irreducible representations.

Semidirect product: G is a semidirect product of H by A where the following are equivalent (1) G is equal to A H; (2) intersection of A and H is trivial group; (3) each element of the G can be written uniquely as a product ah with a in A and h in H.

Solvable group: the following are equivalent: (1) G is solvable if the filtration sequence from the trivial group is such that each group is normal to the next subgroup and the quotient group of the entry group by its previous entry normal subgroup is abelian.

Supersolvable: solvable group requiring all members of the filtration be normal subgroups be normal and quotients of entry group by its previous entry be isomorphic to cyclic group.

Nilpotent: supersolvable and additionally the following are equivalent (1) each quotient with its adjacent (G_i/G_{i-1}) in the filtration needs to be in the center of G/G_{i-1}, for integer i with at least inclusive 1 and at most inclusive n. Find Borcherds notes from Lie groups; (2) the group is obtained from the trivial group by a finite number of central extensions.

Brauer theory: representations of finite groups in characteristic p with those in characteristic 0 are compared.

Algebra over a field: let G be a finite group of order g, K be a commutative ring, K[G] be an algebra of G over K, basis indexed by elements of K. The functions f in the algebra over K, K[G] can be written as linear combinations of the left coefficients in the field K, with group elements s such that it is the sum of a_s * s for element s in the group G.

Center: element commuting with all other elements of a center.

Center definition of an abelian group: an abelian is a group that is equal to its center.

Basis of the center: for c in conjugacy class, let e_c be the union of all elements in each conjugacy class, then e_c forms basis of the ceneter, so the dimension of the center is the number of conjugacy classes (check this I think I might have made typos)

Modular character or Brauer character: function from the set of p regular elements to the valuation ring A

Artinian ring: the following are equivalent, decreasing sequence of left ideals is stationary; left A module has finite length; finitely generated left A modular finite length.

Example of Artinian ring: algebra of finite dimension over a field K is Artinian, K[G] for finite group.

Grothendieck group: we have a ring A, F be the be the category of left A modules, the Grothendieck group of the category F is an abelian group with generators for each left A module and relations [E] = [E’] + [E’’] associated with exact sequences such that 0 is to E is to E’ is to E’’ is to 0.

Projective module: the following are equivalent: (1) free module in which P is a direct factor; (2) surjective homomorphism f from E to E’ of left A modules, every hom g’ from P to E’ such that there exist a lift g from P to E where g’ equals to f g; (3) the functor from category E to hom sets of projective modules Hom_A(P, E) is an exact functor for E a left A module.

Discrete valuation of a field K, K be multiplicative group, it is a surjective field homomorphism such that v(x + y) is more than or equal to least upper bound of valuation of x and valuation of y. Then when the valuation is extended to the field, the valuation of 0 is infinity,

Completeness of topology with respect to topology defined by powers of m: the canonical map from the valuation to the projective limit A/m^n is an isomorphism. See algebraic closure.

Characteristic of a field: smallest positive integer such that the sum of 1s with this many integers is 0, if it exists. If it does not exist, then it is 0.

Forgetful functor from G-modules to real Lie group; left and right adjoint are called Casselman and Wallace globalisation functors.

Frobenius reciprocity: generalisation of quadratic reciprocity, restriction of representation do adjoint (right adjoint) to induction on representation

Induction: the following are equivalent: (1) consider subgroup H of group G, R is a system of left coset representatives of subgroup H. Let V be a complex G group C[G] module, and W be the corresponding submodule using subgroup H. The module V or the representation V is induced by G if V is the direct sum of sW for left coset representatives of S in R or V is a direct sum of images sW; (2) W is tensor product of C[G] and W over the C[H] module, be the C[G] module obtained from W by a scalar extension from C[H] to C[G], injection W to V extends by linearity to a C[G] homomorphism, i from W’ to V.

Group elements congruent modulo subgroup: these belong to the same left coset.

Artin’s theorem motivation: character in group G is. A linear combination with rational coefficients of representations induced by the direct sum from cyclic subgroup.

Brauer’s theorem as a generalisation of Artin’s theorem: character in the group G is a linear combination with integral (formable into polynomial as linear combination) coefficients of characters of representations induced from the elementary groups of G.

Brauer’s theorem and elementary groups: motivates the definition of elementary groups, these are groups that generalise Artin’s theorem from cyclic subgroup.

Mackey’s criterion motivation: tells us when an induced representation is irreducible

Frobenius reciprocity as a formula: it is a formula relating the class function induced on a subgroup and its restriction calculated on the full group.

Group product vs semidirect product: group product  form pairs, but semi product forms uniquely from each product of elements s in G and t in H given that their intersection is the trivial group.

Induced function: the class function on H where you take the average of conjugates or integral of Haar measure where the main element is in the full group and the conjugate is in the subgroup. We say that the I function is induced by F for the group G, subgroup H. This is OK since class functions are constant on members of conjugacy classes

Properties of induced representation: (1) exists and unique; (2) canonical isomorphism from Hom sets between Hom^H(W, E) and Hom^G(V, E), induction is transitive from associativity of the tensor product.

Frobenius theorem: the semidirect product of the Frobenius kernel and the Frobenius complement is the full Frobenius group. Exercise in Serre. Each linear representation of subgroup H extends to a lienar representation ofG whose kernel is N, the set of elements of G which are not conjugate to any element in N. Therefore N union {1} identity element is normal subgroup in G.

Algebraic scheme over a field K: (1) scheme X and morphism of finite type from scheme X to prime spectrum of a field Spec(K); (2) scheme X has a finite covering by affine opens with coordinate rings as finitely generated K-algebras. Coordinate ring of affine open U may be denoted A(U).

Morphism of finite type in schemes: morphism f of schemes X to Y has covering of affine open subschemes V_i = Spec(A_i) such that preimages V_i has a FINITE covering by affine open subschemes U_{ij} = Spec(B_{ij}) of X with B_{ij} an A_i algebra of finite type.

Morphism of finite type in commutative algebra: ring homomorphism of A to B of commutative ring, B is called an A-algebra of finite type oif B is finitely generated as an A-algebra, much stronger for B to be a finite A-algebra, which means B is finitely generated as an A-module.

Point of scheme: 0-dimension subvariety of scheme X. Visually, a dot.

Function field of variety R(V) with example: V is subvariety, then R(V) is the residue field of the structural sheaf of O_{V,X} quotiented out by the maximal ideal M_{V,X}

Point rational over the ground field if function field of variety R(P) = ground field K.

Closed subscheme Y of scheme X: defined by ideal sheaf F(Y) in the structural sheaf O_X of X, from an affine open covering of X, Y corresponds to an ideal in each coordinate ring of X, this comes equipped with a closed imbedding Y -> X. Imbedding / subscheme is typically assumed to be closed unless prefixed by "open" or "locally closed".

Plane curve xy not isomorphic to poly ring in one variable: A[Z] = k[x, 1/x], but x = 0 not in k, therefore not isomorphic to poly of one variable in k.

Variety: (1) reduced and irreducible (integral) algebraic scheme.

Subvariety: reduced and irreducible closed subscheme of X, subvariety V corresponds to a prime ideal in the coordinate ring of any affine open set meeting V.

Localisations are flat, equivalently a canonical homomorphism A to the localisation of A called S^{-1} A is flat: proof, N be a sub-A-module of M as A-module, by construction S^{-1} N is submodule of S^{-1} M, take tensor product in A: N *_A S^{-1} A -> M *_A S^{-1} A is injective (submodule) so by definition localisations are flat.

Nakayama's lemma false for ideals not finally generated: pick M = Q, I = (2), IM = M, odd numbers do not kill Q when M is nonzero. So M is not zero.

Nakayama's lemma: let A be a ring, I be the (Jacobson) radical of A (intersection of prime ideals of A), M is finitely generated A module such that M = IM, then M must be 0.

Proof of Nakayama's lemma (Qing Liu): let {x_1 to x_n} be generators for M, suppose n is minimal by well ordering of integers, exist coefficients a_i such that linear combination x_n = sum a_i x_i using the fact that M = IM, (1 - a_n)x_n = sum a_i x_i under condition that i < n, (1 - a_n) is invertible (used fact that it is a ring and I is the radical of A), n is minimal, so n = 1, x_n = 0.

Proof of Nakayama's lemma (Stack Overflow, identical to Qing Liu's): induction on generating set, M is generated by 0 elements so M is 0, suppose it holds for n - 1 elements {x_1, .., x_{n-1}} elements, let M be generated by n elements, then m_n is linear combination of eps_i m_i eps_i in J so (1 - eps_n) m_n = sum^{n-1}_{i = 1} m_i, divide by unit 1 - esp_n, m_n is linear combination of m_1 to m_{n-1}, by induction M = 0. 

Tensor product commutes with direct sum of modules over the ring (Qing Liu, Exercise 1.1): tensor products commutes with colimits since it is left adjoint to homs.

Unique A-linear map such that Hom_A(M, M') *_A Hom_A(N, N') -> Hom_A(M *_A N, M' *_A N'), (Qing Liu, Exercise 1.2): proof, unique by universal properties of tensor product and Hom, need to show existence, take A-linear map to be projection, composition of projection and identities commutative gives definition of such a A-linear map.

Canonical isomorphism for (M/M') and (N/N') with tensor product of the M *_A N quotiented over image i_N + j_M: proof if m and n are coprime, the product is 0, otherwise apply Qing Liu Corollary 1.13 to two exact sequences of that. Then for quotients you want to quotient out by sum of images.

R-algebra / associative algebra: (1) ring with (distributive) homomorphism f: R -> A such that subring f(R) is contained within the centre of A; (2) R-module with bilinear product such that a * (b + c) = a * b + a * c, (a + b) * c = a * c + b * c, (r . a) * (s . b) = (rs) . (a b), if * is commutative/associative/unital then it is a commutative/associative/unital R-algebra; (3) a ring is monoid object in category of abelian groups, now replace this with category of modules, get an associative algebra.

Example of associative algebra with square matrices: ring of square matrices over commutative ring K.

Example of ring being an associative algebra: any ring is an associative algebra over its sub-ring.

Example of canonical isomorphism of (M/M') and (N/N') with tensor product quotiented over images of submodules: consider (Z/nZ) tensored with (Z/mZ) = (Z/lZ), the kernels of these maps sent to zero are maps of dimension m and n forming equivalence class, since they form equivalence class for quotients, it is equivalent to taking the l being gcd(m,n)

Abelian variety: algebraic group that is geometrically integral and proper over field k, always projective and commutative.

Geometrically integral: let X be algebraic variety of k, k^b be the algebraically closure of k, we say X is geometrically reduced (respectively geometrically integral), if X_{k^} is reduced or integral. Similarly, for geometrically connected varieties and irreducible varieties.

Hartshorne vs Vakil's definition of morphisms of schemes: Hartshorne defines morphism at the level of stalks, ring homomorphism induces contravariant morphisms of schemes, construct ring homs on stalks, concludes that maps of sections from O_{spec B}(V) -> O_{spec A}(f^{-1} V) at the level of the preimages of V as contravariant; Vakil spends a chapter using compatible morphisms on distinguished basis elements (morphisms of affine scheme) and then glue.

Affine scheme: locally ringed space such that topological space + structural sheaf is isomorphic to prime spectrum of A and structural sheaf on prime spectrum.

Morphism of affine schemes: exactly a morphism of locally ringed spaces, or morphism of schemes.

Equivalence of categories for affine schemes and rings: proof, contravariant functor sending A to (prime spectrum of A, structural sheaf of Spec A).

Reduced scheme: all opens in scheme X the structural sheaf ring O_X(U) is a reduced ring (i.e. powers of f^m = 0 equivalent to f = 0).

Category of schemes has all fibre products ie. if Spec A *_{fibre product over Spec R} Spec B is isomorphic to Spec(A *_{tensor product over R} B): proof, for affines it is case of universal properties of fibre product of schemes, tensor product of rings, Yoneda lemma, for schemes, need to look at affine covers of X, Y, and S, then cover them with the fibre product at S and S_j indexed. These are affine and proved, now glue all of them. See Hartshorne for proof.

Points as fields: take Spec(Z), each point is a finite field, Z/mZ, or Q, so immediately you know the prime power stuff and composites are not finite fields by the classification using Spec(Z), so localisation gives fields, points are fields. See the Pandharipande joke in math life balance.

Fibre product of schemes is not the fibre product of spaces with extra structure: forgetful functor from schemes to topological spaces or sets do not have a left adjoint (or free). There is no left adjoint to the forgetful functor producing a scheme from set or topological space.

Weil conjectures: for a scheme X of finite type over integers (locally Spec A where A is finitely generated Z-algebra), then the analytic topology of X(C) i.e. complex points of X have a strong influence on the number of finite field F_p valued points i.e. X(F_p). Or you have generating functions (local zeta functions) derived from counting points on algebraic varieties on finite fields. Weil conjectured that zeta functions for smooth varieties are rational functions, satisfy some functional equation, and have zeroes in restricted places (feels like Riemann zeta function).

Weil conjectures on projective line: take X to be projective line, number of points is q^m + 1, where 1 is point at infinity, the variety is Riemann sphere, initial Betti numbers is 1, 0, 1. Striking about it is analogy with topology.

Deligne's first proof of the Weil conjectures: uses Lefschetz pencils, blow up, some Leray spectral sequence, find some eigenvalue of some sheaves, looks very complicated.

Weil conjecture on topology of space of solutions: correspondence between number of solutions of polynomials over finite fields correspond to topology of the space of solutions over complex numbers.

Motivation for motivic stuff: cohomology of algebraic varieties, too many cohomology theories, these are realisations of the same object, motive of a variety. Cohomology class is related to algebraic cycles as classes of cohomology theory. In some sense, motives should be the central point for these cohomology theories?

Failure of Veronese map by proj construction: from the fact that Proj T -> Proj S do not come from S -> T. P^1 -> P^2 is the Veronese map.

Dedekind cuts: a real number is a cut in the rationals

Fancy names and actual understanding: orbit stabiliser theorem is one of them. Borcherds showed the stabiliser action on faces of dodecahedron, fixing a side (orbit) then take stabiliser action, rotating to derive the total order of a group on icosahedron embedded in real space, however I never understood the statement in Silverman nor his proof of it.

Cuts: pair of nonempty subsets whose union is rationals, one set is upper bounds for the other and the set of lower bounds have contain largest element.

Members of covers are not covers: there exist elements in A that are not in cover, use word patches instead.

Circle not homeomorphic to disc by using connectedness: remove one point, circle is disconnected, but not disc, disc becomes connected torus.

Denumerable vs countable, countable may be finite, denumerable always has cardinality of integers.

Cauchy condition: for all norm bounds epsilon that is positive, there exists a integer called the minimum index such that the norm of the difference in two Cauchy terms is more than the minimum index is bounded by the positive norm bound epsilon.

Path connectedness implies connectedness: by contradiction, suppose path connected but not connected, find homeomorphism to disjoint union of closed intervals, contradicting connectedness of interval

Integral domain spatial intuition: I multiply stuff and I can’t walk back to 0, vectors in Z[i] lattice is what I use to imagine this.

Hom exact as generalisation of divisibility test: if Hom(-,M) is exact on this form: 0 to ideal to main module to module quotient out by ideal to 0, here they have generalised divisibility, consider case of principal ideal in integral domain case. Is it divisible by the generator of the principal ideal?

Cartesian pair of compact sets is compact; consider subsequence in component an and sub subsequence in component b, they both converge to (a,b) so Cartesian product is convergent. Induction on naturals makes this argument generalise.

Box of closed intervals is compact: example of induction on Cartesian pair of compact sets.

Limit of limit is limit: limits are idempotent.

Completeness of product if components are complete: complete means Cauchy sequences have limit, so consider limit of each component, exists in product space.

Closed subspace of complete space are complete: Cauchy sequences inherited from inclusion, limit in subspace due to closed.

Closed subspace of compact spaces are compact: convergence of Cauchy subsequence inherited from inclusion, limit in subspace due to closed.

Bolzano-Weierstrass: bounded sequence inherited R^m have convergent subsequence, proof bounded so in compact box up to homomorphism, closed boxes are compact, so convergent subsequences exist. 

Heine-Borel: closed and bounded boxes imply compact in R^m, proof: bounded so without loss of generality homeomorphic f to box, box is compact, limit in image if closed since limit in preimage if closed.

Failure of Heine Borel for general metric spaces: easiest counterexample is naturals with discrete metric. Striking one is C(unit interval, R) with L infinity norm, complete space but closed unit ball not compact.

Continuous image of compact sets are compact: proof by image of compact subsequences which must have limit in image of compact set, we used continuity to show existence.

Open sets closed set duality: complementation is how this duality is established

Epsilon delta condition: for map f, for all positive image bound epsilon at each point in domain, exists positive coimage bound delta in image such that distance between points is less than coimage bound epsilon implies distance between images of points is less than image bound delta.

Irreducible element different from zero divisor (CAUTION): field of two elements F_2, look at ring F_2[x] / (x^2), {0, 1, x, x+1}, note that x is irreducible, only pairs multiplying to x are x1 and x(x+1), both cases one of the pair is a unit, but x^2 is a zero divisor. Further R = Z/4 has irreducible element, but it is a zero divisor. I think this one is clearer.

Quadratic reciprocity calculation: Legendre symbol (q/p) to be 1 if p divides n^2 - q, -1 otherwise. Then (p/q)(q/p) = -1^((p-1)/2 * (q-1)/2). Determines integer solution to p dividing x^2 - a.

Hodge theory idea: cohomology has canonical representative given Riemannian metric on manifold, differential form vanishing under Laplacian of metric.

Ramification: square root function has two branches, now generalise this to other cases in geometry. Picture of Riemann surface of square root will be useful. There is ramificaiton theory of valuations, unramified morphism to define etale morphisms, aand tameness, local fields, algebraic extensions of rationals.

Graph, edge vertex colouring: no vertex, edge, face sharing a boundary have the same colour. Planar duality of points and lines generalise.

Riesz potential: definition for the inverse of a power of a Laplace operator (Laplacian, divergence of the gradient of f). Some singular integral. Some weak convolution.

Thom isomorphism: morphism from cohomology of X, to Thom space of vector bundle of rank n over simply connected CW complex.

Regular language: formal language that can be defined by a regular expression. Empty language is regular, singleton language is regular, Kleene star language is regular, union and concatenation is regular. No other languages are regular.

Regular expression: with boolean or, grouping example (gray|grey) is (gr(a|e)y); quantification with question mark, asterisk or Kleene star and Kleene plus. Question mark means not sure if preceding character is there: example {a?b} matches to "ab" or "b"; * means 0 or more occurences, example "hi*" means "h" or "hi" or "hii" and so on, + means one or more occurence of preceding "hi+" means "hi" or "hii" and so on, we have {} which does several functions {n} means exact match n times, {min,} means match minimally min, similarly for {,max} and {min,max}, there is also the wildcard character ., that matches any character.

Finite state machine: exactly in finitely many state of any times and can be changed via transitions based on inputs. Less computational power than Turing machine.

Ramification group: filtration of Galois group of a local field extension.

Complex conjugate pair of eigenvalues and eigenvectors: say we have e_2 e_3 = 1, e_2^2 = e_3, e_3^2 = e_2, we have eigenvectors [1, e_2, e_3]^T and [1, e_3, e_2]^T, which are a complex conjugate pair.

Lagrange duality: constraint problem is dual to abundance problem, min problem dual to max problem, related to duality of vector space in optimisation.

Harmonic conjugates (complex analysis): the following are equivalent: (1) real valued function u has harmonic conjugate if they are real and imaginary parts of a holomorphic function. Example f, holomorphic, u is real function, v is real function, then f = u + iv; (2) u and v satisfy the Cauchy-Riemann equations; (2) u + iv is complex potential, u is potential function, v is stream function, u and v have orthogonal trajectories see Cauchy-Riemann equations.

Projective harmonic conjugates: A and B points are harmonic conjugates if with respect to pair C, D, cross ratio (ABCD) = -1.

Contour integral: calculus of residues, direct integration, Cauchy's integral formula.

Contour: directed curve made up of a finite sequence of directed smooth curves, endpoints matched to give a single direction.

Picard's complex analysis theorem: all about range of analytic functions.

Entire function (integral function): complex valued function that is holomorphic on whole complex plane.

Examples of entire function: polynomial and exponential functions, finite sums, products, compositions of these like sine, cosine, sinh, cosh, error function.

Non-examples of entire functions: natural log, reciprocal, square root. Analytical continuation of functions fail for these.

Little Picard theorem: entire nonconstant functions have the set of values that is either the entire complex plane, or the centire complex plane minus single point called the lacunary value of the function.

Great Picard's: if analytic function f has an essential singularity at point w, any punctured neighbourhood of w, f(z) takes on all possible complex values, with at most a single exception, infinitely often. This can be clearly seen if you use Little Picard's.

Example of Great Picard's: exp(z) is entire nonconstant function that is never 0, exp(1/z) has essential singularity at 0, but still does not obtain 0.

Big Picard's proof sketch: work with some integral, then carefully think about disks and upper half plane. Use Riemann's theorem of removable singularities and Landau's theorem.

Casorati-Weierstrass's theorem: range of f is dense.

Little Picard corollary: image of entire nonconstant functions must be unbounded.

Sketch of proof of little Picard: modular lambda, holomorphic universal covering of the twice punctured plane. Construct using elliptic function, have it omit two values (use Liouville's theorem here), compose f with inverse of modular function, maps plane to unit disc implying f is constant, contradiction.

Alternate proof of little Picard: Consider f(z) - z_0 / z_1 - z_0 as linear approximation, f has holomorphic logarithm since C is simply connected with range omitting 0. Now take "Fourier transform" of entire function g, where f(z) = exp(2 pi i g(z)), the range omits all integers, use quadratic formula, entire function so g(z) = cos(h(z)).  h omits all complex of the form 2 pi n +- i cosh^{-1} m. n integer, m nonnegative, use Landau's theorem to consider h'(w) = 0 to make some large disk for one number range of h omits, so h'(w) = 0 instead, h is constant so f is constant by fundamental theorem of calculus.

Meromorphic function: on open subset D, function that is holomorphic on all of D except poles of function. Meros means part.

Algebraic geometry point of view of meromorphic function: function's domain is connected, meromorphic functions is the field of fractions of the integral domain of the set of holomorphic function. So holomorphic function feel like integers, meromorphic function feels like localisation of the integers to form the rational numbers. I think it is easier to work with locally connected with this example.

Locally connected: every point admits a neighbourhood basis of open connected sets.

Locally path connected: points admit a neighbourhood basis of path connected open subsets. This is quite the amazing definition now that I think about it since it makes locality so intuitive. You have some property done locally, then you make it a basis somehow (basic elements) to construct whatever you want.

Meromorphic function expression: ratio of two holomorphic function defined on D, poles coinciding with zero of denominator. Easiest to see, Laplace transform of rational functions.

Big Picard's (meromorphic): let M be Riemann surface, w a poitn of M, P^1(C) = C union point of infinity as Riemann sphere (projective plane), and f: M excluding w -> Riemann sphere be a holomorphic function with essential singularity at w, then on any open susbet of M containing w, f(z) attains all but at most two points on P^1(C) infinitely often.

Big Picard's meromorphic example: f(z) = 1/(1 - exp(1/z)) is meromorphic on C - {0}, complex plane with deleted origin. Essential singularity is z = 0, attains infinity infinitely often in any neighbourhood of 0, but fails to attain 0 or 1.

Big Picard's conjecture: idea is to locally glue, let U_1 to U_n be collection of open connected subsets of C covering punctured unit disk D\{0}, on each U_j there is injective holomorphic function agreeing on df_j = df_k oon each intersection U_j with U_k, differentials glue together to a meromorphic 1-form on D. This is quite motivating, but obviously really really hard.

Frobenius classification of finite dimensional associative division algebras: reals, complexes numbers and quaternions.

Homography: isomorphism of projective spaces.

Examples of measure 0 sets that seem big: Cantor set.

Prime element versus irreducible element: p is prime element if p divides a b means p divides a or p divides b, irreducible means p = ab implies a unit or b unit.

Wedderburn's little theorem: the following are equivalent: (1) all finite division rings are commutative and are finite fields; (2) no distinction between domains, division rings and fields for finite rings so it is a classification theorem; (3) Brauer group of finite field is trivial.

Sketch of proof of Wedderburn's little theorem: each step needs to be proven by the way: (1) commutative finite division rings are fields so we want to show commutative; center of division ring is subfield, center of D is Galois field, and characteristic of Galois field is prime; (2) Z/(p) be quotient ring over principal ideal (p) of Z, prime subfield of Z(D) is isomorphic to Z/(p), therefore vector space over Z/(p), and D is a vector space over Z(D), both vector space are of finite dimension, Z(D) has p^n elements, D has (p^n)^m elements, where n and m are dimension of vector space of Z(D) and D respectively; (3) show D is commutative, Z(D) is commutative by construction since it is a center, now show D = Z(D), or |D| = |Z(D)| since vector spaces are classified up to dimension considering them as module with m = 1; (4**) use conjugacy classes in it's Lagrange's theorem form, then do some screwy thing with contradiction which I don't understand. The hard part is establishing the class equation on the center of the division ring. (Ernst Witt's proof). Chevalley-Warning's theorem will help. Serre's Local Fields?

Division rings being simple: no two sided ideal besides zero ideal and itself.

Simple module: (1) nonzero modules with no nonzero proper submodules; (2) every cyclic submodule generated by a nonzero element of M is equal to M for simple module M; (3) analogous to simple groups in group theory.

C[x,y] as unique factorisation domain but not a PID: similarly Z[x], C[x,y], mainly a PID is always of dim 1, every poly ring with more than one variable coefficients in field, 

Euclidean domain: integral domain (product of nonzero is nonzero), with Euclidean function that enable's Euclid's algorithm for finding primes. It is very close to fields and algebraically closed fields. Or, a and b in R, b nonzero, existence of q and r such that a = bq + r.

k[X] as PID: degree of polynomial is a norm, need it to be a Dedekind-Hasse norm (it is an Euclidean norm), try Z[([1 + root(-19)]/2)], pair of polynomials have greatest common divisor d so it has Euclid's division algorithm.

Identity map on C([0,1]) is not compact, unit ball in C([0,1]) not compact for infinite dimensional vector space: counterexample is take functions of norm 1 supported on [1/(n+1), 1/n], unit ball in normed vector space is compact if it is finite dimensional.

Log-concave: three numbers x < y < z, we have y^2 >= xz.

Perron-Frobenius theorem: real square matrix with positive entries have unique eigenvalue of largest magnitude, with real eigenvalue. Defines leading eigenvalue with spectral radius equalling it, it is a simple root of the characteristic poly, there is a leading eigenvector. Key step for proof, Brouwer fixed point theorem.

Proof sketch of Perron-Frobenius theorem: positive matrix, spectral radius is 1 without loss of generality, consider another eigenvalue that is not 1 also fall on unit circle (i.e. maximum is not unique), so (KEY STEP) there is A^m positive, real part of lambda^m is negative, take T = A^m - eps I, this is positive matrix when we pick eps to be half the smallest diagonal entry, check that Ax = ex, then A^m x = e^m x so e^m - eps is eigenvalue, lies outside spectral unit disk p(T) > 1, BUT entries in T are positive and less than or equal to those in A^m but by Gelfand's formula p(T) <= p(A^m) <= p(A)^m = 1, contradiction, so eigenvalue is 1, no others exist on the unit circle. 

Motivation for Koszul complex: define cohomology for Lie algebras, ended up as a general construction. You can use it to prove facts about module depth.

Duality for depth of module and Krull dimension: these are corresponding notion of dimension.

Koszul complex: looks like projective sequence of wedge product for R-linear maps, let R be commutative ring, s: A^r -> A be an A-linear map, it is the wedge product *_{r} A^r -> *_{r-1} A^{r} all the way *_0 A^r isomorphic to A.

Motivating example for Koszul complex: let M be manifold, O(M) be ring of functions on it which is the commutative ring R of the Koszul complex, then we have s-linear maps picking functions. Simplest example of r = 1, picks function whose cokernel is ring of functions on zero locus f = 0 ("some opposite of kernel"), general case we have cokernel of last map where all the functions vanish, so it is the tensor product of r many Koszul complexes for f_i zero, dimensions given by binomial coefficient. We get the Koszul complex as derived intersections of zero locus, where as in algebraic geometry, the ring of functions of the zero locus is ring R quotiented out by ideal generated by (s1, ... s_r) as equivalent. So Koszul complex gives intersection where vanishing of these s_i are equivalent, in some derived sense using wedge product instead of inductive product.

Koszul complex as chain complex: this just means composition of any two maps is zero, and K_s tensor K_s to K_s just turns (a_1 ^... a_k) and (b_1 ^... b_k) to a_1 ^ ... a_k ^ b_1 ^ ... b_k

Koszul complex as derived tensor product of chain complexes of R-modules: for s-linear maps s = (s_1 to s_r), then K_s is isomorphic to K_s1 *... K_sr

Cohomology as ring: homology as equivalence classes of chains on X (simplices cannot be multiplied), cohomology as equivalence classes of ring valued functions over chains (can be multiplied). Need cup product to define ring multiplication (understoof as singular cohomology as prototype example).

Cohomology ring worked example: (1) sequence of cohomology groups H^k(X, R), coefficients in commutative ring R (pick your favourite: Z_n, Z, Q, R, C), define cup product: which tunrs H^k * H^l into H^{k + l}, cup product gives ring product on direct sum of cohomology groups. Define indefinite sum of cohomology group H^*(X, R) to be the direct sum of all cohomologry groups in naturals. Examples H^*(RP^n, F_2) gives F_2[alpha]/(alpha^{n + 1}), |\alpha| = 1.

Cohomology broad background: solve problems locally, local solutions are glued to global solutions.

Resolutions in defining cohomology: sheaf cohomology can be defined using injective resolutions existing in any cateegory of sheaves, but sheaf homology defined by projective resolutions need not always exist.

Examples of derived functor in cohomology: (1) sheaf cohomology as right derived functors of global section functor (this feels like sheaves by the way, recall sheaves are about existence of global sections) with De Rham cohomology and etale cohomology; (2) Ext functor: left derived functor of right exact functor of Hom_R(-, B): R-module to Ab^op with group cohomology, Hochschild cohomology and Lie algebra cohomology; (3) Tor functors: left derived functor of tensor product from Mod-R, R-Mod to Ab, examples are group homology, Lie algebra homology. Hochschild homology.

Quillen model structure intuition to derived functors: (1) fibrant cofibrant resolution of object apply that DERIVED functor, extend to whole category to preserve weak equivalences.

Examples of right derived functors: assume F is left exact, examples are F: A -> Ab given by X -> Hom(X, A) with right direct functor Ext^n(-, A), or X to Hom(A, X) with right derived functor Ext^n(A, -), global sections functors on sheaves with right derived functor which is the sheaf cohomology H^n(X, F), direct image functor with right derived functor R^nf_*(F).

Enough projectives: the following are equivalent: (1) for every object X, there is an epimorphism from a projective object P to X

Enough injectives: the following are equivalent: (1) for every object X, there is an monomorphism from object X into injective object I

Motivation for enough projectives or injectives: need to see where it fails, to have derived functors.

Liouville's formula: y' = A(t) y is some square matrix, this feels like eigenvalue equation, find some fundamental matrix P'(t) = A(t) P(t) let trace of A(s) = sum of i-thh diagonal entries then det P(t) = det P(t_0) exp (integral from t_0 to t of trace A(s) ds). Typically, over interval [0, 1] on reals.

Slogan for derived functors: right derived functors come from left exact functors, use injective resolutions; left derived functors come from right exact functors, use projective resolution.

Connection between derived functors to Kan extensions: derived functors with abelian category A can be seen as Kan extensions of embeddings of A into suitable derived categories.

Derived functors and derived category intuition: let A be abelian category, define a homotopical category with morphisms being hom-sets up to homotopy, then (simplicially) localise at it to get a derived category.

Universal property of derived category: localisation of the category of complexes with respect to quasi-isomorphisms.

Derived category: A abelian category, D(A) is a category, with functor Q from category of cochain complexes Kom(A) to the derived category D(A) with universal property, defined by universal property, C is another category (note, note abelian), and F: Kom(A) to C such that f^o is quasi-isomorphism in Kom(A), image F(f^o) is ISOMORPHISM in C, F factors to Q. They weakened universal property with quasi-issomorphism.

Category of complexes of A, Kom(Ab) as example: objects in Kom Ab are cochain complexes of C* of abelian groups, Hom(B*, C*) are morphisms of complexes f*: B* -> C* that are equivalent under homotopy.

Cochain complexes look like long maps of X^i such that differential (coboundary) of the differential is zero i.e. d^{i+1} * d^i = 0, ith cohomology group of H^i is defined by the kernel of the differntial map d^i (sending objects in X^i to 0) quotiented out by the image of d^{i - 1} (equivalence of elements in the image of the previous differential map for stuff in the kernel)

Image of integers in commutative field is integral domain: you get isomorphisms of Z to Q and Z/pZ to F_p. The former is characteristic 0, the latter is characteristic p.

Field of characteristic p, map s: x -> x^p is isomorphism of K onto subfields K^p: (1) verify that s(xy) = s(x)s(y), binomial coefficient is congruent to 0 mod p (same trick in Silverman when he proves Fermat's little theorem), conclude that s(x+y) = s(x) + s(y).

Multiplicative group of finite field F_q cyclic of order q - 1: proof using Euler phi-function, number of integers x with 1 <= x <= which are corprime to d, whose image in Z/dZ is a generator of this group. There are phi(d) = q - 1 generators of cyclic group of order d.

Zero ring: trivial field, excluded from a field, one maximal ideal (0).

Z[root(2)] not a field but with unifnitely many units: key step is using (1 + root(2))^n(-1 + root(2))^n = 1 by induction, so these are the only units using induction on b of a + root(2) b.

Gaussian integers of integral domain which is not unique factorisation domain: nonunique factorisation of (1 +- root(5)/2) and (3, 2) but it is a integral domain, products of two nonzero gaussian integers cannot be zero.

No ring of order 6 is an integral domain: key step is 2 * 3 = 0, so not integral domain. Lagrange's theorem gives 1, 2, 3, 6 as number of cosets of equivalence classes.

Finite integral domain must have power prime order: adapt the idea that no ring of order 6 is an integral domain for rings with order of products of two primes.

Product of ideals is ideal: (1) zero is in ideal; (2) check linear combinations of ideals to be in ideal i.e. = 0.

Final object: projective limit of functor with empty indexing category.

Initial object: inductive limit of functor with empty indexing category.

Category theory objects in set: we prove that in set, all finite limits and colimits exist. Here (1) final object is singleton, dually it is initial object which is the empty set; (2) projective limit or direct products is direct product of sets, inductive limit is coproduct which is disjoint unions; (3) equaliser of two mappings is equality of two maps in Set, with coequaliser being quotients under equivalence relations forming new disjoint unions of equivalence classes.

Products and pullbacks imply equalisers: (1) equaliser of f and g from A to B is equivalently the pullback of (1,f) and (1,g) from A to A * B (product) cones over pullback diagram of (1,f) and (1,g) have projections pi_1 = pi_2 such that f * pi_1 = g * pi_2.; (2) morphisms f, g from A to B, pull back of diagonal map Diag_Y = id, id: B to B * B, along f, g from X -> Y * Y is the equaliser of fand g.

Projective limit as representative object: projective limit can take the place as a representative object of a functor.

Examples of minimal injective abelian groups over commutative rings: Q is localisation of Z by the complement of prime ideal, Q_(p)/Z for prime p, Q_p additve groups of rationals.

Projective module: the folowing are equivalent, (1) direct summand of free modules, (1a) direct summand of projective modules; (2) lifting exists i.e. every surjective module homomorphism f: N ->> M and every module homomorphism g: P -> M, there is a module homomorphism called the lift h: P -> N such that fh = g; (3) every short exact sequence 0 -> A -> B -> P -> 0 is split exact sequence i.e. surjective module homomorphism f: B ->> P, section map exist that h : P -> B such that fh = id_P so h(P) is a direct summand of B, h is an isomorphism from P to h(P), hf is a projection on summand of h(P) or B = Im(h) ++ Ker(f), Ker(f) = A, Im(h) is P or EASIEST FOR ME: 0 -> Ker(f) -> Im(h) ++ Ker(f) -> Im(h) -> 0; (4) the functor Hom_R(P, -) for P as R-module is exact, if 0 -> N_1 -> N_2 -> N_3 -> 0 is an exact sequence, then 0 -> Hom_B(P, N_i)... -> 0 is exact (fill in yourself, see Michael Artin's notes)

Split exact sequence: short exact sequence is exact if isomorphic to exact sequence where middle term is direct sum of the outer ones 0 -> A -> A ++ C -> C -> 0. From A to A ++ C is a injective, and A ++ C to C is a projective.

Examples of split short exact sequence in vector spaces: (1) we have 0 -> A -> A ++ C -> C -> 0. From A to A ++ C is a canonical injective, and A ++ C to C is canonical projective, A, C as R-modules; (2) any short exact sequence of vector spaces are split exact; (3) any set of linearly independent vectors in a vector space can be extended to a basis.

Example of non-split exact sequence: we have 0 -> Z -> Z -> Z/2Z -> 0, first map is multiplication by 2, note that Z ++ Z/2Z is ???.

Exact sequence: Ker(f_{i+1}) = Im(f_i) for exact complex is exact sequence, example 0 -> M -> N is exact if and only if M -> N is injective.

Exact sequences of A-modules are exact on tensor products: proof from Qing Liu, surjectivity comes from g since every element in tensor product can be worked as linear combination of tensor product of basis elements, so surjective (but not general products, Cartesian product reduces to tensor product). Now show Ker(g_M) = Im(f_M) for N'-f> N -g> N'' -> 0 and N' * M -f_M> N * M -g_M> N'' * M 0< 9. Take quotient of tensor product with map f_M is isomorphism, this makes it isomorphism under equivalence relation.

Canonical isomorphism of (N *_A M)/(Im i_M) is isomorphic to (N/N') *_A M for N, M A-modules, N' submodule: proof is to apply exact sequence of A-modules exact on tensor products on exact sequence N' -> N -> (N/N') -> 0, pick N = A or ring, and N' = I or ideal using the fact that tnesor product of A-module M with A isomorphic to ring A-module M.

Projective module as locally free: projective modules are "locally free", such that localisation at every prime ideal is free over the corresponding localisation of the ring (with basis vectors). Similarly, vector bundles are locally free (hint, think of free group as alphabet and vector spaces) since projective modules (over certain commutative rings) are analogues of vector bundles.

Properties of projective modules: e = e^2 is idempotent in ring R, Re is projective left module over R.

Module theory properties: free implies projective implies flat implies torsion free. Note: some define torsion free modules over a domain, torsion free means there are no nonzero torsion elements.

A-module is flat equivalent to torsion free over A proof: define nonzero ideal aA over A, t_a denote multiplication of a in A, u_a denote multiplication of a in M, then t_a: A -> aA is isomorphism, commutative diagram shows that t_a * Id_M + f = u_a, f is canonical hom from I *_A M to IM, f is isomorphism if and only if u_a is isomorphism, so kernel ax = 0 implies x = 0.

Torsion element: TFAE (1) an element x is torsion if there is a nonzero a in A such that ax = 0;

Flat module that is not projective: example abelian group Q is a Z-module that is flat, but not projective.

Flatness when A is Noetherian, A[x] is flat over A, completions of Noetherian rings are flat over original ring so A[[x]] is flat over A[x], then use surjection A[[x]] -> A by mapping x-> 0

Power series ring of thing that is not field is faithfully flat but not free: Z[[x]] is not projective over A consider Z[[x]] isomorphic to infinite cartesian product of Z so it is not free (no nice basis?), if A is noetherian of dimension at least 1 then A is not projective over A, since it is not even projective, if it is not even free.

Relation amongst components of left A-module, let X be a left A module, (x_1, ..., x_n) be a finite set of elements in X, family of (a_1, ..., a_n) in A^n is a relation of sum of a_i x_i from i to n is equal to 0, generally Y^n is right A-module if tensor product y_i * x_i is zero for i from i to n i s equal to 0.

Small category: objects in category are sets.

Noetherian integral domain as unique factorisation domain: equivalent to every prime ideal of height 1 is principal. Note that a prime ideal of height 2 in a poly ring need not necessarily be generated by two elements. Counterexample in Hartshorne is the following, x = t^3, y = t^4, z = t^5 as parameters of curve Y in A^3, I(Y) is prime ideal of height 2 in k[x,y,z] which cannot be generated by two elements (need at least three generators). Proof: t -> (t^3, t^4, t^5) is homemorphism from affine line to Y, dim(Y) = 1, P has height 2. Generators are actually x^2y - z^2, zx - y^2, x^3 - zy with suitable substitution.

Subcategory fullness: if Hom_C(X, Y) = Hom_D(X, Y) for any X, Y objects of subcategory C.

Faithful functor: homsets in domain category is injective into homsets in codomain category under functor action.

Faithful flatness (see Qing Liu proposition 2.17 in chapter 1.2.3): for M a flat module, the following are equivalent: (1) M not equal mM for every maximal ideal m of A; (2) N be A-module if M tensor N over A is 0, then N is 0; (3) f: N_1 -> N_2 be homomorphism of A-modules, if f_M: N_1 *_A M -> N_2 *_A M is isomorphism, so is f;

Full functor: homsets in domain category is surjective into homsets in codomain category under functor action.

Finite dimensional linear space as projective objects and inductive objects in the category of vector spaces of the field: it is projective because it is free with basis, it is inductive because the category of vector spaces is self-dual. 

Free module: module with basis elements.

P rank: decompose ideal class group into cyclic groups of order p power order

Presentation of a group: generating elements + constraining relation

Presentation of cyclic group: generated by roots of unity whose TFAE: (1) power is the identity, (2) power -1 is idempotent

Presentation of groups with relators: composed terms without equals sign is the identity, example a^n is a relator of the cyclic group of order n

Presentation of dihedral group of order 8, free group of rotations of order 8 called r, flips of order 2 called f, with relators r^8, f^2 and rfrf.

Free group: a group whose presentation has relators only.

Universal property of free group: any map f of sets (called the generating set of the free group) into a group, there is a unique group homomorphism p from the free group into the set such that the composition of the inclusion i of the set into the free group and group homomorphism p is f, this means f = p * i. Proof feels like Cayley’s theorem / Yoneda. The idea is that this unique group homomorphism is enough to work with and for all intents and purposes, replaces the group. So the group is replaced by a unique arrow from the free group into it.

Construction of free group: from universal property, we see this is left adjoint to the forgetful functor from the category of set to the category of groups, that forgets the group property forming its generating set.

Finite support: finite number of values in domain whose image is nonzero in value 

Totally separated: intersection of all closed and open neighbourhood of X is singleton

Totally separated implies totally disconnected, not the converse: fan with removal of single point gives Cantor space.

Quasi components: quasi comes from equivalence class, let (B, T) be topological space we say x and y are equivalent for x and y in A if A cannot be separated (A in topology T, subset of B into open disjoint neighbourhoods of X and Y. These form equivalence classes of x known as the quasi components of x. Equivalently, intersection of all closed AND open sets containing x. So quasi components is at least closed, but not open in (B, T) 

Containment of component definitions: the set of all components is contained in the set of all path components which is contained in the set of all quasi components.

Components: equivalence classes of connected open cover of x and y.

Path components: equivalence classes of path-connected open cover of x and y. 

Path homotopy: Path connected uses some homotopy (continuous family of maps idempotent by composition at endpoints), these form equivalence classes of paths.

Paths: the following are equivalent: (1) continuous map from nondegenerate closed interval to underlying set of topological space; (2) continuous map from closed unit interval to underlying set of topological space.

Idea of sites: categorical philosophy, instead of open sets as covers, you change this into jointly surjective maps.

Jointly surjective: jointly is doing a lot of lifting here, let p_i be family of maps from U_i to X, we say these family of maps are jointly surjective if the family of images of p with domains U_i under union is EQUAL to X. Note, U_i open gives etale cover, U_i pro-finite set gives pro etale cover. If you form this into a category (horizontal categorification of point with pro etale covers using finitely many families), this becomes the definition of a pro-etale site of a point. 

Locally presentable category: category where every object is a nice colimit of small objects in some small set.

Condensed set: sheaf of sets, pro etale covers i.e. opposite category of pro-etale site of point to sets, having this property locally on sets and has nice liability, descent in this case is agree on direct limits of fiber products of pro etale covers.

Fppf: French for faithfully flat of finite presentation

Fpqc: French for faithfully flat, quasi compact.

Definition by classification: sometimes objects can be defined by a procedure which creates a classification, then an object is generalised by the classification. Example: horizontal categorisation of monoid gives category, generalise this everywhere to say one object with all invertible automorphisms to become group.

Etale cover: family of maps p_i from U_i to X, we say these family of maps are jointly surjective if the family of images of p with domains U_i under union is EQUAL to X. Description feels like unique group homomorphism of free group into set. In this case, etale cover feels like a free group, such that family (not unique) of jointly surjective maps who union of images of U_i is exactly X, onto X. 

Terminal object: for every object in C, there is a unique morphism ! to the terminal object, this is an empty diagram unlike construction of free group, there is no composition or other inclusion, it is the simplest form of universal property construction. Therefore equivalently it is the limit of empty diagram.

Terminal object on sets: one element set, morphisms are families morphisms of representing each object onto the set. Horizontally categories to trivial category

Initial object on sets: empty set, whose domain using morphisms representing each object in set S onto image which is any set S.

Initial object: for every object in C, there is a unique morphism ! from the initial object, this is an empty diagram unlike construction of free group, there is no composition or other inclusion, it is the simplest form of universal property construction. Therefore equivalently it is the colimit of empty diagram.

Zero object: an object that is both an initial object and and a terminal object.

Pro object: formal cofiltered limit of objects, commutes with finite colimits. Projective object.

Profinite set: pro object in finite set, easiest way into profinite sets is Stone duality. By Stone duality profinite sets are totally disconnected compact Hausdorff spaces.

Ind object: formal filtered colimit of object, commutes with finite limits. Inductive object.

Filtered category: horizontal categorification of directed sets, see filters and ideals in lattice theory, directed set means there is upper bound for pair of objects (coproduct need not exist), filtered category means there is upper bound (coequaliser need not exist) for parallel morphism. 

Filtered diagram: diagram in filtered category

Filtered colimit: colimit in filtered diagram in filtered category.

Examples of filtered category: categories with terminal object and finite colimits, products of filtered categories is a filtered category 

Loop: the following are equivalent: (1) continuous map from circle to underlying set of space. 

Construction of totally disconnected quotient space. Example: take X arbitrary, equivalence of points if connected, this is equivalence relation giving equivalence classes of connected components of X, now quotient of X by this equivalence relation such that preimages of f(X) are open (i.e open) with quotient topology. The image you should have in mind makes it obvious that this is a totally disconnected space. It just looks like X, T, T with only connected components. 

Totally disconnected space: very local definition, only connected sets are singletons. A connected set is one that is not the union of two opens.

Cantor set homeomorphic to p-adic integers: canonical example that motivates profinite sets, compact Hausdorff totally disconnected space.

Field of p-adic integers as totally disconnected: motivation for profinite sets

Continuous images of totally disconnected spaces are not necessarily totally disconnected: continuous image of Cantor space are compact metric spaces.

Examples of totally disconnected spaces: rationals, irrationals, the Baire space (not Baire spaces in functional analysis), p-adic numbers, Cantor set, Stone spaces.

Totally disconnected spaces property preservation: subspaces, products, coproducts.

Radical of an ideal intuition: idempotent action of taking intersections. For number theory, take intersection of prime powers removing excess prime factors. Similar idea for ideals. Since it is an ideal, it is also an absorbing set to form closure under forgetting modules into abelian groups or subgroups that uses absorption of idempotent actions to give closed property.

Radical ideal intuition: ideal that has undergone radicalisation.

Nullstellensatz intuition in terms of duality: ideals are dual to varieties up to radicalisation.

Hilbert's Nullstellensatz: map from ideals in poly ring with a = rad(a) is equal to closed sets affine algebraic sets in the Zariski topology of field k^n, is BIJECTION, with an inverse where for generating elements f in the poly ring being in affine algebraic sets V where f(x) = 0.

Existence of nonempty affine algebraic sets for all proper ideals in poly ring k[X_1, ..., X_n]: proof, a is proper ideal, 1 is not in a (otherwise it will be full ring) so 1 is not in rad(a), rad(a) is proper ideal of k[X_1, ..., X_n]. By nullstellensatz, V(a) = V(rad(a)) which is not equal to V(k[X_1, ... X_n]) which is empty, so we have x in k^n with x in V(a). This tells us that exactly one of these two things happens: x in k^n such that f_1(x) = ... = f_m(x) = 0, OR we have g_1, ... g_m in ring k[X_1, ..., X_n] such that linear combination of f_i g_i up to m is equal to 1. This second possibilities prevents common zero.

Irreducible: same as connectedness in topology, cannot be written as the union of two basic objects. So irreducible varieties cannot be written as union of two varieties. I am starting to realise that lots of properties or definitions of irreducibility are meant to construct classes of basic objects. Interestingly, connectedness in topology means contains no clopen set, how does this affect definition of irreducibility.

Varieties intersection properties: Zariski topology of closed sets was invented to help remember the intersection properties, finite unions, arbitrary intersections.

Motivation for schemes using topology: topology fails since you cannot encode more information than single points.

Regular function construction: step 1 define quotients locally, step 2 glue neighbourhood of points as bases, step 3: regular function defined.

Regular function: let U be open subset of variety V, a function from U to coordinate ring C(V) is a regular function if for every point p of U, find an open set U_p in U containing p and a rational function f_p / g_p, g_p(x) nonzero, the set of all regular functions is the sheaf of opens in variety V. Regular function is special case of general sheafification.

Regular functions on distinguished open set: let U be open subset of variety V, a function from U to coordinate ring C(V) is a regular function if for every point p of U, find an distinguished open set D_g in U containing p and a rational function f / g^n, n in integers, g_p^n nonzero, the set of all regular functions is the sheaf of opens in variety V. Regular function is special case of general sheafification.

Global regular functions are the same as those in coordinate ring: notationally equivalent to O_V(V) = O(D(1)) = C(V), proof is by Nullstellensatz?

Differentiation as linear approximation: use the form derivative * f(h) + f(t) = f(t+h). It makes it obvious it is a linear approximation or models some form of failure in the linear homomorphism (feels like kernel of group homomorphism). More generally, one need not even use addition as the group or composition law. NOTE, we still want f(h) to be as small as possible to see how bad is the defect in this composition.

Scheme theory key example for cohomology: probably the twisted thin Mobius band; recycled everywhere to show how surjectivity fails globally. 

Fiber product construction intuition: define product locally, have it as a basis, construct twisting globally. Same way as locally compact i.e. all opens are covered by compact set.

Commutativity equivalent statements: the following are equivalent: (1) maps are self dual, no need for dual space; (2) left conjugate is idempotent; (3) right conjugate is idempotent; (4) commutator is identity; (5) identity is an canonical adjunction 

Normality: commutative means self normal, you can form self dual or some form of equivalence class / adjoint class / class, then when you take quotients, these are equivalent / adjoint in some sense so we deliberately lose information about it using combinatorics and look at a higher level / sub collections of it and see what structures we can form. So quotients mean we look at equivalence classes, finite quotients not a problem, infinite quotients require axiom of choice.

Inner product and natural transformations: condition for adjunction of Hilbert operators is on the level of inner products, which means that each component is commutative, and in some sense the sum of it is complete with respect to a field. Adjunction in categories obey this to some extent, with natural transformations being a global form of commutativity in composition and no worry about completion since composition of morphisms are morphisms (the same sort of guarantee helps with the Yoneda lemma).

Tensor hom adjunction intuition: you take homsets and reduce it to elements of codomain, same (up to natural transformation which just means if you compose maps that do this, you can form some “normal” class due to commutativity, as taking pairs of elements and reducing it to single elements called the tensor product. Normal classes are used in some sense similar to orthogonal or equivalence classes, commutativity is a condition to ensure these are equivalent in some way by thinking about self dual maps, identity being adjunction, idempotent action under left/right conjugation.

Homotopy equivalence in contrast to commutativity: you weaken the condition that instead of having an identity map as the adjoint action, you have a family of invertible continuous maps that are idempotent action at the right endpoint by composition of these maps (invertible to give idempotent action at the left endpoint) to give some sort of commutativity. That way you can define some sort of homotopy equivalence classes, and use quotients to identify a more macroscopic structure.

Free and cofree relative to forgetful functor: free is left adjoint to forget, cofree is right adjoint to forget.

History of ideals in lattice and ideals in ring: coincide in Boolean lattices using meets and joins, but weakened to partial order in general lattices.

Liouville's theorem for hamiltonian mechanics: (1) phase space distribution function evolves with time and is constant along trajectories. Valid for no friction, with no chemical reactions. Defines measure preserving systems  You can prove the fluctuation theorem (what is this), then derive the second law of thermodynmics.

Liouville's theorem for classification of holomorphic functions: (1, Gelfand/Manin) the family of holomorphic functions with domain of the Riemann sphere and sheaf of holomorphic functions on it consists of constant functions only; (2) every bounded entire function must be constant, i.e. for every holomorphic function f, whivh exists a positive M such that |f(z)| <= M for all complex z is constant.

Picard's little theorem: (1) every entire function whose image omits two or more complex numbers must be constant.

Spectral theorem: result when linear operator can be diagonalised and form some eigenvalues or spectrum or set of values k such that T = kI is not invertible.

Spectral decomposition: spectral theorem gives this decomposition.

Svarc-Milnor lemma: if a group G acts on a metric space X such that the action is cocompact, properly discontinuous and by isometries, then X is quasi-isometric to G with the word metric. Similar to when a group acts on a space transitively and you quotient out by the stabilizer.

Noether's theorem: continuous symmetry of the Lagrangian physical system corresponds to conservation law. Time translation invariance, energy conserved, space translation invariance, momentum is conserved.

Formulations of Noether's theorem: variational calculus on local action functional, variational bicomplex definition, moment maps.

Symplectic noether theorem: moment map of Hamiltonian action preserving a given time evolution is conserved by this same time evolution.

Motivation of implicit function theorem: k nonlinear equation in k unknown, in practice cannot event ell whether it has solution. Implicit function theorem reduces impossible questions to linear ones. However, it is limited to local linear approximations near (a,b)

Intuition of implicit function theorems: sufficient conditions for differentiable inverse of germ f_p of a differentiable map of smooth manifolds f: M -> N, invertibility works as germ is local diffeomorphism for some neighbourhood of p to some neighbourhood of f(p), then you can consider the tangent map.

Torelli's theorem: nonsingular projective algebraic curve (compact Riemann surface) is determined by its Jacobian variety given in the form of a principally polarised abelian variety for algebraically closed field.

Fubini theorem on Lebesgue measure: Lebesgue integrable on Cartesian product rectangle X * Y (product measure is needed), then double integral equivalent in evaluation with iterated integral. Warning: product of two complete measure spaces is usually not complete example Lebesgue measure of unit interval with itself is not Lebesgue measure of unit square. Fix by using complete measure.

Weaker Fubini's theorem on Riemann integrals: Riemann integral Cartesian product rectangle X * Y, if function is continuous, then double integral equivalent in evaluation with iterated integral.

Tonelli's theorem: apply to non-negative measurable functions.

Central limit theorem common misconceptions: (1) random sampling leads to normal distribution for sufficiently large samples of any random variable, in reality, it will reproduce properties of population; (2) theorem applies to random sampling of any variable, rather than mean values or sums.

Contragradient representation: let p be a linear representation p^{*}(g) is transpose p(g^-1) for all g in finite group G. Existence, use the standard basis of the dual of vector space. Uniqueness is tricky, you need the fact that the contragradient is always invertible (note: linear representations are maps to the general linear group of a vector space, so linear representations are invertible). Its character is the conjugate of the character of p. This follows because a finite dimensional matrix is conjugate to its own transpose, taking values in a field (using theory of modules over a PID: Smith normal forms of XI_n - A and XI_n - A^T are the same by symmetry. A and its transpose A^T has the same invariant factors, and has the same rational canonical form (Frobenius normal form), and hence they are similar over K.s

Characters of direct sum representation: direct sum of representations has their characters added. Proof is by considering Jordan blocks.

Characters of tensor product representation: tensor product of representations has their characters multiplied. Proof is by carefully considering sum of products of eigenvalues.

Characters of symmetric square and alternating square: let s be some element in finite group G, (1) X_Sym(s)^2 = 0.5(X(s)^2 + X(s^2)); (2) X_Alt(s)^2 = 0.5(X(s)^2 - X(s^2)); and (3) X_Sym^2 + X_Alt^2 = X^2. Proof: (1) choose basis consisting of eigenvectors, then we have p_s e_i = lambda_i e_i by eigenvalue eigenvector equation, and the result is that X(s) = sum of eigenvalues, X(s^2) = sum of eigenvalues squared. Now consider the definition of the basis of the symmetric squares and alternating squares, one should obtain the above which looks similar to the dimension expression which is obtained above. The third expression is simply because the tensor product of vector spaces is the direct sum of the symmetric square and alternating square representations.

Decompositions of (x + x')_Sym^2 into x_Sym^2 + x'_Sym^2 + xx': proof is by using Proposition 3 of Serre where X_Sym(s)^2 = 0.5(X(s)^2 + X(s^2)), you decompose once, the recompose again, be careful and state that it is x(s) where s its the element of the finite group. The same trick can be applied to the alternating representation.

Linear representation of Hom(V_1, V_2): see exercise 2.4 of Serre, let p_1 be a map from finite group G to the general linear group GL(V_1), let p_2 be a map from finite group G to the general linear group GL(V_2), let W be the set of linear maps (homomorphisms preserving vector space structure) W = Hom(V_1, V_2), then define for s in finite group G, and f in Hom-Vector space W we have p_s * f = p_2,s * f * p_1,s^{-1} so p_s f is in W. This is a linear representation p from finite group G to GL(W) since composition of linear maps is linear. Dimension is X_1^* X_2. 

Character of a representation: let p from finite group G to general linear group of vector space GL(V) be a linear representation. For each element s in the finite group G, put the character of the representation of p, X_p(s) = Tr(p_s). Defined so that it characterises p.

Properties of character of representation: let p be a representation of degree n, and X be a character of its representation. X(1) = n since the trace of 1 is simply degree n, X(s^-1) is equal to X(s)^* or the conjugate since p is of finite order, and a unitary matrix can represent this, X(tst^{-1}) = X(s), so this is preserved under conjugation, in fact it follows from Tr(ab) = Tr(ba) for two linear maps since sums of eigenvalues are commutative.

Tensor product of vector spaces / linear representations / matrices (Serre's definition for linear representation): map from V_1 x V_2 to V_1 * V_2 = W with map (x_1, x_2) -> x_1 * x_2 is tensor product if these two conditions: (1) x_1 * x_2 is linear; (2) if (e_i) is basis in V_1 and (e_j) is basis in V_2, then product of e_i e_j is basis in W. This exists and unique up to isomorphism (universal property).

Tensor product of module as as a universal property: of M and N over A, where M and N are A modules and a bilinear map from product of M and N to H, satisfying universal property, where if there is L which is a A-module, unique morphism from L to H gives commutative diagram.

Comparison of tensor product to free group: direct product is like free group of tensor project, then Hom is right adjoint like forget is right adjoint.

Tensor product of two irreducible representations is not irreducible: example rotation group SO(3), double cover SU(2). Decompose into V_{l} * V_{m} = V_{l + m} + V_{l + m - 1} + ... + V_{l - m}. Need more clarity. In general this is a problem of character theory.

Symmetric square and alternating square: V * V = Sym^2(V) + Alt^2(V), let p be automorphism of V * V such that p(e_i e_j) = e_j e_i for pairs e_i, e_j as elements of basis of V. Sym^2(V) is set of elements z in V * V such that p(z) = z, Alt^2(V) is set of elements z in V * V such that p(z) = -z. Symmetric sum (e_i e_j + e_j + e_i) is basis of symmetric square, whereas (e_i e_j - e_j e_i) is basis of alternating square. Dimension of symmetric square is n(n+1)/2, dimension of alternating square is n(n-1)/2, and these are stable under G for a vector space of dimension n.

Dimension decomposition of tensor product: dim(V_1 * V_2) = dim(V_1) dim(V_2)., this arise from condition 2 of tensor product from vector space

Moduli space: points are algebro-geometric isomorphism classes of objects, solutions to geometric problems.

Example of projective space as moduli space: real / complex projective space is a moduli space parametrising the space of line passing through the origin in real / complex space.

Projective space: identified with the quotient (C^{n+1}\{0})/(C^*) which are lines in C^{n+1}.

Projective space in terms of algebra: action of C* on poly ring C[x_0, ..,x_n] by multiplication of l in C*, l powers, direct sum decomposition is eigenspace decomposition, this defines the weight space.

Example of Grassmannian as moduli space: Grassmanian G(k, V) of a vector space over field K is moduli space of all k-dimensional linear subspaces of V. I think this is the example that is interesting since it talks about vector spaces directly.

Lindelof spaces equivalent to axiom of countable choice: the following are equivalent: (1) N, Q, and R are Lindelof spaces i.e. weaken compactness to use countable subcover / local refinement; (2) the axiom of countable choice holds for subsets of the reals.

Algebraic group: endow algebraic variety with a group structure.

Regular map: morphism of algebraic varieties, given locally by the polynomials.

Geometric transformations as algebraic groups: examples include orthogonal group (rotations), general linear group, projective groups, Euclidean groups

Affine algebraic group: algebraic group where the underlying variety is an affine variety. There is an exact correspondence to the subgroups of the general linear group.

Chevallay's structure theorem: (1) every connected algebraic group is an extension of an abelian variety by a linear algebraic group; (2) K perfect field, G connected abelian group over K, unique normal subgroup H in G, such that H is connected linear algebraic group, G/H an abelian variety.

Projective algebraic group: algebraic group where the underlying variety is a projective variety, formed by the abelian varieties.

Quotient group / factor group idea: similar elements are now made equivalent by an equivalence relation. Duality with subgroup.

Quotient group naming: compared to division of integers: 12 divide by 3 gives 4, 12 objects into 4 subcollections of 3 objects. G / N gives cosets of N in G, 4 cosets of 3 equivalence classes. The three objects in normal division are identical (not even equivalent). Axiom of choice becomes important when picking representative elements of equivalence classes.

Properties preserved by quotient groups of normal subgroups: abelian,nilpotent, solvable, cyclic, or finitely generated.

Fundamental theorem of homomorphisms: capture properties of quotient groups.

Isomorphism theorems: capture properties of quotient groups.

Subgroup quotient group duality: can be seen in (short) exact sequences.

Quotient object: three are quotient ring, space (linear algebra or topology), quotient set.

Involution: f^2 is idempotent or f = f^{-1}.

Fermat's theorem: every prime p - 1 is divisible by 4 is the sum of two squares, consider if two involutions act on a finite set, one fixes odd number of points so does the other. Let p = 4k + 1 be prime, let N be natural numbers, consider finite set of triples (x,y,z) such that x^2 + 4yz = p, x has two involutions (x,y,z) -> (x,y,y) is sum of two squares x^2 + 4y^2 and the other involution, (x,y,z) -> ... (fill in yourself), with one fixed point (1, 1, k) so it becomes 1 + 4z = p, so cardinality of this set is odd, hence S also has a fixed point with respect to the obvious involution.

Cantor's bijection: a bijection from the product of naturals to the naturals taking (x, y) to 0.5([x+y]^2 + 3x + y). Draw it out. This is the only quadratic bijection up to symmetry of variables (x,y) (y,x). Used to show cardinality of products of naturals is the same as that of the naturals.

Algebraist definition of 0^0: this is equal to 1, empty map from nothing to nothing. Also gives 0! = 1.

Matrix associativity with Einstein summation notation: ((AB)C)_ij = (AB)_ik C_kj = A_il B_lk C_kj = A_il (BC)_lj = (A(BC))_ij.

Hilbert basis Theorem: if R is Noetherian than R[X] is Noetherian.

Module has finite composition rings equivalent to Artinian and Noetherian module: prove using the finite composition series.

Left annihilator ann(x): set of a in ring R such that ax = 0. Kernel if R is an algebra (need not be always true), f: A -> A where f(x) = ax. This is a left ideal in R.

Left annihilator ann(x) in category theory: kernel of action map R to endomorphism ring End_R(M) determined by the adjunct map of the identity M -> M along the tensor-hom adjunction.

Degenerate bilinear form: bilinear form such that map from V -> V* where the following are equivalent: (1) taking v -> (x -> f(x,v)) is not an isomorphism; (2) when V is finite dimensional the map has a nontrivi	al kernel; (3) there exist nonzero x in vector space V such that f(x,y) = 0 for all y in V; (4) for finite dimensional vector space relative to basis, and teh determinant is zero or the matrix is singular form and in this case it is a singular form. This feels like the failure of the "Yoneda lemma" where objects and maps of objects do not correspond. 

Nonsingular form: map from V to its dual V* such that the following are equivalent: (1) v -> (x -> f(x,v)) is isomorphism in finite dimensions; (2) f(x,y) = 0 for all y in V implies x = 0.

Examples of non-singular forms: inner products, symplectic forms. This gives rise to symmetric nondegenerate forms to generalise inner products.

Example of generalisation of Riemann manifolds: manifold with inner product structure on tangent space is Riemannian manifold, so a manifold with a symmetric nondegenerate form is a pseudo-Riemannian manifolds.

Quotient of Noetherian is Noetherian: follows from Hilbert's basis theorem.

Finitely generated ring over Noetherian ring is also finitely generated: follows from Hilbert's basis theorem.

Composition series of module M: finite increasing filtration of module M by submodules such that successive quotients are simple and replace the direct sum composition of M.

Jordan-Holder theorem: two composition series of a given group are equivalent with the same composition factors, up to permutation and isomorphism. Proved using Schreier refinement theorem.

Schreier refinement theorem: two subnormal series of subgroups of a given group have equivalent refinements.

Zassenhaus / butterfly lemma: G is group with subgroups A and C, B is normal subgroup of A, and D is normal subgroup of C, there is this isomorphism of quotient groups: (A ^ C)B/(A ^ D)B is isomorphic to (A ^ C)D/(B ^ C)D. The Hasse diagram (diagram showing finite partially ordered set) looks like butterfly.

Goursat's lemma consequences: subdirect product of two groups can be described as a fiber product.

Primary decomposition / Lasker-Noether theorem: every Noetherian ring is a Lasker ring, every ideal can be decomposed as an intersection called primary decomposition of finitely many primary ideals (similar to powers of prime ideals). Extends fundamental theorem of arithmetic.

Primary ideal: the following are equivalent for proper ideal I: (1) for each pair of elements x and Y in noetherian commutative ring R such that xy is in ideal I, then either some power of x is in I or some power of y is in I or both; (2) every zero-divisor in quotient R/I is nilpotent; (3) Ass(A/I) consists of a single element; (4) set of zero divisors is equal to the nilradical.

Commutative ring has minimal prime ideal: proof requires Zorn's lemma.

Every prime ideal contains a minimal prime: proof: apply localisation at minimal prime ideal to localisation at p.

Equivalence of definitions for primary ideal (https://math.stackexchange.com/questions/804556/how-to-prove-assr-q-p-if-and-only-if-q-is-p-primary-when-r-is-noet): Zero divisors are union of associated primes in Noetherian ring, so the nilradical intersection of all minimal primes, every minimal prime is an associated prime, so the union of primes in Ass(R/Q) is equal to the intersection of minimal primes in (R/Q) which is equal to the intersection of primes in Ass(R/Q). Union = Intersection, occurs if |Ass(R/Q)| = 1, therefore P is the radical of Q for the single associated prime {P} = Ass(R/Q).

Associated prime of a module M over a ring R: the following are equivalent: (1) prime ideal of R that is an annhilator of a prime submodule of M. The set of associated primes is Ass_R(M), this is called the assassinator of M; (2) minimal prime over Ann(x) for nonzero x in R-module M

Union of associated primes of M: equal to the set of zero divisors of M if the ring is Noetherian. 

Support of a module: set of all primes p such that the localisation of the module at p is nonzero.

Consequence of Lasker-Noether theorem on algebraic sets: every algebraic set can be decomposed as finite union of irreducible components. I think it means that intersections of Lasker ring correspond to union of irreducible varieties.

Classification of finitely generated modules over PID canonical forms, consider R = K[T], algebra of polys with field K evaluated at T: invariant factors + companion matrix yields (1) Frobenius normal form or rational canonical form; primary decomposition + companion matrix gives (2) primary rational canonical form; primary decomposition + Jordan blocks gives (3) Jordan canonical forms (valid only for algebraically closed field).  

Finite dimensional matrix is conjugate to its own transpose, taking values in a field: (1) counterexample is left shift and right shift operators being adjoint to one another but not conjugate (consider kernels of these linear transformation), so you need finite dimensions; (2) [1 -5 ; 3 1] is not conjugate to its transpose in matrices over the integers, but are conjugate over the rationals, this is related to how ideals work in rings of algebraic integers.

Finite dimension matrix is conjugate to its own transpose, taking values in a field (using Jordan normal blocks): key step is to use Jordan canonical form (exists only for fields that split the characteristic polynomial), reducing it to single Jordan blocks.

Finite dimension matrix is conjugate to its own transpose, taking values in a field (using theory of modules over a PID: Smith normal forms of XI_n - A and XI_n - A^T are the same by symmetry. A and its transpose A^T has the same invariant factors, and has the same rational canonical form, and hence they are similar over K.

Smith normal form: normal form that can be defined for any matrix with entries in a principal ideal domain (every ideal generated by one element, it is principal ideal).

Rational canonical form / Frobenius normal form: canonical form for matrices by conjugation of invertible matrices over F, reflecting the minimal decomposition of a vector space into subspaces which are cyclic for A.

Subspaces cyclic for A: spanned by some vector and repeated images under subspace A for full vector space M(F), for field F.

Classification of finitely generated modules over PID: uniquely decomposed into sum of cyclic modules generated by invariant factors. 

Classification of finitely generated modules over PID, pick module R = Z: gets fundamental theorem of finitely generated abelian groups which is direct sum of primary cyclic group and infinite cyclic group. The invariant factor decomposition is equivalent to this classification by the Chinese remainder theorem.

Invariant factors of module M over PID R: finitely generated module M over principal ideal domain R, there exists a unique decreasing sequence of proper ideals such that M is isomorphic to the sum of cyclic modules, the generators of these ideals d_i are unique up to multiplication by unit, these are the invariant factors of the module M. Ideals are proper, so these factors are not invertible. These are a complete set of invariants for the module, so any two modules with the same set of invariants are necessarily isomorphic. It looks like the free part of M + sum of modules that has the invariant factors quotiented out. Proof of this is by taking finitely generated module M over PID is finitely presented, PID is Noetherian. Then take presentation and put it in Smith normal form, this gives invariant factor decomposition, diagonal entries of Smith normal form are invariant factors.

Alternate proof of invariant factor style decomposition: define tM torsion submodule, get short exact sequence 0 to tM to M to M/tM to 0. M/tM is finitely generated torsion free module (that was the goal of defining torsion submodule), this is free module of finite rank so isomorphic to R^n for positive integer n. Free module is projective module, right inverse of projective map exists, use splitting lemma M = tM + F. Prime element in R, you can talk about N_p as direct sum of cyclic modules and tM as direct sum of N_p to get the cyclic decomposition you want. 

Elementary divisors of module M over PID R: finitely generated module M over principal ideal R is isomorphic to the sum of indecomposable R/(q_i), q_i are primary ideals, whose elements are elementary divsors of M. This gives every finitely generated module over PID as completely decomposable, using the Lasker-Noether theorem.

Locally contractible: a topological space (X,T) that has a basis of open subsets consisting of contractible topological spaces. Again, basis is useful in defining local properties.

Contractible: a topological space (X, T) is locally contractible if the canonical map from X to a point is a homotopy equivalence. 

Whitehead theorem (classical): the following are equivalent for CW-complexes: (1) weak homotopy equivalence; (2) homotopy equivalence.

Homotopy equivalence: morphism f: X -> Y with a homotopy inverse. This is an equivalence relation.

Homotopy inverse: for morphism f: X -> Y, there exists g: Y -> X and homotopies g * f is 1_X and f * g is 1_Y. Homotopies are a totally ordered family of continuous maps graded along the unit interval such that composition of maps at the endpoint is idempotent. In this case, the family of maps are idempotent onto the identity at X and Y.

Reduced ring: ring R contains no nonzero nilpotent elements, r^2 = 0 implies r = 0 for any r in ring R.

Nonreduced ring example of matrix ring: [0 1; 0 0]^2 = [0 0; 0 0].

Nonreduced ring example, Z8: 4^2 = 0

Linear (Cauchy functional equation) but fails homogeneity: requires axiom of choice, consider a rational vector basis extending Q linear independent set {x nonzero x is not root(2)x}, f(x) = r != 0 and f(root(2)x) not equal root(2) r and the rest on B anyway you want. 

Irreducible / simple representation: nonzero vector space with no vector subspace stable under V except for zero space and whole space. Equivalent definition is irreducible representations are not the direct sum of two representations.

Every representation is the sum of irreducible representation: let V be a linear representation of finite group G, by classification of finite groups we can induct on dimension of V, dim(V) >= 1 valid, if V irreducible trivial, otherwise it can be decomposed into direct sum V'and V'' with dim(V) larger than these representations. By induction hypothesis V' and V'' are direct sums of irreducible representations.

Nonuniqueness of irreducible representations: typical counterexample is several possibilities of real lines to form a space in real plane.

General linear group of a vector space GL(V): group of isomorphisms of a vector onto itself, an element of GL(V) is a automorphism of vector spaces, it is invertible, and the inverse is linear. This is identified with the invertible square matrices of order n if we think of linear combination of basis vectors.

Linear representation in terms of group homomorphisms: homomorphism p from a (not necessarily finite) group G into the general linear group of a vector space, i.e. p(st_G) = p(s) *_GL(V) p(t). Picking 1 and the group inverse means it preserves the inverse. We say V is the representation space of G, or by abuse of language, the representation of G.

Subrepresentation of V of finite dimension exists: proof, take vector subspace generated by the basis elements of the group homomorphism.

Similarity of representations: representations are similar two representations are dual or adjoint to one another i.e. we have linear isomorphism t from vector space V to V' via the adjunction on the linear composition t * p(s) = p'(s) * t for all s in finite group G, if p and p'  is given in matrix form then there exist an invertible matrix T such that T * R_s = R_s' * T, therefore one R_s' is the conjugate (adjoint) such that R_s'= T R_s T^{-1}. Of course, invertible in this case means conjugate transpose for unitary similarity. See Horn and Johnson for more, the definition I presented here is from Serre.

Representation of degree 1 of a group G: homomorphism from the group to the multiplicative group of nonzero complex numbers. The values of the group homomorphism is the roots of unity.

Trivial representation: representation p(s) = 1 for all s in group G.

Regular representation: let g be order of G i.e. s^g = identity, let V be a vector space of dimension, linearly composed by basis elements e_t indexed by elements t of G, the group homomorphism rho_s sending e_t in the basis to e_{st} defines a linear representation called the regular representation. Degree of this homomorphism is the order of G.

Permutation representation: let V be a vector space, basis e_x for indices x in index set X, there is a linear map p_s that sends e_x to e_sx, satisfying permutation from x to sx where identity 1x = x and group action associativity s(tx) = (st)x for s,t in G, x in X so s and t are group actions. This linear p_s is the permutation representation.

Stability under action of G: for a vector subspace W of vector space V, and a linear representation p from finite group G to full space V, then W is stable under the action of G if x in G implies p_s x is in G. Restriction of p_s^W of p_s to W is an automorphism, so p_st^W = p_s^W * p_t^W where * is composition of linear representation, then p^W is a linear representation, and W is a subrepresentation of V. Typical example is the vector sum of basis elements to generate subspace of dimension 1 W as subspace of regular representation V.

Group orbit: group G acts on set X (group action), it permutes elements of X, element moving in fixed path is called orbit so G(x) = {gx in X such that g is in G}. The elements in set X are permuted. Intuitively, it is everything that can be reached from x by an action of something in G.

Stabiliser: set of g in G such that for set X we have {g in G such that gx = x}. Intuitively it is the set of alle lements of G which don't move when they act on x.

Example of group orbit: group acts on itself by conjguation, orbit is conjugacy classes, element stabilises another in this action exactly when they commute since gxg^-1 = x (stability) implies gx = xg (commutativity).

Group fixed point, absorbing element: an element sent to itself under all elements of the group. Example, set of 0, under action of multiplicative group of integers. 0 is the group fixed point or absorbing element.

Orbit stabiliser with circle group: G circle group, radius 1 as unit circle in C, G acts on X = C by multiplication, multiplication by exp(i theta) acts by rotation on theta. Fix x in C, orbit through x will be exactly circle of radius |x| except 0 which is {0}, stabilisers are when it is commutative, so zx = x only if z  = 1 for x nonzero.

Group action versus symmetry action: symmetry is bijective transform, group action extends this definition where every element acts like bijective transformation. Now have same group act on different set of features.

Orbit stabiliser theorem: feels like Lagrange's theorem, bijection between orbit of element on set of left cosets of stabiliser group x in G, so we have ...

Orbit stabiliser theorem on symmetric group of cube: fix one face, 4 ways to move the cube (stabiliser group), to rotate the cube, 6 possible faces (orbits), so 4 * 6 = 24. Group of order 24. Examples can be worked out ignoring reflections with dodecahedron and icosahedron of order 60, cube and tetrahedron order 12. 

Lagrange's theorem related to orbit stabiliser: H subgroup of G, H acts on G by left multiplication, orbit of 1 is H, |H| Or(G/H) = |G|, Or(G/H) is cardinal of the orbit space. Then cardinal of orbit space is equal to index of subgroup.

Direct sum of subspaces: W and W' is direct sum forming V if for x in V that is a superspace of W and W', v in V is linear composition of w + w'. Note that W and W' is disjoint, and the dimension of V = dimension of W + dimension of W' if we apply forgetful functor (dimension) of linear representations to integers. W' is a complement of W.

Projection of V onto W, and kernel of projection: suppose V is a direct sum of W and W', the mapping which sends x in V to component w in W is a projection of V onto W. W'is said to be the kernel of this projection. Reversing this example, projections of V onto W are in bijective correspondence to complements W onto V.

Complement exists for stable vector subspaces: let p from group G to general linear group GL(V) be a linear representation of G in V (we will find out that this is a unitary matrix IF scalar product exists), and W is a vector subspace of V stable under G, then (1) W^0 exists as complement of W in V ( we wil find out that this is a orthogonal complement IF scalar product exists), this (2) complement is stable under G. For (1) construct average of conjugates of p, P0 = 1/g sum of P_t p P_t^{-1} where P_t are group elements, g is the operator of G, this is similar to Reynold's operator for Hilbert's finiteness theorem for ring of invariants. Then this average of conjugates is shown to be a projection of V onto W, and is self adjoint onto the linear representation. Since this is self adjoint, we have the W^0 is dual to W, and is stable under G. Note that with inner product (i.e. V is inner product space) and selecting a suitable basis, this linear representation is a unitary matrix, and W^0 is the orthogonal complement of W.

Inner product space over R and C that are not complete: example is space of countable sequences that are nonzero for only finitely many entries. Square summable sequences will be their limit points. This is not a complete space, not all Cauchy sequences converge.

Completion of a ring construction: consider an E and abelian group with some filtration action F such that E = F^0 E containing F^1 E containing F_i E so on and so forth. This is a descending filtration. The completion with respect to the filtration is an inverse limit, this is an abelian group. The completion consists of elements a_n which are nonzero in the product of the quotient group of E quotiented out by each filtration of E, such that a_i congruent a_j modulo F_i E for all i <= j i.e. a_i - a_j is divisible in filtration F_i E for some definition of divisibility which I do not understand. This construction is also functorial, preserves short exact sequences (on FINITELY GENERATED R-MODULES).

p-adic integers as completion: complete the ring of integers at ideal (p) to get the ring of p-adic integers. Note that ideals are dual to filters.

Ring of all formal power series in n values over field K: complete the polynomial ring in n variables and complete it over the maximal ideal (x_1, ..., x_n) note that ideals are dual over filters. 

Formal power series, are sum of inner product of infinite sequence a_n and monomials of x.

Spectrum of formal power series Spec k[[x]], zero ideal, maximal ideals, ideals generated irreducible element.

Integral homomorphism: f: A -> B means B/f(A) is an integral extension.

Finitely generated k-algebra: A is an algebra which is quotient of poly ring over k.

Element a in A is integral of A_0: there exists monic polynomial sum_i a_i T^i in A_0[T] such that sum_i p(a_i)a^i = 0, called an integral equation for a over A_0.

Closed point of Spec A: let p in Spec A, {p} is closed in Zariski topology if and only if it is a maximal ideal, so p is a closed point in Spec A, point x in top space is closed if singleton is closed.

I-adic completion of ring R: noetherian ring completed over an ideal I = (f_1, ... f_n). This a flat module over ring R. This is also a noetherian ring. This is also a Noetherian local ring if you complete it over a unique maximal ideal.

Motivation for complete commutative ring: Hensel's lemma applies. Similar to localisation. This turns ring and modules into complete topological rings and modules.

Differential manifold paracompactness motivation: the following are equivalent for X being a differentiable manifold: (1) X is paracompact; (2) X is metrisable (1 to 2s is kind of the point); (3) X has differentiable partitions of unity; (4) each connected component of X is second countable; (5) each connected component of X is sigma-compact.

Locally compact: every point has a neighbourhood contained in a compact subset (open cover of that set admits a finite subcover) of X. Compare this with the definition of locally path connected for a better feel of local definitions.

Topological manifolds are locally compact: follows from existence of countable basis of precompact coordinate balls.

Topological manifolds are locally path connected, connected equivalent to path connected, components of M are same as the path components, and has countably many components, each is open subset of M: prove sketch start with rational balls, these are path connected open subsets on R^n, manifolds have a chart from this to its basis of path connected open subsets, so topological manifolds are locally path connected. Connectedness being equivalent to path connectedness follows from second countability. The rest follows from second countability anyway, all components are disjoint (Hausdorff), this must be the countable subcover of the topological manifold. See full proof from Lee's book but I captured all of the key points.

Topological connectedness: the following are equivalent (1) nonexistence of two disjoint, nonempty, open subsets whose union is topological space X; (2) topological space X contains no clopen set. 

Path connected: every pair of points in X can be joined by a path in X.

Topological path: continuous map from closed interval to topological space (X, T). Reminds me of mapping cylinders.

Existence of countable basis of precompact coordinate balls for topological manifolds: key step is probably homeomorphism to precompact rational balls by suitable coordinate chart. Use second countability to make countable subcover to cover the topological manifold with countably many coordinate charts, use Hausdorff to ensure if closure of these bases is compact, these balls are precompact in the manifold. See Lee's for fuller explanation.

Topological manifolds (Lee's): topological spaces that look locally like k^N, k field. The following are equivalent: (1) topological manifold; (2) second-countable, locally Euclidean of dimension n, and Hausdorff space.

Coordinate chart: a pair of set U also known as the coordinate domain and homeomorphism P from U to an open subset of R^n.

Graphs of continuous functions as topological manifold: pairs of points with y = f(x) with the SUBSPACE topology. Projection map to first factor Pi from R^n times R^k to R^n, and we have the restriction r from the graph of f Gamma(f) to open subset U, r(x,y) = x. The restriction is a homeomorphism to U, so the graph of f Gamma(f)and r is a global coordinate chart known as graph coordinates.

Spheres as topological manifold: shadow of sphere is homeomorphic to open in R^n.

Torus as topological manifold: product manifold of topological manifolds so it is a topological n manifold, pair of (HOMEOMORPHIC) product maps and images in open subset of R^n form coordinate charts. 

Projective space as topological manifold: set of 1 dimension linear subspaces of R^{n+1}, example, lines through the origin. Hausdorff since you can separate lines pointwise (inherited as subspace of Euclidean space), and second countable inheriting the countable bases of the rationals.

Projective space defined by equivalence relation: complex projective space CP^n is equal to C^{n +1} - 0 that is quotiented out by points (x_0, ... x_n) equivalent two sclar multiples of it e(x_0, ... x_n)for all eigenvalues in complex multiplicative group. These are the homogenous coordinates, ratios are well defiend when x_j is nonzero.

Standard cover of projective space CP^n: thesea rethe (n+1) many copies of C^n.

Projective space for any field k: more generally we have P^n(k) = k^n+1 - {0} quotiented out by multiplicative group of k. Caution, not the case for general ring R.

Projective space is compact: proof sketch restriction of sphere S^n (R^{n+1}) to complex projective space (RP^n) is surjective (looks like shadow casting, in fact it is Riemann sphere). But sphere S^n is compact, so RP^n is compact when we consider open covers on complex projective space RP^n, take an open cover on the sphere and its finite subcover, preimage of the projection map from the open cover RP^n to this finite subcover, and back again (surjectivity is used here) gives a finite subcover, so projective space is compact.

Chart centering: for a coordinate chart P(u) = 0, u is some point in U, then the chart is centered at u. You can center again the chart by subtracting vector P(u), note that vectors make sense here since it is a homeomorphism to a finite dimensional real vector space.

Second-countable: there exists a countable basis.

Locally Euclidean of dimension n: each point of manifold M has a neighbourhood that is homeomorphic to an open subset of R^n. Specifically, this means open subset U containing p in manifold, open subset V of Euclidean space R^n, and homeomorphism p from U to V. You can get equivalent definitions by weakening it to open ball or to R^n itself, rather than any open subset. The main property you want to preserve is connectedness when defining this.

Topological invariance of dimension: a nonempty n-dimensional topological manifold cannot be homeomorphic to an m-dimensional manifold unless m = n. Lee's book states you use some singular homology to prove this, but I think this would fail already if you can assume the fact that finite dimensional vector spaces R^n are classified up to dimension, and those are topological manifolds, so minimally dimension will be required for a homeomorphism.

Lorentz metric: metric defined so that gravity can be modelled.

Motivation for smooth structure: topological manifold + smooth structure gives some sort of derivative.

Sequences, nets, and filters: convergent sequences can fail when checking for closure, continuity, and compactness. This motivates the definitions of nets and filters.

Net: a function from a directed set D (called an indexing set) to X, directed set have preorder (not poset, be careful) on it. Proper filters correspond to nets.

Convergence of nets: let X be set, T be topology, so (X, T) is topological space, let v be a net from a directed set A to the underlying set X, we say the net v converges to an element x in X if given any neighbourhood U of x, v is eventually in the set U. This point x is a limit point of net. 

Clustering of net at clustering point: let X be set, T be topology, so (X, T) is topological space, let v be a net from a directed set A to the underlying set X, we say the net v clusters at point x if v is frequently in U for every neighbourhood U of x.

Uniqueness of limit point of X: limit points need not be unique except in Hausdorff spaces.

Motivation for subnets: since it is defined so that the theorem that the following are equivalent: (1) compact spaces; (2) space that every net has a converging subnet. This is the whole point of this, since for sequences we only have sequential compactness. 

Subnet: given a net (x_a) and a net (y_b) with index sets A and B respectively, we say y is a subnet of x if the eventuality filter of y refines the eventuality filter of x. Explicitly, for each a in A there is a b in B such that for every b_1 more than b_in B there is a a_1 more than a in a such that y_{b_1} = x_{a_1}.

Motivation for filters: to define subnets.

Weierstrass approximation theorem (original): supremum norm |f-p| less than epsilon on real intervals. Proof by Bernstein polynomials, slowly. There are versions for everything, C* algebra, reals, locally compact space.

Filter of a power set: let X be a set, T be a topology, P(X) be the power set of X. A subset of the power set of X is a filter of subsets if it is closed under intersection and under taking supersets.

Filter of a partially ordered set: a (NONEMPTY) subset F of poset L if it is upward closed and downward directed: (1) if A <= B in poset L, and A is in subset F, then B is in subset F; (2) for some subset A in poset L, A is in filter F; (3) if A is in filter F and B is in filter F then there is a C such that C <= A and C <= B. This is similar to filtrations in probability if you look at property 1. Further, filtrations are used in the construction of completion of functors of rings and modules that result in complete topological rings and modules.

Intuition behind filter: it is dual to the ideal of a lattice, which is very similar. The duality arises when a subset of L that satisfies the first two of the three axioms for a ideal in a lattice (inhibited, antisymmetric, reflexive, transitives) is precisely a directed subset of Y. 

Intuition of ideal: ideal is addtive subgroup in additive group R, absorbs multiplication on the left by elements of additive group R. So left ideal is left submodule of R, the considered as left module over itself, the over itself is absorption part. So unlike closure of subgroup or subspaces, ideals using this absorption property to ensure closure to make it module over itself, vector space over itself. Feels like a zero object.

Ideal in a lattice / proset: an ideal I is a lattice or a proset is a subset I in the underlying set L such that (1) ideal I is inhibited; (2) if x and y are in I then x, y are less than or equal to z for some z in ideal I (this corresponds to transitivity, existence of upper bound, antisymmetric); (3) if x is in I, and y <= x, then y is in I (this is dualised, in a filter if A <= B in poset L, and A is a subset of filter, then B is a subset of the filter. Here, abusing the same notation, it says if B is in the ideal, then A is in the ideal.)

Comparison to ideals in rings versus ideals in lattice: left ideal in ring is such that: (1) 0 is in the ideal which corresponds to the ideal being inhibited which is weaker; (2) x + y is in the ideal whenever x, y is in the ideal this is weaker than saying x, y <= z for some z in the ideal I; (3) xy is in I, whenever y is in I, regardless of whether x is in I (this regardless becomes OR for two sided ideals). From this comparison (NOT VERIFIED, THIS IS WHAT I THINK I UNDERSTAND), I think that ideals in rings are much more strict, since they enforce that the upper bound not just exist, but equals to the ring sum i.e. x + y = z, and also the product must exist if the elements forming the product is in the ideal such that the product ideal is a subset of the ideal.

Proper filter: a filter such that each set in it is inhibited i.e. there is no empty set in it.

Prime filter: a filter whose complement is an ideal.

Maximal filter: same as ultra filter, if it is maximal under proper filters.

Eventuality filter of a net: a proper filter

Sequences are a special case of nets: pick the directed set to be set of positive or nonnegative integers from 0 to infinity.

Directed set: preordered set with reflexive and transitive relation such that every finite subset has an upper bound (that way we do not have to use Zorn's).

Directed set of neighbourhoods: set of neighbourhoods is a directed set by reverse inclusion.

Motivation for nets: sequential compactness fails at detecting general compactness, since the natural numbers can be too short. So nets detect teh topology, topological continuity, Hausdorff and compactness.

Norm induced by inner product: maps from V to half open ray [0, infinity) such that norm ||v||^2 = inner product of v and v. Typical examples are for l^2 and L^2(Omega), where 1 is a sum from j = 1 to j = infinity of |x_j|^2 and the other is an integral of the norm of f(x)^2 over support Omega.

Proof that norm induced by inner product is a norm: nonnegativity by computation on example, homogeneity by considering product of scalar and its scalar conjugate. Triangle inequality gives inequality excess of 2 times the real part of the inner product of x and y typical of a binomial expansion.

Parallelogram identity: norm of square of (x+y) + norm of square of (x-y) gives two times the norms squared of x and y.

Hilbert space: complete inner product space with completeness respecting the norm induced by the inner product.

Polarisation identity: 4(x,y) = sum from n = 0 to n = 3 of i^n(x + i^n y)^2. Proof is easy by expanding the right hand side into four roots of unity.

Closed subspace of Banach spaces are Banach spaces: proof, if Y is complete than (x_n) in Y is Cauchy in Y so it is Cauchy is X, if Y is closed...

Schauder basis: motivated by the fact that the basis will always be finite dimensional even in an infinite dimensional space. Take a countable set of basis elements e_j from j = 1 to j = infinity for a normed space X. If every x in X can be written uniquely as a linear composition of coefficients in base field K with the basis elements e_j such that the sum converges in X, then it is a Schauder basis. Only separable Banach spaces admit a Schauder basis. The Schauder basis is powerful since it gives a unique infinite linear combination of basis elements.

Schauder basis proof of decomposition of linear combination of complex exponentials: any function in L2[0,1] or L2[-pi, pi] can be approximated by a Fourier series, since its Schauder basis is precisely that of the complex exponential exp(2 pi i n x) or exp(i n x) depending on the range of your infinite dimensional Hilbert space. This is a countable basis. Therefore, L2[0,1] and L2[-pi, pi] is a separable Banach space, approximated by countably many complex exponentials. Therefore, not all functions can be approximated by the Fourier series.

Orthogonal: inner product of elements is zero.

Orthonormal: all basis elements in E has a unit norm, and the inner product of pairs of basis elements is zero. Important, this does not require E to be countable.

Orthonormal set in l^2, this is just the set of e^(j) from j = 1 to j = infinity.

Orthonormal set on L^2{-pi, pi}. This is the basis elements with coefficient 1/2{\pi} and exp(ikx) for some integer x. Proof: inner propduct looks like Fourier transform, this is 1 when you have identical exp{ikx} and exp{-ikx}. If not identical, this vanishes when you compute the Fourier transform.

Generalised pythagoras: define orthonormality so that generalised Pythagora's falls out easily.

(Hilbert) adjoint of a linear operator: consider a linear operator from hilbert spaces H to K, then using the Riesz representation theorem there is a unique adjoint T^* in the set of bounded linear operators B(H, K) such that (Tx, y)_H = (x, T^*y)_K. Construction starts with f(x) := (Tx, y)_K, then since this is a bounded linear operator the norm of f(x) is less than or equal to the norm of the linear map T in the operator norm ||T|| of the space of bounded linear maps B(H, K), by linearity f is in H^*, therefore using Riesz representation theorem, you can get uniqueness.

Operator norm on the space of bounded linear maps: is the greatest lower bound / infimum of all M such that the norm of Tx in Y is less than M times the norm of x in X for bounded linear maps B(X, Y) from X to Y.

Motivating the Hilbert adjoint: generalises inner products (recall that Hilbert spaces is a complete space with endowed with an inner product). Consider the example of subsets S and T in set X, such that we have some indicator intersection norm where an nonempty intersection of S and T gives 1, and S and T disjoint gives 0. For a relation R from X to Y, there is a unique adjoint of the relation R^* from Y to X where <RE, F> = <E, R^*F> where R^* is the set of (y,x) such that (x,y) is in R. This is symmetric in the basic example of some indicator intersection norm.

Self adjunction of a linear operator: a linear operator such that T = T^*. Self adjoint linear operators have plenty of examples, and serve as generalisation of unitary / Hermitian / symmetric matrices.

Self adjoint of a linear operator and its spectrum: supposed linear operator T in the banach space of bounded linear operator B(H), then if it is self adjoint we have all eigenvalues are real, then if Tx_1 = e_1 x_1 and Tx_2 = e_2 x_2 with nonequal eigenvalues e_1 e_2 then the inner product of x_1 and x_2 is zero. Typical example is that of symmetric matrices.

Motivation for self adjoint operators in physics: these correspond to physical observables like mass, momentum (not like complex valued stuff like capacitance and inductance) on an infinite dimensional hilbert space.

Adjunction of right shift operator gives left shift operator: suppose we have s_r x = (0, x1, x2, ...) and maps s_r from l^2 to l^2 discretised Hilbert spaces, then we have s_r^* = s_l since we can see that s_r^* y = (y2, y3, y4, ...). We have that (s_r x, y) = (x, s_r^* y) or that the the right shift operator x is left adjoint to the left shift operator on y.

Right shift operator has no eigenvalue: proof is s_r x = k x, k is eigenvalue in field K. We have kx_1 = 0, kx_2 = x_1, kx_3 = x_2. If k is nonzero, then x_1 must be zero, so x_2 and the rest must be zero. So the spectrum of nonzero eigenvalues k is empty, therefore this is an example to how a linear operator may have empty spectrum or no eigenvalues.

Example of operator as functor: derivative operator is a functor from the category of pointed smooth manifolds to the category of vector spaces taking smooth maps f: (M, m) to (N, n) for m in M, n in N, f(m) to the derivative df_m from the tangent space T_m(M) to tangent space T_n(N). Chain rule is derived from respecting composition.

Linear subspace as algebra: subspace of a compact metric space A defined to be C(X, K), X subspace, K field such that the identity is in A and that it is closed under composition.

Arzela-Ascoli definition of compactness: for X a compact metric space, it is equivalently equicontinuous, closed and bounded. Note, you can modify this using nets and ultrafilters to avoid dependence on countability.

Stone duality definition of compactness: every limit point is point. Or with Stone duality, any decidable proposition is computable within finite time.

Bounded in the sense of norms: there exists a positive R > 0 such that the max norm (l^\infty) on the norm of f is less than R.

Bounded linear operator in the sense of norms: (1) there exists a positive R such that the norm of Tx in Y is less than R * the norm of X; (2) it is continuous (but only on normed spaces), for forward implication take small approx of L(x+h) - L(x) being bounded, for converse, use an epsilon delta proof.

Baire category theorem motivation: a form of axiom of (dependent) choice to ensure that no countable cover of proper subspaces of K^n exists, K being some field. See Tao's notes. Baire category theorem requires some form of the axiom of choice.

Dense: subset A is dense in set X if every point in X can is either in or close to a member of A. Picture: rationals are dense in reals as typical example. The following are equivalent: (1) smallest closed subset of X containg A is X; X is the closure of A in X; (3) interior of the complement of A is empty; (4) points in X either belong to A or a limit point of A (see intuition above); (5) for all x in X, every neighbourhood U of x intersects in A; (6) A intersects every nonempty open subset of X.

Baire category theorem, main result (Tao's definition): let E_1 and E_2 ... be a countable sequence of subsets of a complete metric space X, if the union of all this sequence contains a ball B (at least axiom of dependent choice is used here, when you take the countable union of this sequence and somehow gets a ball out of it by dilating the ball to be big enough), then at least one of the E_n is dense in a subball B' and B. The contrapositive is interesting: the countable union of nowhere dense sets cannot contain a ball. 

Baire category theorem, classical equivalent characterisation: any complete metric space, its underlying topological space is a completely metrisable topological space is a Baire space (this is the BCT1 definition). Recall that a metric space, completeness can be defined using Arzela-Ascoli (compact, bounded, equicontinuous). This requires the axiom of choice, or at least the axiom of dependent choice. However, you do not need the axiom of choice if the space is separable (i.e. it has a countable dense subset). This means the reals are Baire spaces, irrational numbers are Baire spaces, every Polish space is a Baire space.

Polish space: separable completely metrizable topological space homeomorphic to complete metric space with countably dense subset. Example, real line, separable Banach space, Cantor space. Motviation is to be used for measure theory.

Baire category theorem, alternative characterisation: every locally compact regular space is a Baire space. Also, every locally compact Hausdorff space is a Baire space. Examples: compact Hausdorff space like the Cantor set, or manifolds even if not paracompact (hence not metrisable)

Regular space: closed set F and point x not in F, then you can separate x and F with disjoint neighbourhoods always.

T3 space: regular Hausdorff space.

Quasicompact: open cover have finite subcover. Hartshorne also defines it this way. Topologists say this is valid enough for compactness, however this definition is used in algebraic geometry, where compactness is quasicompact + Hausdorff. 

Noetherian topological space is quasicompact: proof, ascending chain condition of opens terminates finitely.

Subset of noetherian topological space is noetherian in induced topology: pick maximal element (Zorn's), exists in induced topology.

Noetherian set which is also Hausdorff must be finite set with discrete topology: Hausdorff so single points open since minimal element exists in Noetherian topological space, single points open means discre topology.

Paracompact: if compact spaces have every open cover admit a finite subcover, then a paracompact space in which every open cover has an open refinement (new cover that has sets contained in the original cover) that is locally finite (sets intersects with only finitely many sets in collection). Sometimes people define paracompact to have Hausdorff also. Basically paracompactness is sort of the key idea in metrisation.

Lindelof: weaken compactness to use countable subcover / refinement.

Refinement of cover: a refinement of a cover C in a topological space X is a new cover D of X such that every set in D is contained in some set in the cover C.

Partition of unity: feels very category theory like, a set R of continuous functions from topological space X to the unit interval [0, 1] such that for every point x in X, there is a neighbourhood where all but a finite number of the functions of R are 0, the sum of all function values at x is 1. Classical example is partitions of unity of a circle unrolled to a line, then you have compositions of sine waves to form the flat circle. Bernstein polynomials are examples of partitions of unity. Weak Hilbert Nullstellensatz asserts that the linear combination polynomials with no common vanishing points f_re1 to f_r and polynomials a_1 to a_r that is equal to 1 is subordinate to the Zariski open cover (something like that, see Wikipedia).

Motivations for having paracompactness and partitions of unity in differentiable manifolds: mainly it is to quickly give easy properties of integrals on differentiable manifolds. Say you have three charts and compute integrals and these have nontrivial intersection, partitions of unity avoid this by a priori having a disjoin union of pieces. It is also used to define the Riemannian metric, or integrals with repsect to volume form et cetera.

Locally finite: each point in the space has a neighbourhood that intersects with only finitely many sets in the collection. This is the key idea that helps in Nagata-Smirnov metrization, as well as the definition of paracompactness which is sufficient for metrization.

Hausdorff space: points x and y in the space can be separated by disjoint neighbourhoods. Easy to relate to regular spaces.

Baire space classification: NOTE there are Baire spaces that are not complete pseudometric spaces or locally compact regular spaces. Therefore, the Baire category theorem does not admit a full characterisation.

Metrizable: topological space homemomorphic to a metric space i.e. there is a metric d from pairs of the space to the half open ray [0, infinity). Examples of non-metrizable spaces include the Zariski topology or spectrum of a ring. Another example is the long line which is locally metrizable but not metrizable.

Uryshon's metrization theorem: second-countable regular spaces are metrisable. Or, a topological space is separable and metrizable if and only if (equivalently) regular, Hausdorff, and second countable. This does not require axiom of choice.

Nagata-Smirnov metrization theorem: topological space is metrisable if and only if it is regular, Hausdorff and has a COUNTABLY LOCALLY FINITE basis. You add some locality to basis for the construction.

Separable: a topological space is separable if it has a countable dense subset. Typical example is countable dense balls of rational radii that cover the real line. Countability is important if you think about Stone duality (countably many experiments can be used to determine a result, corresponding to every limit point being a limit point of some countable subset). Replace balls with neighbourhoods and you have the general topological notion.

Uniqueness on dense subset on whole space: if f and g are CONTINUOUS functions that agree on a dense subset of both X and Y, and X and Y is Hausdorff, then f is equal to g.

Equicontinuous in the sense of norms: continuous everywhere, pick your favourite definition of continuity (preimage of opens is open on operators, epsilon-delta definition, preimage of open neighbourhoods)

Resolvent of a linear operator: set of values k in the complex numbers / field such that T - kI is invertible, T is linear operator, I is identity operator / matrix. Equivalently, this is the set of complex numbers such that (A - e I)^{-1} is bounded and densely defined.

Spectrum of a linear operator: the complement of the field (typically C) from the resolvent. or the set of values k such that T = kI is not invertible. Note: in finite dimensional vector space, this corresponds to the set of eigenvalues for some linear transformation / matrix.

Operator: operators feels like endofunctors. Not very well defined. Typical definition is function from object of some structure to another object of some structure.

Kernel as comparison between isomorphism and homomorphism: isomorphism has trivial kernel, homomorphism may have nontrivial kernel. Use null space analogy again. Homomorphisms can be seen as approximations of the group law, isomorphisms are PERFECT approximations.

Baire category equivalences: see Tao's notes. Relates qualitative theory of continuous linear operators and quantitative theory of estimates. I am surprised this is not phrased in terms of a categorical duality.

Intuition behind uniform boundedness principle: equates qualitative boundedness (convergence) of a family of continuous operators with quantitative bounds.

Uniform boundedness principle: let X be a complete normed space (a Banach space), let Y be a normed vector space, let T_a indexed by a in indexing set A be a family of continuous linear operators T_a from X to Y. The following are equivalent: (1) pointwise boundedness of linear operator i.e. the set of T_a x is bounded (exists positive M such that T_a x in norm Y is less than M times norm of x in norm X); (2) uniform bounded, the operator norms T_a are bounded i.e. infimum of all M such that the norm of T_a x in norm Y is less than M times norm of x in norm X on the whole space of linear operators B(X, Y).

Proof of uniform boundedness principle: uniform boundedness obviously implies pointwise boundedness, assume pointwise boundedness, consider point x, then take countably many sets E_n be the set of points x in X such that norm of T_a y is less than n for all a in the indexing set A. This E_n cover X, using the Baire category theorem, one of this E_n is dense in a ball (I understand this key step). The T_a are continuous, so E_n are closed, so one of the E_n contains a ball. Stuck on this step, you can have the ball centred on the origin. Increase the value of n, E_n dilates, and it contains the open ball B(0,1), but all of the operator norms are bounded by the value of n, so pointwise boundedness implies uniform boundedness.

Failure of uniform boundedness principle (Tao's exercise 4): drop completeness we have the enumeration of the rationals in unit interval f_n(r_N) = n, f_n(x) = 0 if x is not equal to r_n. Each function of f_n is bounded (by n), but has single point of discontinuity. This is pointwise bounded but no subintervals are uniformly bounded since it contains infinitely many rationals. Similar reasons, it is not continuous. For nonlinearity, pick sequence (x_n) = 1/n, get sequence f_n = n, this is unbounded.

Intuition behind the open mapping theorem: equates qualitative solvability of the linear problem Lu = f with quantitative solvability.

Open mapping theorem: let surjective continuous linear map T be from Frechet spaces (weaken to Banach spaces) E to F. Then T is an open mapping, where if open subset U of Frechet space E means T(U) is open in F (open mapping, well defined, this is like opposite of continuous where you have preimages). See also Tao's quantiative version but it is a the following are equivalent untidy spam. I only recommend his notes because they give the philosophy as to why we want these theorems to be true.

Frechet space: locally convex (some people drop locally convex requirement, but I understand why they want this so that norms work nicely) metrisable topological vector space. Defined so that every Cauchy sequence in X converges to a point in X. Banach spaces and Hilbert spaces are Frechet spaces.

Weakened open mapping theorem: linear map f between normed spaces E to F is nearly open if the image is non-meagre in F (continuity is not needed, meagre means countable union whose closure has empty interior). I could not identify the key step but common patterns based ont he proof in Wikipedia is: shrink the open ball to centre at zero, apply axiom of dependent choice to construct f(E) = union f(nU), norms are bounded by radii, linearity and convexity gives subsets (-1)U.

Metamathematics of open mapping theorem: justifies approximations for solving linear equations Lu = f for datum f in Y and unknown u in X, looks like linear PDE. f is in some dense class of nice functions find some norm ||u||_X <= C||f||_y for some constant C.

Bijection and invertibility equivalence in the open mapping theorem: let T be a continuous linear operator from X to Y, X and Y are Banach spaces, the following are equivalent: (1) T is bijective; (2) T is bijective and T^{-1}: Y -> X is a continuous (hence bounded) linear transformation.

Bounded inverse theorem: continuous bijective linear operator between Frechet spaces has continuous inverse. Corollary of the open mapping theorem. Also, for this example, then bounded inverse theorem means bijection is enough if you have the linearity and Frechet spaces.

Closed graph theorem: let T be a continuous linear operator from X to Y, X and Y are Banach spaces, the following are equivalent: (1) T is continuous, (2) T is closed, (3) there exists a topology F on Y, weaker than the norm topology (containing fewer opens) but still Hausdorff. Proofs: 1 implies 3 picking F as norm topology, 3 implies 2, convergence in norm gives convergence in weak topology. Hausdorff topological spaces have unique limit, 2 implies 1 is KEY STEP using the open mapping theorem, T closed, consider graph which is set of (x, Tx) for x in X is a closed linear subspace of the Banach space X * Y, this is a Banach space (see lemma elsewhere here). On the other hand, projection map back to X is clearly a continuous linear bijection, BY corollary of open mapping theorem, inverse is continuous linear bijective, so T is continuous i.e. 2 implies 1.

Closed graph theorem quantitative (Tao's approach): X and Y are Banach spaces, some inclusion Y into Z into Hausdorff topological vector space. Let T: X -> Z be a continuous linear operator / transformation (need not be bijective), the following are equivalent: (1, qualitative regularity) for x in X, Tx is in Y; (2, quantitative regularity) x in X, Tx is in Y, and |Tx|_Y <= C|x|_X, for some C > 0 is independent of x; (3, quantitative regularity on a dense subclass) x in dense subset of X, Tx is in Y, and |Tx|_Y <= C|x|_X. Proof: 2 implies 3 or 1. 3 implies 2, by using the fact that limits in Hausdorff space is unique; 1 implies the 2. or 3. use closed graph theorem to reduce it to a map from X to Y, this map is continuous (this step that Tao gave is not very clear.)

Intuition behind the closed graph theorem: equates qualitative regularity of weakly continuous operator T with quantitative regularity.

Basis of topological space: every open is union of set in basis sets. Like basis of vector space. You know when vector spaces use orthonormal basis and arrows, now replace those stupid arrows with balls and just glue glue glue them together.

Unique subbasis: related to countable intersections of opens as unions.

Bernstein polynomials: looks like Binomial series: start with 1 = (x + (1-x))^k = sum (n! / (n - k)! k!) x^k (1 - x)^{n - k} from k = 0 to k = n. Now have some f(k/n) factor in each term.

Compact linear operator: linear operator T from X to Y is compact if for any bounded sequence (x_n) in X then the sequence of (Tx_n) in Y has a convergent subsequence OR T is compact if TB_x is precompact (bounded and equicontinuous) subset of Y OR completion of TB_x is a compact subset of Y.

Precompact: equivalent to Cauchy subsequence. This relates to its completion, a precompact space is a space whose completion is compact.

Comparison of precompactness to compactness: precompact is every Cauchy subsequence converges versus every Cauchy sequence converges.

Cauchy sequence: all but finite (note, finite is stronger than countable) number of elements of the sequence are less than than any stipulated positive distance from EACH OTHER. Not sufficient for each term to be arbitrary close to PRECEDING TERM. Must be each other. Cauchy sequence in complete metric space, convergence only depends on the terms of the sequence and not just the limit values, so algorithms produce a Cauchy sequence to fit some logical sequence.

Baire space: topological space whose conclusion satisfies to Baire category theorem. This is also the topological space where intersections of countable family of dense open subspaces (endowed with topology) is also dense. This is the space with countable union of closed sets with empty interior also has an empty interior. Trick  example: algebraic varieties with the Zariski topology are Baire spaces, but are not metrisable.

Closed subspaces of Baire spaces need not be Baire. Example: product of rationals {0} is closed in open upper half plane with rationals on X axis is a Baire space but this is not a Baire space.

Complement properties for Baire space definition: a set is open (closed under arbitrary unions and finite intersections) so its complement is closed. A set is comeagre, its complement is meagre or of first category (a set is a countable union of set whose closure has an empty interior). A set is dense, its complement has empty interior. A set has a dense interior, its complement is nowhere dense. A set if Baire (unrelated to Baire sigma algebra) or ALMOST open if it differes from an open set by a meager set. 

Analogy between complete nonempty mertic spaces and measure space of positive measure: helps to related, meager or first category is like zero measure / null, second category is like positive measure, residual or co-meager is like full measure or co-null, Baire is like measurable. NOTE: these differ in practice, see Tao's blog article for this.

Banach-Mazur game: topological game, infinite positional game of perfect information related to Baire spaces.

Hilbert-Schmidt operator: orthonormal basis {e_j} from j = 1 to j = infinity of a Hilbert space is such that the norm square of T which is the sum of norms of the linear maps from the orthonormal basis elements squared is bounded i.e. sum from j = 1 to j = infinity of norm(Te_j)^2 is less than infinity. This is well defined since this is independent of the orthonormal basis we pick.

Every Hilbert space has a orthonormal basis: proof apply Zorn's lemma (warning: there is no need to use Zorn's for finite dimensional vector space), collection of orthonormal sets ordered by inclusion has a maximal element, so it is a basis (otherwise, you can extend the Hilbert space with the extra element, so the non-maximal element is not an orthonormal set) 

Separable equivalent to countable orthonormal basis for Hilbert spaces: take countable dense set, apply Gram-Schmidt, so this set admits a Schauder basis, therefore equivalent to countable orthonormal basis. The equivalence of separable to countable orthonormal basis is equivalent to the definition of a Schauder basis.

Unitary maps: invertible linear maps U from H_1 to H_2, for H_1 and H_2 Hilbert spaces preserving inner products i.e. <Ux, Uy>_2 = <x, y>_1. This is an isometry if you pick y = x. Converse, isometry and SURJECTIVE required, otherwise you do not have a well defined Uy in norm of H_2.

Continuous function: Equivalently: (1) preimage of opens in codomain is open for all opens in domain; (2) lim_n f(x_n) = f(lim_n x_n) for all convergent sequence in the domain of f; (3) epsilon-delta; (4) continuous at a point x if preimage of any neighbourhood of f(x) is a neighbourhood of x.

Convolution (group, measure theory perspective): suppose we have two finite complex Radon measure on an LCA group G, it is the unique, bilinear, weak-* continuous extension of the group product to M(G) which is the space of measures, and G is naturally identified with point measures. Restrict to L1(G), gets convolution formula.

Convolution (probabilist): the probability density function associated with the sum of two independent ABSOLUTELY continuous random variables
https://mathoverflow.net/questions/5892/what-is-convolution-intuitively

Equivalence relation: binary operation that is reflexive, symmetric and transitive; Equivalently: there exists a function f such that R(a, b) if f(a) = f(b).

Function: triple (A, B) such that R is a subset of the product of A and B. Or Timothy Gowers prefer not to say what it is at all, and just say f is a function form A to B, x is an element of A, f(x) is an element of B.

G-torsor: a set X with an action of G (group homomorphism from G to X), multiply any element of g with element x in X such that identty and associativity holds for action 1x = x and (g1g2)x = g1(g2 x), a group action is a torsor there exist a UNIQUE group element such that gx1 = x2 for any x1 and x2 in X, such that (x2 / x1) x1 = x2.

Smooth structure: manifold that is an equivalence class of an atlas, use some locally ringed space formalism to define this.

Group action: homomorphism from G to the group of permutations on X

Dates as Z-torsors: subtract two dates gives integer number of days, so dates are elements of a Z-torsor, you cannot add dates, integers is Z.

Indefinite integrals as R-torsor: when you integrate f you get a set of functions whose derivative is f. This is a R-torsor, with + C

Energies are R-torsor: potential energy is with respect to a base point, so you need an R-torsor.

Affine plane as torsor: you forget the origin, so the plane becomes torsor. Affine space is a vector space forgetting an origin. A torsor is like group forgetting the identity. To turn the G-torsor into a group G, pick an element to be an identity.

Normal subgroups: subgroup invariant under conjugation of any group element i.e. gng^{-1} is in N. Equivalently, (1) image of conjugation is subset/equal to N; (2) left cosets and right cosets are equal; (3) N is A (not the) union of conjugacy classes of G; (4) there is some group homomorphism whose kernel (null space if you use representation theory) is N; (5) for all n in N and g in G the commutator n^{-1} g^{-1} n g is in subgroup N. Special linear group is a normal subgroup of the general linear group, since it is the kernel of the determinant map as group homomorphism.

Center of group: set of elements that commute with all elements of the group.

Hamiltonian group: non-abelian group but every subgroup is normal.

Classification of integers: primes, prime powers, or composites (products of prime powers). This is useful for me to show Z/mZ is integral domain equivalently m is prime, and Z/mZ field equivalently if m is prime.

Matrix rings: set by two by two matrices also form a matrix ring, example we have injective ring homomorphism from x + yi to [x y ; -y x]. Can show that this is a ring explicitly, for additive it is piecewise addition, use the fact that base is commutative ring, then product is explictly computed to have the same structure as [x y; -y x]. Noncommutative, because matrix product is anticommutative.

AB in matrix ring = I, means BA = I: proof, dumbest proof ever [a b; c d], compare components of matrix with 1, you get a^2 + b^2c^2 + d^2 = 2, and ring is commutative, so it must be the other case as well and the entries obtained is the same. Similarly, ab + bd = ac + dc = 0.

Matrix ring is not integral domain: pick [1 0; 0 0] and [0 0 ; 1 0], so not integral domain.

Injective morphism: kernel is zero, f(x) = f(y) implies x = y, converse of well definedness of function.
 
Gaussian integers: ring of integers adjoined with the root of -1. Compare this to Euclid's formula of Pythagorean triples and can be used to generate them.

Forgetful functor of unital commutative rings from Z: there is a unique group homomorphism from Z to ring R.

Sylow's theorem: important partial converse to Lagrange's theorem, G be finite group. Let p be prime, and p^n divides the cardinality of G for some power n >= 1, G has a subgroup of order p^n. Used to prove fundamental theorem of algebra using galois theory?

Lagrange's theorem: consider G FINITE group, cardinality of G = cardinality of H * number of distinct cosets in H. Proof is based on left cosets of finite groups form equivalence classes. Coset distinction since left cosets form equivalence classes. Consider group G as disjoint union of left cosets of H, apply forgetful functor so cardinality of G is cardinality of H * number of distinct cosets. Lagrange's theorem falls out from left cosets as equivalence classes. 

Index of a subgroup: the following are equivalent: (1) number of left distinct cosets of H; (2) A be abelian subgroup of G with order a, G has order g, each irreducible representation have of G has degree <= g/a, g/a is index of subgroup A in G.

Left cosets of finite groups form equivalence classes: same proof, disjoint and we are done, otherwise we can find g1 h1 = g2 h2, then consider g2 h2 h1^{-1} h is in left coset g2 H. This gives equivalence classes of left cosets.

Left coset of a subgroup H of G attached with element g: this is the group formed by multiplying every other element of H with the element g using the group law of G.

Group homomorphism: homomorphism that gives p(a * b) = p(a) + p(b) where * is a group law and + is another group law. Typical example is the logarithm, which takes from product group on reals to addition group on reals.

Symmetric group: group with permutations as the composition law. Important since this is related to the Cayley's theorem and it is one of the first example of the Yoneda's lemma in action.

Dihedral group: group of all permutations of the n-gon. 

Quaternion group: eight element group of signed 1, i, j, k, with a bunch of formulas where i^2 = j^2 = k^2 = ijk = -1.

Cyclic group: there is an element i.e. that generates the entire group i.e. g^{n}, n integer gives all elements in the group.

Primary cyclic group: there is an prime p i.e. that generates the entire group i.e. g^{p}, n integer gives all elements in the group. 

Order of element of a group: integer n where number of products give g^n = e, where e is the identity, and g is the group element.

Partial order: binary relation if it is reflexive, antisymmetric, and transitive.

Principle of inclusion and exclusion: cardinality of union on sets on A and B is equal to cardinality of A + cardinality of B - cardinality of A intersect B, proof is easiest considering the forgetful functor (cardinality) on the category of finite sets.

Binomial theorem: (x + y) raised to the power m is a series of with binomial coefficient m! / (m - k!) k! multiplied by x^k and y^{m - k}. For the binomial distribution, pick x = p, and y = 1 - p. This is useful in deriving the characteristic function of the binomial distribution since this is an integral of a damping exponential or a Fourier transform.

Binomial coefficient is 1 mod p at k = 0, k = p, 0 otherwise: proof, p choose 0 and p choose p is 1 by calculation. The rest are divisible by p.

Fermat's little theorem: this is the statement that a^p = a mod p, or a^{p - 1} = 1 mod p. Proof: I like this binomial coefficient proof I saw in Silverman using induction on a. Verify for a = 0, a = 1, now assume it is true for a, verify true for (a + 1)^p. Do binomial expansion, this will give series (p choose [p - k]) a^k, which is a^p + 1 (from p choose p = 1), which then reduces to a + 1 from the induction hypothesis. Second statement, just divide both sides by a. 

Unique factorisation up to order and units: all integers more than or equal to two can be factored uniquely up to order and units into a product of primes.

Integers modulo prime p: equivalence classes forming p distinct equivalence classes for primes. NOTE: this is actually a set of sets. 

Integers: group completion of the naturals.

Mathematical induction: verify base case is true, let n >= some integer, then assume P_1 all the way to P_n is true (important, not necessarily P_n), then show P_{n+1} is true.

Construction of equivalence classes theorem INTO partitions: statement that if sets have equivalence relations on it, then (1) they are either equal or disjoint union, these are what we call partitions of a set where every element is included in exactly one subset; (2) there is a functor from disjoint union of equivalence classes to cardinality of equivalence classes. Proof: if disjoint union, we are done, otherwise assuming union, reflexivity, symmetry and transitivity necessitates that mutual inclusion of the two sets. The set of equivalence classes is a partition.

Kolmogorov consistency theorem: you want a unique measure P on outcome space Omega and and sigma algebra Sigma such that under natural projection pi(omega) = list of coordinates vectors (x_1, x_2, ... x_n) the induced measure P pi_n^{-1} = P_n on R^n. Wikipedia says that it means you can construct a probability space if you fulfil conditions that permutations of distinct times (careful NOT measurable sets i.e. random variables are exchangeable) still give consistent product of measurable sets i.e. order in which the t_i appear does not change the distribution, only the way I write down and future events can be input as R^{n} in the probability measure and these two conditions (which define a stochastic process) are necessary and sufficient.

Consistent family of finite dimensional distributions: the natural projection from R^{n + 1} -> R^{n} losing one degree of freedom, the probability measure P^{n+1} projects to P^{n}.
 
Moment generating function: integral of x^k on the distribution, or the expected value of X^k for k-th moment. Stone-Weierstrass theorem suggests that polynomials from the linear combinations of all the moments of a distribution can approximate any continuous function (some sort of completeness or separability condition on vector spaces), this can be done to recover the probability distribution from the moments, however this is not easy according to Varadhan. See also cumulants.

Moments do not determine distribution in general:  example it is the problem of trying to recover the function from all the derivatives at t = 0 aka the Maclaurin series. Varadhan constructs an explict counterexample on page 23 which I do not understand why this fails.

Characteristic function of binomial distribution: recall that the characteristic function is the expectation of exp(itx). Consider sum from 1 to N of (n!/(n-k)! k!) p^k (1 - p)^(N - k) * exp(itk) for discrete sum. Now fold it into: (n!/(n-k)! k!) (1 - p)^(N - k) * [exp(it) * p]^k and then you will get  ([1 - p] + p exp(it))^N as a decomposition of the binomial sum.

Characteristic function of degenerate distribution with probability 1 at point a: this is just exp(i a t). See exercise 2.1 in Varadhan.

Subspace: subset of the vector space that itself is a vector space of the field. Proper if not equal to the full vector space. A subspace S is said to span vector space V if span S = V.

Sum of two subspaces: S_1 + S_2 can be expressed as the span of the union of S_1 and S_2. If the subspaces are disjoint, this is defined as direct sum.

Hermitian matrix: matrix that is equal to their conjugate transpose. A Hermitian matrix or a symmetric matrix to a real number sort of like how unitary or orthogonal matrix is like a number on a unit circle. Hermitian matrices are nice because there is a spectral decomposition of A = sum of e_i P_i, where e_i is the eigenvalue, and P_i is the projection onto the eigenspace for e_i. Majorization is an important part of studying hermitian matrices.

Orthogonal matrix: product of matrix and matrix transpose is the identity matrix.

Essentially Hermitian: exp(i theta) A is Hermitian.

Toeplitz decomposition to symmetric and skew symmetric: matrices can be decomposed uniquely to the sum of a symmetric matrix S(A) and a skew-symmetric matrix C(A). S(A) = (A + A^T)/2, C(A) = (A - A^T)/2. This is studied in representation theory. Similarly for Hermitian and Skew-Hermitian that is given this canonical name.

Isotropic vectors: x^T x = 0 example [1 i]^T is a nonzero isotropic vector in C^2. There are no nonzero isotropic vectors in the reals.

Skew-Hermitian: matrix equal to the negative of its conjugate transpose.

Cyclic permutation: permutation matrix that forms a cyclic subgroup i.e. action of P^{n - 1} is idempotent or P^{n} gives identity matrix.

Tests for positive definiteness of matrices: each are necessary sufficient, x^T A x > 0 for all nonzero real vectors x, all eigenvalues are positive, all upper left submatrices A_k have positive determinant, all pivots without row exchanges (i.e. like eigenvalues) are positive.

Rayleigh's quotient: minimisation problem equivalent to solving (A - e I)x = 0, so we have minimise R(x) = x^T A / x^T x. 

Preconditioner in numerical analysis: we have Ax_1 = b, so S is the preconditioner with many choices to classify the iterative method solver, S being diagonal part of A gives the Jacobi method, S being the triangular part of A give the Gauss-Seidel method, S being combination of triangular part and diagonal part gives successive over-relaxation.

Circulant matrix: all rows are make of the same element, each row is rotated one element to the right in the relative to the preceding row.

Orthogonal vectors in linear algebra: x^T y = 0

Differentiation in linear algebra: it is a linear operation, null space is one dimensional space of constants where Ax = 0 i.e. nullity is 1, column space is n-dimensional space P_{n-1}.

Integration in linear algebra: there is no null space except for zero vector, integration does not produce all polynomials in P_{n + 1}.

Incidence matrices: every entry is 1, -1 or 0. This is meant to represent a graph.

Matrix: m rows, n columns. Representation of a linear transformation, so stuff like domain, range / row space of matrix and (right) null space of a matrix are valid notions. Domain is always a vector space or subspace, than the range or row space is set of y such that y = Ax, null space is the set of x such that Ax = 0.

Square matrix: m rows, n columns, m = n.

Submatrix: some rectangular array lying in the entries of the matrix to be formed as am matrix.

Linearly dependent: valid for only a finite list of vectors if there exists scalars in scalar field such that the sum of a_i v_i = 0. Or nontrivial linear combination gives zero vector. This happens when one vector is a linear combination of the others (hint: you can consider inverse). Two vectors are linear dependent is logically equivalent to saying one vector is a scalar multiple of another. For infinitely many vectors, you simply need some sub-list of vectors to be linearly dependent.

Incidence matrices in the fundamental subspaces: null space is dimension 1, column space gives r = n - 1, any n - 1 columns are independent or give sufficient information on the matrix and all vectors in the column space have y^T b = 0, or all potential differences add to zero around all loops, row space is r = n - 1 and every vector in the row space add to zero this is the current laws, independent rows from spanning trees, left null space is dimension m - r or m - n + 1, contained by the current loops. This gives Euler's formula from the four fundamental spaces.

Euler characteristic for connected graphs using linear algebra and incidence matrices: V - E + F for loops = 1, we have (n) - (m) + (m - n + 1) = 1.

Incidence matrix, Kirchhoff laws: A^T is the right matrix for the current law, left null space gives Kirchhoff current law, right null space gives Kirchhoff voltage law. A^T y = f.

Trees in linear algebra: graph with no loops.

Row rank = column rank: not obvious, it also implies if the rows of square matrix and linearly independent, columns are also linearly independent. 

Rank of a matrix: elimination gives r pivot variables and n - r free variables, r is the rank of the matrix. It counts the number of pivot rows in the row space and pivot columns in the column solutions.

Column space (image): column space contains all linear combinations of the columns of A. It can be thought of as the space that is spanned by its columns. It is a subspace of R^n. Its dimension is the rank of the matrix. This is called the range, since it is all the possible vectors f(x) = Ax, that is why it is given the name for some hypothetical function.

Null space (kernel in linear algebra): consist of all vector x such that Ax = 0. It is a subspace of R^n. Column of A are independent when null space is the zero vector. The reasoning is as follows: pick columns of triangular matrix with no zeroes on the diagonal. Solve Ac = 0, forced to pick entries of c to be zero, therefore, the only combination to produce the zero vector is the trivial combination. The dimension is dimension of the space - rank of matrix or n - r. This dimension is also called the nullity.

Eigenvalues and null space: Ax = ex, e is eigenvalue, special case of eigenvalue equals zero gives nullspace.

Difference between null space and kernel: kernel is basis free, only once you choose a basis you can define the null space.

Cokernel equivalent definitions in linear algebra (not true over general fields): the following are equivalent: cokernel of matrix A, orthogonal complement of the image of A, equivalence classes of every vector of image of A. Proof is finding isomorphisms but requires x^T A^T Ax = 0.

Row space (coimage): column space of the transpose of A.

Left null space (cokernel in linear algebra): null space of the transpose of A. It is the number of columns = m, so it is m - r, where r is the rank of the matrix.

Echelon form, U: it is a staircase pattern, upper triangular, zeroes below the pivots.

Reduced row echelon form, R: Make all the pivots 1, use the pivot row to produce zero above the pivot, apply this to an echelon matrix, so this is the reduced row echelon form. 

Gaussian elimination: PA = LU, you permute the matrix A, then decompose them into LU.

Inverse matrix: matrix such that A * A^(-1) gives the identity matrix. NOTE, not all matrices are invertible. If Ax = 0, and x is nonzero, then an inverse is zero. No matrix can multiply the zero vector and get back a nonzero vector. The rank is s large as possible so that the inverse exists.

Symmetric matrix: matrix that is equal to its own transpose. See Hermitian matrices.

Sparse matrix intuition: sparse matrices tend to have far fewer than n^2 pieces of information, so there should be ways to speed up matrix multiplication.

Band matrix: a_{ij} = 0, except in the band |i - j| < w, interesting that a norm is used to define this band matrix.

Positive definite matrices: pivots are positive. 

Frobenius matrix: represent Gaussian transformation for Gaussian elimination, all entries on main diagonal are ones, entries below main diagonal of at most one column.

Orthogonality of fundamental subspace: row space is orthogonal to (right) null space, column space is orthogonal to left null space.

Rank nullity theorem: dim(row space, image) + dim(right null space, kernel) = number of columns, n. We have dim(column space, image) + dim(left null space, cokernel) = number of rows, m. Dim of row space is designated as a rank of the matrix, the dim of the right null space is designated as the nullity of a matrix. dim(row space of A, image) = dim(column space of A, coimage) since there is a bijection from the image and coimage of A.

Orthogonal complement: subspace V, then it is the space of all vectors orthogonal to V.

Fundamental spaces orthogonal complement: right null space is orthogonal complement to row space, left null space is orthogonal complement to column space.

Pseudoinverse: A^+ Ax = x, for x in the row space. Pseudo-inverse requires singular value decomposition, motivates eigenvalues.

Projection matrix: A(A^T A)^{-1} A^T, seems like some crazy formula, because I am stupid. It is symmetric P^T = P, and it is idempotent P^2 = P. These two properties feel like the identity matrix.

Inner product in matrices: row vector * column vector. NOTE: non-commutative. Notation is x^T y, or transpose x from row vector to column vector. Useful: if nonzero vectors are mutually orthogonal, than those vectors are linearly independent: suppose linear combination of those vectors are zero. Take inner product of both sides with v_1, so it is multiply by v_1^T. Get v_1^T (sum of c_1 v_1 to c_k v_k) = c_1 v_1^T v_1 = 0 using mutual orthogonality. But v_1^T v_1 is nonzero (basis vector), so c_1 must be zero, so independent. 

Elementary matrix, square matrix obtained by doing elementary row and column operation. These are row switching, row multiplication and row addition. These generate the general linear group GL_n(F), F is field.

Identity matrix: 1s on the diagonal, 0s everywhere else. It can be thought as the matrix that gives an idempotent action (matrix multiplication) on every other matrix. It is the multiplicative identity of the matrices as the group of linear transformations.

Upper triangular: all entries below diagonal is zero.

Row picture: intersection of planes. Example, three planes are identical. 

Column picture: combination of columns. 

LU factorisation: factorising a matrix to a left bottom triangular matrix and a right upper triangular matrix. I like the word factorisation instead of decomposition.

Basis of vector space: linearly independent vectors that span the space. Maximal independent set, minimal spanning set. Each element of a vector space can be represented as a linear combination of basis vectors in uniquely. No list (still within vector space V) containing the basis is linear independent. Any linearly independent list of vectors may be extended non-uniquely to a basis. A basis need not be finite: examples infinite list of monomials, 1, t, t^2, ...

Standard basis: consider matrix, each element has 1 in its i-th entry.

Subspace intersection theorem: dim(S_1 intersect S_2) + dim(S_1 + S_2) = dim S_1 + dim S_2.

Zero matrix: matrix with all zeroes, it is the additive identity.

Dimension of vector space: positive integer n such that the basis of vector space contains exactly n vectors. If this exists, V is finite dimensional vector space, otherwise it is infinitely dimensional. In infinite dimensional vector space, we have a one-to-one correspondence between elements of any two basis (bijection in the style of Cantor).

Maschke's theorem in representation theory: generalisation of the theorem that vector spaces are classified by dimension. Corollary to this result, if V is a representation of a finite group G over a field F with characteristic not dividing the order of G and V has a subrepresentation W, then it has another subrepresentation U such that V = W ++ U, ++ is direct sum. Corollary is: every representation of a finite group G over a field F with characteristic not dividing the order of G is a direct sum of irreducible representations. So this helps classify represenation of finite groups to be determined up to isomorphism by its character.
Fails at G infinite, or K has characteristic dividing G.

Maschke's theorem in category theory: if G is a group, F is field with characteristic not dividing over G, then the category of representations of G over F is semi-simple.

Semi-simple: can be decomposed into simple obeject, and simple object to not contain nontrivial subobjects.

All finite dimensional vector spaces are semisimple: proof comes from the fact that all vector spaces are classified up to dimension, problem is essentially homemorphic to taking direct sums of copies of R to form your vector space.

Vectors are classified up to its dimension: suppose these are the row vectors of the basis W is not equal in number to row vectors form a basis V (dimensions are different) where W is a n by 1 matrix, then V is a m by 1 matrix where n is more than m, take linear combinations of w with v vectors. you get W = VA, but A must be size m by n which is not square. There is a nonzero matrix Ax = 0, VAx = 0, so Wx = 0, therefore W is not a basis, contradiction. So n and m must be equal.

Finite dimensional normed vector space is complete: isometrically isomorphic to K^n with l^2 norm, so it must be complete.

Compactness of subsets of finite dimensional normed vector space is equivalent to closed and boundedness: forward: closure and boundedness is preserved under equivalent norms, identity map on equivalent norms is continuous, so it is really just a statement on how closure and boundedness is equivalent to compactness in topology.

All norms are equivalent on finite dimensional vector space: harder than K^n since you need to construct a norm on V. First construct Euclidean norm on components of the basis of V, then apply that K^n with l^2 norm is isometrically isomorphic to this norm. So it is sufficient to prove norms being equivalent on K^n since equivalence of norms is equivalence relation. Now use the triangle inequality and the Cauchy-Schwarz inequality (see Robinson) to show norm(x) <= C norm_E(x) and some details attaining lower bound, considering unit spherical shell in K^n as closed and bounded subset of K^n and is compact to show norm(x) >= alpha norm_E(x). It just seems like there are a lot of details for this proof, hard to keep it in your head.

Cauchy-Schwarz generalised: this just states that the L1 norm is less than the L2 norm i.e. |f(x + y)|^2 <=  |f(x) + f(y)|^2, f in this case can be a norm, visualisations, diamond for L1 norm, circle for L2 norm, big square or maximal square for L infinity norm. This is so useful since every inner product gives rise to an Euclidean l2 norm, called the canonical or induced norm. Take square root on both sides give triangle inequality.

Contraction mapping theorem (Banach fixed point theorem): suppose non-empty CLOSED subset K of a completed normed space X with norm norm(x), let f: K -> K be a contraction a endomorphism which norm(f(x) - f(y)) <= k norm((x - y)), for k < 1, then f has a fixed point in the subset k, there exist a unique point where f(x) = x. NOTE: for k <= 1, you need compactness of K. Proof involves constructing a Cauchy sequence bounded by repeatedly using this inequality on terms of the convergent subsequence, then use X being Banach space, K closed, so this limit must be in this set K. Note that such a contraction is CONTINOUS by definition (preimage of opens is in K), we have that function of convergent f(x_n) -> f(x) this is nice since function is continuous, you have the limit of this subsequence x to be equal to f(x) of the contraction, so this is a fixed point. Uniqueness follows by considering norms norm(x - y) = norm(f(x) - f(y)) <= (k) norm(x - y). So we have (1 - k) norm(x - y) = 0 using the fact that k is less than 1, and norm(x - y) is nonnegative. Therefore, x = y.

Fixed point under function: x = f(x) after action of the function.

Contraction mapping: endomorphism on non-empty closed subset K such that distance between f(x) and f(y) in this set K is bounded by a scalar multiple k * distance between x and y, where k is in closed unit interval from 0 to 1 in reals. Note, this works since when define norms it is output on the half open positive ray [0, infinity).

Convergent series of norms of Banach spaces implies sequence converges in the Banach space: let X be such that Banach space, key step is to show that partial sums form a Cauchy sequence using the triangle inequality repeatedly, since the Banach space is complete. Sequence convergent.

Space is normed space where series of norms if finite AND the sum of components converges in the space so the space must be Banach space: two key steps, equivalently show some subsequence converges to y (this needs to be shown separately), next key step is to think that each term is bounded by 2^(-k) carefully using (y_i) is Cauchy so that the full norm is bounded by 1, then replace this with x_j which is some difference, this shows that series of norms is finite, so series of x_j converges to some y in X, then define y_1 + series of differences equal to y_n_j to show this converges to y, so X is complete and y_k converges to y.

Product of Banach spaces is Banach space for Manhattan form and Euclidean norm: proof: step 1 Cauchy sequence, show that p-norms are bounded by epsilon gap using Cauchy sequences in X and Y. Then take difference between norm of convergence of sequences with their converged limit in each component versus that of the pair. Therefore product of components converge to their pair of points, so the product space is also complete.

Cauchy sequence: sequence that converges in metric space i.le. for every nonzero gap epsilon, there exists an integer lower bound N such that d(x_n, x_m) is bounded by (less than) the gap epsilon for all _n and _m more than this lower bound N. Apply triangle inequality, so this definition makes sense when we are careful to use half of the nonzero gap epsilon, which is epsilon/2.

Complete metric space: a space where every Cauchy sequence converges.

Complete uniform space: a space where every Cauchy filter converges.

Banach space: normed complete metric spaces. The reals and the complexes are complete spaces. This carries over to powers of reals and complexes with standard norms. Examples: space of l^p sequences l^p(K), c0(K), l^\infty(K), space C^1([a,b]) is complete on closed intervals.

Linear closed subspaces of Banach spaces are Banach spaces: proof key step, forward just apply the fact that it is Cauchy in Y and then it is Cauchy in X, the limit must be in Y since Y is closed. For reverse, if Y is complete then a must be in X, and Cauchy sequences converge in Y, so Y must be closed.

Banach spaces with equivalent norms must be equivalent under completeness: first spell out definition of equivalent norms, key step is to use left haft and right half of equivalence inequality properly, right half implies that Cauchy sequence (x_n) in X must be Cauchy sequence (Tx_n) in Y. Use the fact that Y is a Banach space (complete), then you can use left half to show that X is Banach space by taking preimages of the sequences and using the left half tending to zero when Y is complete. Lemma 4.5 in Robinson, just use endomorphism of maps with different norms.

Completeness arguments prototype: step 1, define what it means for sequence to be Cauchy, step 2: use this definition to identify a limit, step 3, show it convergences to this limit with the appropriate norm, step 4, show this limit lies in the correct space.

K^d complete with standard norm: step 1, pick l2 norm to be complete, then consider arbitrary powers of n and m where |x_i^n 0 x_i^m| less than equal to bounded gap epsilon. Show that candidate l^2 norm is bounded so limit of this gap in the arbitrary case converges to zero., and this limit lies as an element of K^n.

Linear subspaces of normed spaces need not be closed: this is easy, take unit ball, consider the sum of two identical unit vectors in the ball, it will escape.

Equivalent norms preserve convergence and continuity: for convergence consider c1 norm1(x_n - x) <= norm2(x_n -x) <= c2 norm1(x_n - x). Convergence to zero for norm 1 is equivalent to convergence to zero for norm 2. Compactness is defined by open covers, so equivalence under scalar multiplication means that equivalence of norms preserve compactness.

Isomorphism of normed spaces: if we have a map from normed space X to normed space Y that is a bijection under sets, linear preserving vector space (so this is a matrix) and makes it such that c1 normX(x) <= normY(Tx) <= c2 normX(x) i.e. the map Tx makes norms X and norm Y equivalent, then this is an isomorphism of normed spaces. Linear maps that are bijections are requirement for isomorphism of vector spaces, so this third property gives it an equivalence of norms. Normed spaces are isomorphic if we have this isomorphism. Intuitively, it is an isomorphism of vector spaces + equivalence of norms.

Isomorphism of vector space: invertible function f from vector space U to vector space V such that f(ax + by) = a f(x) + b f(y) for all x and y in U and a, and b in field F.

C^n is isometrically isomorphic to R^2n: use map (x1, y1, x2, y2, ... xn, yn), z_i = x_i + y_i as the isometric isomorphism.

Closed linear span: set of all elements that can be approximated arbitrarily closely by finite linear combinations of E, this feels like separability. We call this the clin(E), which is the closure of the span of E.

Equivalence of separable, separability of unit sphere, linear space is dense: separable spaces containing countable dense subset, scale by scalar using the fact that this is a normed space.

l^infty(K) is not separable: prove using Cantor's diagonal argument using the trivial norm ||x-y|| = 1 if they differ. So any dense set A must contain uncountable number of elements.

l^p(K) is separable: proof key step is to consider the difference between x and linear combination of unit vectors in e^j, then also sum of components powers by p is bounded by some epsilon^p, we used the fact that l^p is a norm here. Therefore the gap between x and linear combination of unit vectors in e^j is the lp norm of components is bounded by another epsilon. See Robinson for a more explainable proof.

Linear span of subset of normed space: set of all finite linear combinations of elements of the subset of normed space X. Spanning just means combinations produce teh whole space.

Isometry: instead of enforcing equivalence of norms X and Y, we say these are equal i.e. norm_X(x) = norm_Y(Tx). Ito isometry is an example, where norms on Wiener process and on time itself are isometric in power 2. Isometry is used in defining unitary maps or unitary matrices. The following are equivalent: isometry and surjectivity, and unitary maps (without surjectivity, the other element may not exist in the range of the Hilbert space)

Isometrically isomorphic, replace equivalence of norms with isometry as a condition. Still must be a isomorphism of vector space.

Lp norm is norm proof: nonnegativity show by contradiction: need to show converse, norm is 0 means it must be 0 function. Suppose you do have a nonzero function that gives norm zero, take some integral from 0 to 1 of the norm of the function, it is more than zero somehow (see Robinson for proof). Next step is simply to apply triangle inequality internally within on the convex combinations of the norm and show that it is less than or equal to 1 by careful integration.

Map from x to norm of x is always continuous: proof is by considering triangle inequality.

Equivalent norms: norms that are equivalent (reflexive, symmetric, transitive) up to constant scalar multiples i.e. c_1 norm(x1) <= norm(x2) <= c_2 norm(x1)

Sequence space: all real valued sequence such that the Lp norm is finite. At infinity, it is the space of bounded sequences equipped with the supremum norm of components.

c0(K) subspaces of null sequences: consists of sequences that have all zeroes as the number of components tends towards infinity:

Norms on a vector space: map from vector space X to positive half open ray [0, infinity), that is zero at zero (note: nonnegative implicit in valid range, Horn and Johnson calls it positivity), has scalar multiplication / homogenity in Horn and Johnson, and obeys the triangle inequality. This feels very similar to random variables actually, maps from outcome space to closed interval. Need this to define open and closed balls.

Norm on a FIELD: map from field F to real numbers, nonnegative and zero at zero, mapping is homomorphism under group product, mapping is weaker than homomorphism obey triangle inequality under group addition i.e. f(x + y) <= f(x) + f(y). Lastly, group identity makes sense f(1) = f(-1) = 1, and norm preserves group inverses i.e. f(x^-1) = x. Examples: if field is reals, the norm defined is the max norm. If the field is the complex number, the norm is the absolute modulus of product of complex numbers, or the geometric mean of a complex number and its complex conjugate. Any field has trivial norm, norm 1 if nonzero, norm zero if x is zero, and finite fields and finite field extensions only have this trivial norm (I want proof for this).

Valuation as logarithmic norm on fields: logarithmic norm on fields, generalises norm to linearly ordered ring (need linear order like in half open positive ray in reals). It is a mapping from field K into a totally ordered linear group adjoined by infinity (similar to half open positive ray.) Infinity is absorbing element, any element added to infinity gives infinity. Properties: the valuation at zero must be infinity, any valuation of an element is less than infinity, the valuation is a group homomorphism converting products f(xy) in fields to group addition in this totally ordered group f(x) + f(y) and lastly, the valuation of a difference f(x - y) is more than or equal to the minima of the valuation in this group i.e. f(x - y) >= min(f(x), f(y)).

Example of valuation as p-adic: suppose v is valuation in field K to linearly ordered group of reals R, if a is real number in open unit interval i.e. 0 < a < 1, then phi(x) = a^(v(x)) is a norm. Now pick field K to be the rationals, v_p is the p-adic valuation of Q, then we have |x| = (1/p)^(v(x)) as the p-adic norm. It is also an example of a ultrametric norm.

Ultrametric norm: useful since it looks like p-infinity norm, it is a group homomorphism f(x+y) is less than or equal to the max(f(x),f(y)). It refers to the difference between the sup/max norm to this.

Normed space: vector space with norm. This has a notion of convergence, and linear structures, so series make sense.

Normed space are metric spaces: endow with taxicab distance d(x,y) = norm(x-y), pick whatever norm you want.

Open ball: set of all points where norm is strictly less than the radius. This work because norms are maps to positive half open rays, so the radius makes sense. For closed balls, change to not strictly less than the radius.

Convex subset: line segment joining two points lie within the set. Points can be as general as you want. Example, let e be the coefficient, we have ex + (1-e)y, or if we have functions we have f(ex + (1-e)y) <= e f(x) + (1 - e)f(y), where e is in open unit interval. You use an inequality here (Jensen's) to get a weaker version of homomorphism of convex functions. I realise you can have an inequality to form a weaker version of homomorphisms (I also realised homomorphism is a lot like linearity i.e. f(xy) = f(x) f(y)).

Constructing norms from bounded convex symmetric set: suppose N is zero on zero, has scalar multiplication. If the set where N applies such that N(x) is convex. Key step for proof: (N[x] / N[x] + N[y])(x / N[x]) + (N(y) / N[x] + N[y])(y / N[y]). The triangle inequality in N(x+y)/(N(x) + N(y)).

Lp norm: take sum of p power components modulus, then take 1/p power of the sum. L2 norm in Euclidean norm. Linfty is amx of components. Proof, key step is Lp norm is obviously norm, since L1 is Manhattan distance, trivially obeying triangle inequality, Linfty is a max norm, looks like a square. The function deforming L1 square to Linfty square preserves convexity of the set. You will need to show this in calculation.

Triangle inequality: I realise this is the whole basis of analysis, this is the weaker version of homomorphism, group law is addition. Example: f(x + y) <= f(x) + f(y), f is the NORM, + is the group law. If you have scalar multiple, this is just Jensen's inequality.

Max norm proofs: it always looks like this: step 1, norm is max norm, step 2: apply triangle inequality for norms within the max, step 3, decompose the max, step 4: redefine max to be the norm. State the max, split the inner norm, split the max, redefine max as norm again.

Jacobson ring: used to describe the Nullstellensatz, a Jacobson ring is every prime ideal of the commutative ring R is in the intersection of maximal ideals. See pg. 132 of Eisenbud.

Points near p in set X: Illustration in Eisenbud. Consider Y is algebraic subset of X not containing P, consider X - Y, this is not an affine algebraic set (examples: plane minus a point is not a affine algebraic set), however you can have it isomorphic to an algebraic set embedded in A^{r+1}(k). This is important: assume that Y is the set defined by vanishing of a single function f. So you can get the affine ring A(X - Y) and A(X), we can invert f by adjoining multiplicative inverses. This localisation gives is an algebraic thing like of the germ of X at p, the local ring of X at p.

Affine algebraic set: a subset in an algebraically closed field k^n if it can be written as the set of common zeros of a set of polynomials, there is a set M variables such that V(M) := {(x_i from 1 to n) in j^n, such that f(x_1, ... x_n) = 0}, this looks like some sort of kernel. Gives consequences if you have Hilbert's basis theorem.

V(affine algebraic set) = V(a for some ideal generated by M): proof containment affine algebraic set M in ideal a is obvious. Converse, write poly in ideal to be linear combination sum f_i g_i, f_i in affine algebraic set, g_i in poly ring k[X_1, ... X_n], then using conditionin (x_1, ..., x_n) in V(M) we have sum f_i g_i - 0, i.e. f = 0.

For any M in poly ring k[X_1, ... X_n], exists finite {f_i from i = 1 to i = m} in M such that V(f_i from i = 1 to i = m) = V(m): proof, Hilbert's basis theorem says that poly ring is noetherian since k is noetherian (it is a field). Ring is noetherian if every ideal is finitely generated or nonempty set of ideals have maximal elements, then this follows from part 1 and we have V(affine algebraic set) = V(a for some ideal generated by M) = V(f_i from i = 1 to i = m) where {f_i from i = 1 to i = m} are generating leements of ideal a.

Representable nature of limits / colimits: for functor diagram F: J -> C, there is natural isomorphism between C(X, lim_J F) and lim_J C(X, F-). Similarly, there is natural isomorphism for C(colim_J F, X) to lim_J^op C(F-, X). Note, be careful, the diagram is for the opposite category.

Reflective subcategory: consider category C, pick subcategory D such that inclusion (or embedding) admits left adjoint (preserving colimits) called reflector or localisation. Mnemonic: object looks at its reflection. 

Stone Cech compactification as reflector/localisation: category of compact Hausdorff spaces included into category of topological spaces. The reflector left adjoint is Stone-Cech compactification. 

Abelianisation as right adjoint of reflector: category of abelian groups admitted into category of groups, the reflector right adjoint is abelianisation.

Sheafification as reflector/localisation: sheaves as subcategory of presheaves, left adjoint is sheafification. 

Localisation as localisation for general commutative rings: inclusion of certain categories of general commutative rings have localisation as left adjoint to inclusion. 

Simplicial set into homotopy category as reflector: small categories included to the category of simplicial sets, the left adjoint sends simplicial set to its homotopy category, no good name for this.

Reflection of isomorphisms: consider a full and faithful functor F from category C to category D, if Ff is isomorphism in cat D, f is morphism in C, then f is isomorphism in C. 

Creation of isomorphisms: consider a full and faithful functor F from category C to category D, if Fx is isomorphic to Fy in cat D, and x and y are objects in category C, then x and y are isomorphic in C.

Full functor: consider category C and category D with functor F : C -> D, if C(x,y) -> D(Fx, Fy) is surjective, this is full for each x, y in C.

Faithful functor: consider category C and category D with functor F : C -> D, if C(x,y) -> D(Fx, Fy) is injective, this is faithful for each x, y in C.

Essentially surjective on objects: if for object d in category D, there exists Fc for object in c and functor F that Fc is isomorphic to d, then the functor F is essential surjective.

Essentially surjective: R be reduced finitely generated k-algebra, then R is isomorphic to poly ring k[X_1, ..., X_n]/a where a = rad(a) i.e. no nonzero nilpotents, nilradical is 0, then we have V = V(a) in k^n, we have sheaf of rings (V) isomorphic to R by Hilbert's Nullstellensatz.

Homotopical category: category is equipped with a class of weak equivalence.

Homotopical functor: functor is homotopical if it preserves weak equivalence.

Universal property of homotopy category: homotopical category C has a homotopy category HoC, universal property, initial among categories equipped with homotopical category C -> E, that is a functor that sends weak equivalence in C to isomorphisms.

Localisation functor: universal functor from HoC -> E. Precomposition with localisation functors induces bijection between HoC -> E and C -> E. 

Finiteness of commutative diagram: a diagram is finite if it is indexing category contains only finitely many morphisms.

Binomial theorem as convex combination: seems to be a generalisation of convex combination coefficients with NCj p^j (1-p)^(N-j), for j = 2 it is just p and (1-p), standard convex combination.

Temperature in stastistical mechanics: degree ot stochasticity in the system. See Sornette for better explanation. See also inverse temperature as measure of disorder or something.

Central limit theorem by pertubation: goal is to define some pertubation pdf close to Gaussian law, apply constraints for the cumulants and normalisation then show that the decay of the perturbation approaches zero.

Central limit theorem: normalised sum of 1/root(N) of N random independent and identically distributed variables of zero mean, and FINITE VARIANCE sigma^2 is random variable with pdf converging to Gaussian distribution with variance sigma^2. Convergence holds measure theoretical sense i.e. probability that above normalised sum falls in given integeral converges to that calculated from Gausssian distribution. Limitations: applies to centre of distribution, fails at large deviations, X_i must be independent, works for finite variance with same order of magnitude but DIFFERENT PDFS. The order of magnitude limitation is deviation sigma approximately root(N). You can relax the root(N) to get a weaker version of the central limit law. Very tricky example, but captures much of the collective phenomena one wants to study.

Central limit theorem with renormalisation group theory: see Sornette, step 1, decimate the degrees of freedom of groups of sum of pairs, this becomes some sort of tree, see Sornette, characteristic function looks like P^(n+1)(k) = [P^n(k)]^2. So cumulant is c_l^(n+1) = 2c_l(n) on log scale. Step 2 is to rescale the variables, cumulants are multiplied by 2^(a l), where a is to be determined and c_l has dimension k^(-l). In this case, pick alpha = 1/2. For cumulant cl we have 2^(1 - la), iterate process of decimation and rescaling, get that first two cumulant nonzero, rest becomes zero and shrinks in the limit, so it is a Gaussian law. Apply Fourier transform, to get characteristic equation of Gaussian law. See pg. 54 of Sornette, note that it is renormalisation of P(x, N, c1, c2, ...) = 1/(2^a) (x/2^a, N/2, 2^(1-a)c_1, ... 2^(1-l) c_l). So the second cumulant pops up naturally because in the decimation process, you just need to split into bins of two.

Central limit theorem with characteristic function: product of characteristic functions of a number of density function becomes close to the characteristic function of normal density, as the number of density functions increase without boundes under nice conditions up to scaling.

Stable extreme value distributions classification: Gumbel, Frechet, and Weibull. Location, scale, and shape parameter. For me, Taleb classifies political processes based on these three parameters as well.

Gumbel intuition: tail falls faster than power law, converges to Gumbel.

Frechet intuition: tail falling as power law X^(-1-mu), follows Frechet.

Weibull intuition: pdf with finite right end point, dependence close to this end point with (x_F - x)^(1 / |eta|), eta is shape parameter, x_F is endpoint. Explains why Weibull is very common.

Derivatives of the characteristic function: (-i)^n d^n(P(x))/dk^n at k = 0, then you can express it as some sort of Taylor series, in fact this will appear as the cumulants of a pdf.

Cumulants: derivatives of the logarithm of the characteristic function, it looks like the action of the (-i) as an action (circle group in the imaginary plane) on the n-th derivative of the logarithm of the probability distribution at k = 0. We have c_n = (-i)^n d^n(log(P(k)))/dk^n at k = 0. So you can write the characteristic function as the exponential of a Taylor series i.e. sum of exp(sum c_n / n! (ik)^n), it becomes the action of (ik) instead. Sum is cumulant preserving, proof is using product of convolution is product of Foruier transform. Also, it motivates alternative measures of dispersion from normality, fixing some problems with moments of a probability distribution. Another motivation for it is that the variance is second degree homogenous i.e. var(cX) = c^2 var(X), translation invariant var(c + X) = var(X) and cumulative var(sum of X_1 to X_n)
= sum of var(X_i) from 1 to n.

Dutch book argument: bettor puts in px, house gives x, at odds (1-p)/p, house can set x to be anything but the bettor must accept both sides of the bet (win/lose). Bettor is consistent if it is not forced to accept a sure loss in probability assignment. I learnt of this argument in Sornette's book.

Mode: maximises frequency count i.e. dP/dx = 0. If nonunique, then pick largest mode value. so argmax(dP/dx = 0).

Moments (in probability, physics): average of the powers of x, so x works as action on probability. It is integral of x^n * P(x) dx, supported on the entire real line.

Support: possibilities for some values. Example: alphabets in the dictionary. Real number values possible.

Mean value based on philosophy in probability: adding all values dividing by number of cases. This is the combinatorial approach converted to the frequency approach.

Frequentist interpretation (braindead version): just imagine X number of times happening, then some part Y smaller than X will happen.

Filtration: nondecreasing family of sigma algebra F_0 in F_s in F_t , for 0 < s < t. Basically, the set of possibilities become larger.

Stochastic processes as random functions of one random variables: events are sets of paths, are typical paths continuous? Motivates random fields, with more than one random variable.

Stochastic process as probability distribution on path spaces. Use functional analysis with path spaces as infinite dimensional spaces. Measure theory suggests no analogs of Lebesgue measure (translation invariant measure) on such spaces, so hard to construct nontrivial measures on these spaces.

Motivation for Kolmogorov extension theorem: consider fixed finite set of points, get random vector distributed on finite dimensional space. Extension theorem allows one to construct stochastic process from family of consistent finite dimensional probability distributions.

Stochastic matrix is largest eigenvalue with Gershgorin discs: consult Horn, eigenvalues lie in Gershgorin disc, so spectral radius 1.

Spectral radius of probability matrices is 1: proof (Spivey) starts with assuming 1 is eigenvalue of transition matrix. Suppose we have (A - e I)x = 0, e > 1. Rows of A are nonnegative, sum to 1, each element of Ax is convex combinations of components of x, not greater than x_max. But if e > 1, one element of e x is greater than x_max, so we cannot have e > 1! See https://math.stackexchange.com/questions/40320/proof-that-the-largest-eigenvalue-of-a-stochastic-matrix-is-1.

Symmetric random walk: +-1, with probability 0.5, random walk on integers. Markov, because distribution is completely determined, probability of Xn+1 conditional on Xn alone.

Transition probabilities: probabilities in state j at n + 1, conditional on state k at time n. Motivated by definition of Markov process, so must understand what a Markov process is first.

Stationary: Markov process where transition probabilities do not depend on state n.

Invariant distribution: action of invariant distribution pi is such that pi = pi * P, i.e. probability transition matrix is idempotent on the invariant distribution.

Action of stochastic matrix of Markov chain: for Markov chain u_n, it is equal to u_n = u_0 P^n, where P^n is the repeated application of the stochastic matrix P, for time up to n (indexing set assumed to be nonnegative integers).

Stochastic matrix: all entries nonnegative, sum of all entries is 1.

Chapman-Kolmogorov equation: probability of state j at time n, given state i at time 0, is sum of all trnasition probabilities in the state space S, probability of state j at time n, given state k at time m * probability of state k at time m, given state i at time 0. This is just Baye's rule, with stipulation of Markov chain giving only one instance of the product for each state space.

Markov process: probability of Xn+1 is conditional on Xn = probability of Xn+1 conditioned on whole history.
Easy to build nonexamples, such as left right random walk such that once you go right, the next step must be right.

Ehrenfest diffusion model: middle membrane container with K particles, pick one at random and place in other part of container. This is Markov process, just look at the current state and you can determine the probability of the next outcome.

Lattice: partially ordered set where each two element subset has a UNIQUE least upper bound (join) and dually a UNIQUE greatest lower bound (meet). Alternatively, a set with two binary absorptions in to A for a join (a meet b) = a and a meet (a join b) = a.

Formal concept analysis: pick complete lattices, with pairs of objects (A, B) where A is extent or set of objects, B is intent or set of attributes. Extent contains all objects that share the attributes in B, intent contains all attributes shared by object in A. Constitutes meet and join.

Descent as inverse of stable under base change: see "https://math.stackexchange.com/questions/4769096/smooth-proper-connected-curve-over-a-field-is-projective". The idea is instead of saying "if f: X -> S has property P, then base change X *_S S' -> S' along S' -> S also has property P", we ask "if X *_S S' -> S' has property P, must f: X -> S has property P"?. For nice S' -> S (the magic words for the case presented is faithfully flat, quasicompact), then you have closed immersion, descent.

Closed immersion in terms of quotient rings: a closed immersion is locally a quotient ring, a base extension is locally a tensor product.

Inverse image of sheaf which is not a sheaf: consider topological space Y, define X as two disjoint copies of Y, set f : X -> Y as canonical projection, take G, sheaf on Y. For subset V in Y open, and define U as the preimage using f on V, we have sheaf F such that  F(U) = G(V). So F = f^-1(G), F is presheaf. But the preimage of a sheaf (f^-1 F)(U) := F^sh(U) = G(V) * G(V). So the inverse image of the sheaf gives cartesian product of sheaves G, but the inverse of the canonical projection is a sheaf. Example: section of one copy, section on other copy, you cannot glue them together, intersection is empty since these are disjoint copies.

Partially ordered set: reflexive (p < p), antisymmetric (i.e. p < q or q < p but not both), and transitive (p < q < r).

Poset of truth values: {0, 1}, we have 0 < 1 as partial order.

Horizontal categorification: step 1: pick concept as magmoid (binary operation) with single object. Typical example is thinking of group as category of one object with morphisms that are all invertible (unitary by default due to category definition), the -oidfied by presenting more than one object instead.

Horizontal categorification of monoid: gives category! Start with unital associative magma i.e. one object with binary operation that has identity and is associative. Do horizontal categorification, it gives a category.

Horizontal categorification of untyped languages: is a typed language.

Magmoid: quiver (generalise set) with partial binary operation Mor(Q) * Mor(Q) -> Mor(Q) + 1, coproduct injections inj: Mor(Q) -> Mor(Q) + 1, such that there is function h in preimage inj(h) = f * g, if s(f) = t(g) and f * g  = point. Easier: groupoid is oidification of group. Group can be category with one object, and isomorphisms on that one object. Groupoid extends to more than one object.

Quiver: generalisation of set, opposite category, and even presheaves! It is a functor G from X -> Set. Where X is a walking quiver. Quiver in a category C is X -> C, C is some category.

Walking quiver: cateogry with one object of vertices X0, one object of edges X1, two "contravariant/preimagey" morphisms s,t: X1 -> X0 called source and target, with identity morphisms. For some reason, it feels like simplifical structure trying to be built in to set.

Category of quivers in C, Quiv(C): functor category C^X, where X is the walking quiver, where objects are functors G: X -> C, morphisms are natural transformations.

Examples of category of quivers in its simplest case: Quiv(Set) is equivalent to category of presheaves on X^op, where X is category of walking quivers.

Toy example of linear functional: consider functions from unit intervals to the reals, define linear functional F(u) = u(1) - u(0). F is not continuous or defined everywhere on L^2(0,1) failing at measure zero single points, but continuous on H^1(0,1). This motivates the trace operator to be defined for H1, then you can use them to sovle PDEs. This example motivates why you do not want to use L^2 spaces for everything.

L^2 space: set of square integrable L2-functions, where <f, g> = int_X fg du, for measure u. Example: pick X = reals, with Lebesgue measures, these are the square summable series. These are equivalence classes of functions with the same L^2 function where the set they differ has measure zero i.e. one point. It is a sort of density function giving bad boundary conditions in differential equations for point f(p) since it is not well defined on measure zero since it is an integral. L stands for Lebesgue measure.

Functional analogous to energy: functional is analogous to ENERGY. This is why functional analysis is so important, for example minimising energy / action. Example: Dirichlet functional is integral | grad u |^2 dx

Specialisation topology / Alexandroff's topology: subset A of preordered set, is open subset if it is upward closed, i.e. if x <= y, x in A, then y is in A. This is a topology, or the specialisation topology. Example: apply specialisation topology to poset of truth values {0,1}. Start with empty, then {1} is open, and total space {0,1} is open.

Sierpinski space: set of 0, 1, topological space is {}, {1}and {0,1}. Note: {0} is omitted. It can also be defined using homotopy type theory as higher inductive type using constructors for meet, top terms; type, left, right associativitt, commutative, idempotence, for meets and joins; meet-join absorption, join-meet absorption, and other functions. Very long, see ncatlab.

Sifted category: category where colimits of diagrams of shape D commute with finite products in category of Set. Consider diagram functor F: product D and S -> Set, S is finite discrete category, the colimit commutes with finite products.

Discrete category: it is a groupoid and preorder i.e. all morphisms are invertible, and two parallel morphisms are equal.

Accessible cardinals: apply cardinal arithmetic on cardinal numbers like omega for infinity, successors, disjoint union for addition, Cartesian product for multiplication, power set of functions for exponentiation. If you cannot use these to get the cardinals you want, these are the inaccessible cardinals.

Schwarz lemma: apply maximum modulus priniciple on function g(z) = f(z) / z if z nonzero, and f'(0) if z = 0, i.e. derivative when z = 0, feels like differentiation and localisation to me, holomorphic on the whole of D at origin,look at |g(z)|. For z_r on boundary of D_r, we have |g(z_r) which must be less than 1/r, if r tends towards 1, then |g(z)| less than or equal to 1, now pick |f(z)| = |z| or |f'(0)| = 1, then f(z) = az with |a| = 1. This gives the hypothesis of the open unit disk centred on origin, and holomoprhic map where f(0) = 0, |f(z)| is less than or equal to 1.

Spin group: Lie group whose manifold is double cover of special orthogonal group, for short exact sequennce 1 -> Z/2 -> Spin(n) -> SO(n) -> 1. Group law by lifting multiplication of special orthogonal group. Represents symmetries of fermions. Complexification describes electrically charged fermions or electrons. Strictly, works only on fermions in zero dimensional space, fix this with pseudo-Riemannian manifolds.

Diagram chasing as linear algebra (Daniel Litt on Math Overflow): ASSUMING category of finite dimensional vector space, diagram is finite acyclic, (1) triangulate all composition of arrows, spam kernels and cokernels until terminates; (2) tabulate all exact paths or infinite long exact sequences, all but finitely many objects are zero, (3) can write the equation of the exact path sum (-1) dim A_i = 0, then solve linear system for dim Ai, telling you about surjectivity and injectivity. See also Gelfand and Manin Methods of Homological Algebra, Section II.5. The E construction in the exercise or MacLane's members.

Common diagram chasing lemma: salamander lemma is the basic, then you have the 3 by 3 then n by n lemma, then four lemma to five lemma, and the snake lemma which generalises to the connecting homomorphism. Lastly, there is the braid lemma.

Open mapping theorem: nonconstant holomorphic functions map open sets to open sets. If |f| obtains locally maximum at z and nonconstant, take sufficiently small neighbourhood and the image, this cannot be open by open mapping theorem, so |f| is constant, therefore proving the maximum modulus principle.

Maximum modulus principle in heat equation: log |f(z)| of heat equation is harmonic, it is the steady state on region D, if STRICT maximum obtained of D, heat at this maximum will disperse to nearby point, contradicting that this is steady state.

Maximum modulus principle: if f is holomorphic, complex differentiable at each point in its complex domain, modulus |f| cannot obtain strict maximum that is strictly within the domain of f.

Compact topological group: topological group whose topology can be realised as a compact topological space, element of group operated on, result is within that group. Examples: circle groups, orthogonal group of rotations, unitary groups, torus groups.

Lorentz group is noncompact: group preserving quadratic form x^2 + y^2 + z^2 - t^2 is Lorentz group. Clearly this is unbounded.

Quadratic form: all terms are degree 2 i.e. Ax^2 + Bxy + Cy^2.

Immersion of linear maps: maps whose derivative everywhere is injective as a linear map (locally). In topology, you do not require it to be homemorphic to its image. Embedding requires injectivity and continuity, X and f(X) to have same topological properties. Example: immersion is mapping circle to figure 8, or double circle onto circle or semiopen interval to circle, inverse map is not continuous.

Immersion: tangent spaces are mapped injectively. Example: Klein bottle, any point of intersection has two distinct tangent planes, map is injective onto R^3. But Klein bottle cannot be embedded in R^3. Best thought of as a local embedding.

Jaffard ring: ring such that poly ring R[T1, ... T_n] = n + dim R, so dim of variables + dim of ring itself is equal to dim of poly ring (NOTE: using Krull dimension, Noetherian chain definition)

Embeddings in concrete categories: since concrete categories have underlying set, you can just use injective functions on underlying set to define embeddings for concrete categories. However, general definition of embedding does not exist yet. The dual of embedding is a quotient, this makes sense if you think about algebraic geometry.

Embedding as topological invariant: a (topological) space is different from another if one object can be embedded in the space, and the other cannot.

Embedding in topology: homeomorphism onto its image, or injective continuous map f: X -> Y, if f is homeomorphism (preserving topological structure) between X and f(X), where f(X) inherits subspace topology of Y. 

Locally injective / locally embedding at point: consider neighbourhood and the point as the domain for the injection as a restriction of a function. Similarly, restriction of an embedding to the neighbourhood of the point. Note: generalises say for topological embeddings, smooth embeddings, isometric embedding in Riemannian geometry, field embeddings using ring homemorphisms and instead of neighbourhoods you use ideals.

Morphism in category theory as structure preserving map: since it is still in the same category, therefore morphisms in category is a structure preserving map.

Laurent series of complex f(z) about point c: generalises Taylor's series with positive and negative dimension. f(z) can be represented as sum of a_n (z - c)^n from negative infinity to positive infinity. Coefficients a_n is path integral f(z) / (z-c)^n+1 divided by 2 pi i.

Complementary: variables in primal problem is complementary to constraints in dual problem. There cannot be a slack in both a constraint and the corresponding dual variable. Result from duality of linear programming problem. Intuition: benefit problem is dual to cost problem.

Centraliser of a subset S in a group G: set of elements in G that commute with every element in the subset S. Motivation is also very good, you can apply techniques of commutativity to a group that is noncommutative. Obviously, a subgroup of G by definition. This motivates the name commutant.

Centraliser need not be abelian: example centraliser of identity of the full group is not abelian.

Normaliser of a subset S in a group G: set of elements in G that is fixed under conjugation.

Rolle's theorem: real differentiable function with two equal values at two distinct point must have one point bin between them a stationary point.

Galois conjugate: element of a separable closure L of a field K, which are in the orbit of x under the group action of the absolute Galois group G_K on L. Generalise complex conjugate to some random fields.

Axiom K: loop function or self identification induction, turns intensional type theory into extensional type theory.

Landau's function: maximum order of element in symmetric group. Or least common multiple of all partitions of number 1 to n. Example of the order of an element in a group.

Abelian group: the following are equivalent: (1) an abelian group is group where every element is self conjugate example: a = gag^{-1} or ga = ag, this gives the reason why abelian is so important; (2) an abelian group is 1 where all irreducible representations of G have degree 1, proof key step is let g be order of G, h is number of classes of h, (n_1, ..., n_h) be degrees of distinct irreducible representations of g, g = sum of n_i^2 and is only equal to h if and only if all n_i = 1; (3) st = ts for all s, t in group G; (4) all conjugacy classes consist of a single element (self conjugate, conjugacy classes are equivalence classes under conjugation); (4) each function of G is a class function which are functions that are constant for the same conjugacy class as linear combinations of characters;

Group conjugate and linear algebra: conjugate is b = gag^{-1}, this is used all the time in linear algebra by the way since if inverse equals to conjugate transpose, b is unitarily similar to a, g is group action.

Conjugacy relation: equivalence relation of conjugacy classes. Example: invertible matrices form general linear group, matrix similarity is conjugacy relation. Unitary matrices for unitary group, unitary similarity is conjugacy relation.

Conjugate: element a, b, g in group such that b is conjugate of a means b = gag^-1.

Conjugacy classes, equivalence of conjugates form an equivalence class that is reflexive, symmetric, and transitive, so this is a conjugacy class.

Class functions: functions that are constant for members in same conjugacy classes. This is also given in Serre explicitly as f(uv) = f(vu) or f(uvu^{-1}) = f(v). Each class function is a linear comnbination of characters.

Character: complex valued function on the group, for vector space V as a representation of group G we have x(g) = Tr(g|v) for elements g in a group. Characters are preserved by group conjugation, we have x(g) = x(hgh^-1). Further, x(1) = dim V. Direct sums give addition of character (characters are like dimensions, so is sum of eigenvalues), tensor products give multiplication of characters (product of eigenvalues), duality of vector spaces gives conjugation of characters (eigenvalues are n-th roots of unity, n the order of the element g), exterior powers of characters i.e. x_(Ext^2 V)(g) = 0.5(x_V(g)^2 - x_V(g^2)) (given by sum of products of eigenvalues apply binomial theorem), symmetric powers of characters, the x_(Sym^2 V)(g) = 0.5(x_V(g)^2 + x_V(g^2)) from comptability of symmetric power and exterior power decomposition of the tensor product.

Residue field of local ring: local ring has one maximal ideal, so the residue field is unique for a local ring.

Residue field: (1) quotient ring of a commutative ring and a maximal ideal; (2) quotient of structure sheaf at point x with the unique maximal ideal at that point, this is denoted k(x) see Qing Liu's definition 2.19.

Reduced commutative ring: commutative ring with no nonzero nilpotents. Meaning: equivalently nilradical is zero.

Nilradical of a commutative ring: ideal of nilpotent elements. Radical of zero ideal. Sum of two nilpotents is nilpotent (binomial theorem), product of two nilpotents is nilpotent (commutative!). See the idea of ideals as absorbing element to become some sort of closed submodule. 

Localisation: adjoining quotients to the ring defined by (x,s) related to (y,t) for (xt - ys)u = 0. Satisfying (x/s + y/t) = (xt + ys)/st, and x/s * y/t = xy/st. See Borcherd's video for two step proof, I forgot about it. It basically corresponds to zooming in on a variety. Need multiplicative subset S. Example: R integers, S to be nonzero integers (multiplicative subsets), you have R[S^-1] to be rational. Another example, R integers, S to be even integers, get localisation to be Z/2, therefore looks like localisation of a spectrum zooming in points other than (2) in Spec(Z).Another example, pick R = C[x], S all nonzero elements, then R[S^-1] is rational functions. pick S = {x} instead then R[S^-1] is Laurent polys.

Localisation with copying construction from rationals, only for case with no zero divisors: for ring R, S multiplicative subset, mostly harmeless. Construction of Q from Z, consider pair r/s. But 4/2 = 2/1, so need equivalence relation. For addition, need r1s2 + r2s1 / s1s2, need multiplicative subset, then r -> r/1 has one subset. Check equivalence relation, operations defined, ring axioms. ONE SUBTLE POINT, checking transitivity of equivalence relation, r1/s1 equivalent to r2/s2 and r2/s2 equivalent to r3/s3, so you get r1s2s3 = r2s1s3 = r3s2s1, implying r1/s1 = r3/s3 ASSUMING s2 is not zero divisor i.e. divides zero. Injectivity R to its localisation also uses the fact that there are no zero divisors. Motivates s(r1s2 - r2s1) = 0 as equivalence relation. 

Zero divisor: nonzero element b such that ab = 0 for any a in ring. Double sided, of course you can have left and right zero divisors.

Localisation relation to linear algebra: construction by R[t1, t2, ...] quotient out by (s1t1 -1, s2t2 - 1, ...) as ideals. Furthermore, this makes it such that elements of (sx tx - 1) or in linear algebra (A - e I)^n for eigenvalue e, linear transformation n as action of nilpotent over subspace.

Nilradical is intersection of all minimal prime ideals: proof for commutative ring A, all ideals contains zero, all prime ideals contain prime nilpotent r^n = 0, every prime ideal contains nilradical. Conversely and equivalently (Brandenburg), assume an comm. ring element a is not nilpotent, show there exists prime ideal does not contain this non-nilpotent element (is enough to show inequality), then localisation of ring A at element a is nonzero (if not then 1/1 = 0, then a^n 1 = 0, then a^n nilpotent which is untrue). Since the localisation is nonzero, it has a prime ideal p (unique maximal element, Zorn's is used here), the preimage in A is a prime not containing element a, since a is non-nilpotent and p is a prime ideal and should not contain invertible elements, so eleemnt a is not contained in the intersection of all prime ideals.

Unitary: inverse equals conjugate transpose for matrix.

Nilpotency: collapse dimensions to lose all informations. All linear transformation is an action of nilpotent over subspace. This connects group theory, to linear algebra.

Generalised eigenvector: (A - e I)^k w = 0, A matrix/linear transform, e eigenvalue, I identity matrix, k integer, x vector. Then we have (A - e I)^(k - 1) x = v, v is eigenvector. This gives all linear transformations as some action of a nilpotent (A - e I) over some subspace x.

Linear transformation: function of vector space such that f(ax + by) = a f(x) + b f(y). In linear algebra, x and y are elements of vector space, but this definition is an indirection and can be generalised.

Functional analysis no-eigenvalue example: S(a1, a2, ...) = (0, a1, a2, ...), Sx = ax, suppose eigenvalue a nonzero, BUT limit of product of a is nilpotent i.e. a^n x, n tends towards infinity. But a is nonzero! So x must be zero.

Wiener process: Gaussian process, with funny covariance function K(s,t) = min(s,t) as random series. Markov process with generator as Laplace operator, and transition density as heat kernel.

Conditional probability: ratio of probability of A and B over probability of B. Intuition, given B, you can divide by the probability of B since you know B will happen, to raise the likelihood of A and B (less or equally likely) to A given B (more or equally likely).

Conditional expectation of integrable function: integral of events f(omega) over probability distribution P in A divided by the probability of A.

Poisson random variable: it is like a memoryless queue, probability is (expected value ^ time)/(time factorial) * damping exp(-expected value), since the expected value being achieved means the effect of the queue is damped somehow. The mean and the variance is the expected value. Limit of Binomial process as the number of bins is infinite and the probability gets to zero, by simple substitution. Intuitively, this makes sense, you have an infinitely small time slice of something showing up in the queue to consider as a Poisson if you think of it is as Binomial. Proof, substitute np = lambda, then take k fixed, n >> k.∂

Characteristic function of a random variable: expectation of the damping e^{i zeta X} or the integral of the damping e^(i zeta x) aka the Fourier transform of the probability distribution. Apply Fourier theory to probability theory. There are three ways to calculate: first is using a sum or an integral, the second is to interpret it as the expectation of the e^{i zeta X}, the third is to think of it as a Fourier transform.

Independent random variable: preserved under products of random variable.

Curry-apply adjunction: equivalent to tensor hom adjunction. Apply is hom, currying is tensor product. Example: in Lisp (apply #’ + (list 1 2)) looks like hom from + to list. See Wikipedia.

Apply: space of exp object Y^X given Y compact open topology, X is locally compact Hausdorff. Needed for homotopy to be continuous paths in space of functions.

Mean value theorem: secant through endpoints, you can find tangent that is parallel to that. Feels like extreme value theorem but for first derivative?

Eigenspace: eigenvectors set of eigenvalue + zero vector. 

Indirection: keep the name, change the object. Example, website name, IP address, keep the website name, change the address. Indirection lets you choose the reference to be invariant, not the object. Better definition: indirection is the contravariant functor to covariant naming. Name network addresses with human readable addresses. INDIRECTION from human readable addresses to network addresses. Indirection is left adjoint to naming which is right adjoint.

Bernoulli source, hamming distortion: probability from 0 to 1/2, Hamming loss is H(p) - H(D) for prescribed distortion less than the probability (so there is loss), and zero if the prescribed distortion is larger than the distortion. This is proven by (1) considering that the rate distortion function is the minimum of the mutual information between the input X and output X^, then simply calculate the joint pmt of the two that satisfies where H(X + X^) = H(D).

Prescribed distortion: D as the upper bound for the limit supremum of the expectation of Hamming indicator loss between input X^n and output X^n.

Reliability function: probability of error decays exponentially with the code length, the minimal error exponent

Achievable rate: sequence of (2^nR, n) code such that probability of error tends to zero as the code is large. NOTE: it is insufficient to define it as argmin_R of the average of probability of error.

Binary symmetric channel, crossover: channel capacity using Shannon theorem gives max I(X;Y) = max H(Y) - H(X + Z|X), Z is Bernoulli p noise. This is max H(Y) - H(Z) = 1 - H(p), where p is probability of noise.

Binary symmetric channel, erasure probability p: this is just H(X) - p(H(X)) = 1 - p. Entropy is 1.

Probability of error: sum of conditional probability of error averaged over upper bound of throughput ceil(nR), n is length, R is rate. For an individual symbol: this is lambda(C) = P(M^ != m | M = m). It just means the probability the message is not realised given the alphabet. Average probability of error is just take the average over 2^ceil(nR)

Memoryless channel: ergodicity property over length n, with message M, input X^n, time i in [1:n], p(y_i | x_i) = p(y_i | x^I, y^I-1, m). Basically, x^I is input at the same time, y^i-1 was the output at the previous time, and m is the message. Memoryless channel, in El. Gamal in its most relaxed form, means that the conditional properly is dependent only on the message, input on time, output at previous time.

Discrete stationary memoryless channel: finite input set X, finite output set Y, conditional probability mass functions p(y|x) on Y. Instant transmission. Classical example is binary channel.

Discrete stationary memoryless SOURCE: alphabet X, probability mass function p(x).

Optimal lossless compression: infimum of all achievable rate. For a discrete stationary memoryless source, this is the entropy. Achievability uses typical sequences and encoding. Converse uses Fano's.

Hamming distortion: indicator function for error.

Max. differential entropy under average power constraint: achieved when X is normally distributed. The maximum of differential entropy h(X) when E(X^2). Is less than or equal to P is given by 0.5 log (2 pi e P), where P is power and is sigma squared. Therefore, for any X following pdf f(x) we have h(X) = h(X - E(X)) is less than or equal to 0.5 log (2 pi e Var(X)).

Power constraint of Gaussian channel: block length n then expected sum of square of random variables E(sum Xi^2) / n is less than or equal to P. Note that this is very similar to a kinetic energy term, dividing by n gives some sort of power since alphabet n is index of sequence, alphabet, or support. Hence the name, power constraint for a Gaussian channel. This is 0.5 log (2 pi e sigma^2), start with KL-divergence differential entropy D(f || phi) definition, get -h(X) and expectation of log(1/phi X), where phi X = e^{-X^2/2}/root(2 pi). This will give -h(X) + 0.5 log 2 pi + 0.5 log E(X^2) <= 0 for no KL divergence giving the constraint.

Capacity of Gaussian channel under power constraint: by power constraint of differential entropy, we have 0.5 log (2 pi e(P + sigma^2))- 0.5 log (2 pi e sigma^2) as the mutual information from h(Xg + Z) - h(Z) where Z is H(Y|X) for channel Y output Yi = Xi + Zi for input X, Zi independent of X. The subtraction of log simplifies to a quotient 0.5 log(1 + P^2/sigma^2).

Turing machine: finite control and single tape and pointer with symbols 0,1,B, B for blank

Bayesian reasoning: P(D|H) P(H) = P(H|D) P(D) or posterior * marginal = likelihood * prior. This is Wittgenstein ruler form. One can replace P(H) with sum of P(Xi) P(H | Xi) or sum of marginals, and still derive multivariate Bayes’ rule

Minimum description length from Bayesian reasoning: consider argmax P(D|H) P(H), take bit log and argmin of negative so argmin E(D|H) + E(H). Gives the minimum description length principle.

Chaitin constant: probability that computer halts when input p is a binary string drawn according to Bernoulli(1/2) process. Or sum of reciprocals of alphabet size of any program p that halts. Not computable, since no finite mechanical way to solve halting problem.

Slepian-Wolf code: correlated sources X, Y can be described at rates RX, RY, recovered with arbitrarily low probability if RX more than or equal to conditional entropy X given Y, RY more than or equal to conditional entropy Y given X and RX + RY more than or equal to joint entropy H(X, Y)

Chaitin constant philosopher's stone: list all programs in binary, supposed you have n bit of Chaitin constant, difference between full Chaitin's and truncated Chaitin's is less than probability of cardinality n (reciprocal of alphabet of n characters). Contributions in reciprocal of program length size is also less than that of reciprocal of alphabet of n characters. So, no program of length n that has yet to halt will half. Run increasingly longer lists of programs to keep track which one halts, find proofs to any yes/no theorems in less than n bits with 2^n characters of Chaitin's constant. Example: program that halts with counter-example to Fermat's last theorem. Program has finite bits N, so with 2^N bits of Chaitin's constant, can determining Fermat's last theorem. WARNING: Godel incompleteness still not bypassed since one cannot find effective procedures.

Kraft inequality: instantaneous codes iff sum of alphabet length raised to the string length for each strength is less than or equal to 1.

McMillan inequality: uniquely decodable codes iff sum of alphabet length raised to the string length for each strength is less than or equal to 1.

Effective alphabet size: 2^{nH(X)}, X discrete.

Effective support set size: 2^{nh(X)}, X continuous.

Effective channel capacity alphabet size: 2^{C}

Nats: replace 2 with e, same laws hold.

Rate distortion theory: relax constraint on lower bound of entropy for compression, find channel capacity to receive signal with acceptable distortion

Channel capacity: maximum mutual information between input and output given a probability transition matrix p(x) gives number of distinguishable inputs (not definition, but is Shannon's channel coding theorem). Alternatively, supremum of all achievable rates of a discrete memoryless channel. Examples: binary symmetric channel has capacity 1 - entropy. Note, one can set a constraint where the sum of the codebook is less than nB.

Channel coding theorem proof: random coding, joint typicality decoding. Weak converse requires Fano's inequality.

Jointly typical sequences: tuples of x y with joint distribution p(x,y) such that the difference between the entropy definition as negative expectation of logarithm for p(x), p(y) and p(x,y) are arbitrarily small (converges in probability).

Feedback capacity: feedback does not increase capacity for discrete memoryless channels.

Source-channel theorem: stochastic process with entropy rate H cannot be sent reliably over discreteness memoryless channel of entropy H more than channel capacity C.

Channel coding theorem: all rates below channel capacity are achievable, using random codes (2^(nR), n) codes, with rate R, n cardinality.

Mutual information: expected value of logarithm of covariate probability ratio p(x,y) / p(x) p(y).

Entropy: negative expectation of the logarithm of a probability distribution. This is concave. This is the average distribution length or the expectation of the ideal word length.

Ideal word length: negative of logarithm of probability distribution.

Estimated probability distribution of average distribution length: sum of entropy of distribution and the joint entropy / KL divergence of the probability distribution and its estimator.

Average redundancy: difference between expected actual word length and entropy.

Joint entropy (KL divergence): negative expectation of logarithm of a joint probability distribution. Different from Shannon's definition. This is convex.

AEP for ergodic sequence: 2^(nH) typical sequence, with probability 2^(-nH) uniform.

Entropy chain rule: the joint entropy is the sum of the unconditional entropy of X and the entropy of Y conditioned on X.

AEP for large deviations: probability of set is 2^(nD), D relative entropy between closest element and true distribution.

AEP: the logarithm of jointly independent and identically distributed random variables divided by sequence cardinality converges to the entropy in probability for sequence that is stationary ergodic.

Typical set: sequences that are between the probability of a set 2^(- card(X) H(X)) up to probability error 2^(- card(X) epsilon). This definitions lets you get high probability for cardinality large of set.

Markov chain thermodynamics: relative entropy to stationary distribution decreases with time. Entropy increases IF stationary distribution is uniform. Conditional entropy H(Xn | X1) increases with time of stationary Markov chain. Conditional entropy of initial condition H(X0 | Xn) increases for any Markov chain.

Entropy rate of joints for alphabet: limit of joint distribution of random variables divided by cardinality as cardinality of Markov chain approaches infinity.

Entropy rate of conditionals for alphabet: limit of conditional distribution of Markov chain terminal random variable against adjacent random variables as the cardinality of the Markov chain approaches infinity.

Stationary stochastic process: entropy rate of joints and conditionals are equal.

Conditioning: condition entropy is less than or equal to unconditional entropy

Log sum inequality: Jensen's using finite summations, only for non-negative inequality.

Relative entropy: sum of product between probability and log of prob. distribution ratio. Also, the expectation of the log of distribution ratio with respect to p(x)

Jensen's inequality: for convex f, expectation of payoff is more than payoff of expected frequency. Payoff space is better than probability space. Trick: use - concave to get convex. Proof sketch: draw slant line passing through y = x^2. Recall, convexity is lines segment lieing within the set. See triangle inequality, and see convexity as some geometric stuff. We have f(tx + (1-t)y) <= t f(x) + (1-t) f(y).

Jensen's gap: difference between the decomposed convex combination and the composed convex combination.
 
Information inequality: joint entropy (KL divergence) is nonnegative. Similarly, mutual information is nonnegative.

Zero joint entropy: occurs when distributions are the same.

Zero mutual information: occurs when distributions are independent.

Data processing inequality: if X to Y to Z is Markov chain, then mutual information I(X,Y) is more than or equal to I(X,Z). Proof I(X, Z|Y) is zero by definition of Markov chain.

Sufficient statistic: consider n -> X -> T(X) Markov chain, T(X) statistic, X random variable, n is indexing. Data processing inequality gives mutual information between indices and random variable - mutual information of indices and statistic to be nonnegative. Definition: this difference is equal to zero if T is a sufficient statistic. Example: number of tails is sufficient statistic to recover Bernoulli variable. Example: max and min values is sufficient statistic for uniform distribution.

Minimal sufficient statistic: if it forms “contravariant” Markov chain n -> T(X) -> U(X) -> X for any other sufficient statistic U. Alternatively, it has the same Kolmogorov complexity as the indices n, or it maximally compresses the indices n.

Fano's inequality: consider Markov chain of input X to output Y to correlated reconstruction X*, then let the error probability be probability that X*(Y) is not equal to X. Then Fano's inequality states that the sum of entropy of the error probability and the error probability times the logarithm of the (alphabet/support- 1) is more than or equal to the conditional entropy X given Y. Intuitively, entropy of error probability is uncertainty with correct predictions, the logarithm of the (alphabet/support -1) refers to the entropy of uniform distribution of all incorrect choice. Therefore, H(X|Y) is less than or equal to Hb(e) + Pe(X) log(card(X)-1), Hb(e) is binary entropy of Pe(X != X*)

Independent and identically distributed inequality, if X and Y are independent and identically distribution, the probability that they are equal is more than 2^{-H(X)}.

Markov chain: X, Y, Z forms Markov chain if X and Z are conditionally independent given Y or I(X, Z|Y) = 0 or Z depends only on Y, conditionally independent of X.

Hypothesis testing distance: relative entropy between hypothesis is exponent in error probability of hypothesis test.

Randomly generated code: Shannon used it to have achievable rate with arbitrarily low probability of error.

Prefix complexity K(x): use conditional Kolmogorov complexity, but programs and data must be self-delimiting. This is called K(x) since not having self-delimitation is annoying and disables some inequalities.

Kolmogorov complexity C(x): not to be confused with prefix complexity K(x); fixing an additively optimal partial computable function phi, it is the conditional Kolmogorov complexity C(x | epsilon). Epsilon is natural number on auxiliary tape.

Conditional Kolmogorov complexity C(x|y): minimum cardinality min(l(p)) such that an additively optimal partial computable function phi(<y, p>) for natural y and program p gives data x. If the program does not exist, then this is infinite. If the program is self-delimiting, then this is K(x|y). WARNING: the definition is subtle, since the program must halts without reading the next symbol after p, it does not need to calculate since it is conditioned on y. See Example 3.1.2. page 206 of Li and Vitanyi.

Computability theory: needed rigour to get quantitative bounds on Kolmogorov complexity. Motivates universal semicomputable semimeasures and stuff

Additive optimality: goal is to have unique minimal element (avoid nonsense with axiom of choice), defined by ensuring existence of functions with greater Kolmogorov complexity up to constant for any Kolmogorov complexity of function i.e. Cg(x) + c_f,g >= Cf(x)

Turing's thesis: effective procedure defined by Turing machine

Church's thesis: objective notion of effective procedure or computability independent of choice of Turing machine.

Partially computable functions: functions that can be computed numerically and algorithmically. Church's thesis guarantees the existence of this definition or equivalence of categories.

Laplace's MDL argument: chance of generating x literarily is 2^{-card(x)), chance of computer program generating x is 2^{-K(x)} (also works as definition of Kolmogorov complexity), probability of program comparison to random process is 2^{-K(x) -(-n)}.

Universal lower semicomputable continuous semimeasure complexity (KM): the logarithm of the reciprocal of the universal lower semicomputable continuous semimeasure M.

Universal lower semicomputable continuous semimeasure: the goal of this is to have a measure that gives an a priori probability

Universal: a lower semicomputable function is universal if enumeration exists.

Universal distribution: the idea is to instead of finding some sort of algorithm that maximises ignorance, you pick some sort of distribution that maximises ignorance.

Kolmogorov structure function / ML estimator: the minimal of maximal data-to-model code length log card(S) for model S.

Simplicity of model: Kolmogorov complexity of model K(S)

Exception MDL: minimise sum of description length K(H) and exception list K(E|H), E is error from between data D and data DH from hypothesis classification, compare this to the data processing inequality K(D|H) + K(H) >= K(D)

Max. Entropy: knowledge of constraints gives bounds that maximise entropy.

Maximum likelihood: pick hypothesis maximising probability of data conditioned on hypothesis. Special case of minimum description length

Probably approximately correct learning: the sum of probabilities of cases where concept in binary exemplified concept class is not equal to halted output concept can be made arbitrarily small by an algorithm. This is also the definition of an Occam algorithm. Predictive power of test set.

Pac-learning and compression relationship?

Asymmetric complexity (minimum description length): minimum sum of encoding and encoded data. Random string: zero encoding, compressibility = data.  Or min K(H) + K(D|H)

Symmetric complexity or Wittgenstein ruler: K(D,H) = K(H) + K(D) + K(K(H), D|H) + K(K(D), H|D). Need double dual to work correctly.

c-incompressibility: the Kolmogorov complexity of a c-incompressible string is at least the length of the string minus c character.

c-compressible: the Kolmogorov complexity of a c-compressible string is at most the length of the string -c characters.

Kolmogorov complexity alternate definition: the complexity K such that the string is both K compressible and K incompressible.

Incompressibility lemma: since there are sum from index 0 to log[card(A)]- c -1 programs is 2^(log [card(A)] - c - 1)so there are at least  card(A) 2^(-c-1) c-incompressible

Disjunctive normal forms (“DNF”): OR of ANDs

Concepts: measurable functions in set {0, 1}, concept class, functions on examples giving binary exemplar.

Occam learning: objective, short data representation. Pac learning implies Occam's not the converse (for some concept classes).

Occam algorithm: poly time, where complexity of hypothesis is at most complexity smallest concept ^ payoff exponent * number of examples ^ probability exponent. Pac-learnable if Occam algorithm exists. Number of hypothesis r is such that at most log r of Occam hypothesis complexity.

Landauer bound: 1 bit erases dissipates 10^-12 heat.

Simple Kolmogorov difference: work to transform strings most efficiently.

Instance complexity: minimal length asserting membership of instance. Describes complexity of individual.

Age of string x: minimum of product of random string 2^l(p) by steps t, where universal monotonic machine U on program p U(p) = x. Expected time for constant size probabilistic program to generate string by coin flips.

Levin Kt complexity: log of age. Or, the sum of program length and log of steps taken till x is printed.

Borel-Cantenelli: sum of probabilities Pk of Bernoulli trial Ak converges, only finitely events (with finitely many trials) occur certainly; also for mutually independent Ak, then if sum of probabilities Pk diverges, infinitely Ak certainly.

Logical depth of string x, least steps d for universal monotonic machine U computes x using b-incompressible program p at most d steps and halts.

Example of derivation: consider multivariable polynomial ring, there is a derivation for each nth variable called the partial derivative.

n-ary operation: suppose U is forgetful from commutative R- algebra to set, then it is an operation such that U^n to U. This is quite a whacko thing to define polynomials.

Dual graph: points are faces, faces are points of the graph. Draw points at each face (including outside edge), draw lines passing through each edge

Noetherian ring: condition so you can do induction over ideals. The following are equivalent: (1) the ascending chain condition; (2) every ideal has in the ring has a finite set of generators a_i, so is the set of all R-linear combination of a_i; (3) every submodule of a finitely generated R-module is finitely generated; (4) existence of maximal element for every nonempty collection of ideals; (6) if 0 -> A -> B -> C -> 0 is short exact sequence of modules, B is Noetherian if and only if A and C are.

Noetherian normalisation: (1) field k, finitely generated k algebra (i.e. containing its center), there exists non-negative integer m and a set of algebraically independent elements X_1, ... X_m in A such that A is a finitely generated module over the poly ring k[X_1, ... X_m]; (2) exists a finite injective map from k[X_1, ..., X_m] into R.

Noetherian R-module M: the following are equivalent: (1) submodules satisfy the ascending chain condition; (2) every submodule of module M is finitely generated.

Base change: pullback over morphism of fields

Z[x] is not a PID. Example (x) and (x, 7) are prime ideals, contradiction derived as (x) = (p) since (x,7) = (p) assuming PID

Lie group: group that is also a differentiable manifold. Group multiplication and inverses are differentiable.

Manifold: locally similar to a vector space.

Classification of compact, connected, simply connected Lie group: product of finitely many, compact symplectic group, special unitary group, and spin group, or 5 exceptional groups?

Compact topological group: topology realised as a compact topological space. Like some sort of finite group with discrete topology. Example: unitary group, special unitary group, circle of center 0, radius 1 (symmetries everywhere). All symmetry lines pass through the two elements. Draw STRAIGHT line at center intersecting two points. Defines

Derivative of complex variable: same definition as that of a real variable. Quotient of infinitesimals taken as a limit.

Holomorphic function, and its sheaf: (1) complex differentiable complex variable at each point in complex domain; (2) any point z_0 in domain U of holomorphic function f from domain U to complex C with a neighbourhood V in domain U where f is represented by a convergent power series sum of a_i(z-z_0)^i for i from 0 to infinity for z_0 in C OR removing the z_0 for the case of z_0 being infinitely. A collection of pairs of functions and neighbourhoods (f, V) gives the most concrete definition of a sheaf of holomorphic functions on the Riemann sphere.

Infinitely differentiable locally. Differentiable one, then differentiable twice. These are regular functions!

Analytic function: locally equal to its own Taylor series. General for convergent power series at each point for the domain. Some conflate holomorphic and analytic functions.

Unipotent: element r such that (r-1)^n is nilpotent some integer n. Feels like eigenvalue problem where (A - e I)^n, A linear transformation, then this is just generalised eigenvector.

Unipotent matrix: characteristic polynomial P(t) is power of t-1. Proof of definition: all roots are equal to 1. (t-1)^n = 0. All eigenvalues is one. Eigenvalues are roots.

Quasiunipotent: some power (r-1)^n is Unipotent. Classical example, diagonalisable matrix whose elements are roots of unity.

Principal ideal domain: (1) domain which all ideals are principal; (2) corresponds to the spectrum looking like an affine line; (3) classification of surfaces gives integers as a PID using mapping class groups.

Ideal product: defined using linear combination of two elements in an ideal, not product of ideals, counter example is I = 2Z[x] + xZ[x], J is 3Z[x] + xZ[x].

Product of principal ideals is ideals: proof is it is a linear combination of ideals, so it is an ideal.

Z is a principal ideal domain: key step aq + r = b, but r must be zero since sums of ideals are in ideals. Consider I as ideal of Z, if I is zero ideal this is principal. Supposed nonzero ideal, let l be smallest positive element in I, existence by well ordering of integers, (l) = I, (l) is in I, since lr in I, r is integer, let b in I, use Euclidean so b = aq + r, so must be zero, b = aq, so (a) generates I for any ideal in Z. Surprisingly this means that zero remainder gives equivalence of linear combinations and products to give principal ideals. See proof that product of principal ideals is an ideal.

Principal ideals: ideals generated by one element

Field of fractions: defined like field extension, smallest field in which an integral domain can be embedded. Prototype: field of fractions of integers is rationals.  Example: field of fractions of half line operators yields operators, Dirac delta, differential and integral operator

Localisation of ring: generalisation of field of fractions, but with arbitrary commutative ring.

Subgroup: the following are equivalent: (1) subset with the same group operation closed under the group operation; (2) action of any element of A on the left is equal to A i.e. xA = A for all x in A, left coset of elements in A is A.

Kernel of a group homomorphism: set of elements such that p(g) = e', where g is the group element and e' is the identity element of the other group. This reminds me of the left null space of a linear map. Null space is in the category of matrices, whereas kernels is linear transformation. The classical example is the special linear group, which is the kernel of the determinant map from the general linear group to the reals under the multiplicative group.

Proper subgroup: proper subset, same group operation. Operation is Unital associative invertible magma

Embedding definitions: defined by how it can be embedded in a bigger objects: example, field of fractions of integral domain that can be embedded in a smallest field

Integral domain: nonzero commutative ring, product of two nonzero elements is nonzero (no nilpotents, idempotents are OK). This is a reduced ring, containing no nonzero nilpotent elements.

Linear model: Schrodinger's coloured cat pill test: (1) relationship is linear (regressor, relationship, non-varying in time), (2) error expectation is zero, (3) error has constant variance, no autocorrelation, (4) observations do not affect the experiment (Schrodinger's come in), (5) bad case of number of observations + extra independent variables > number of independent variables assumed. See book by Peter Kennedy on this

Sigma-algebra: motivation is probability, closed under complements, countable unions and intersections. Complements because of not event, closure of countable unions and intersections because of Stone duality, corresponding to probability of countably infinitely many events (ergodicity without killing rate) being decidable in logic. If you take sigma-semiring, this can be used in ergodic analysis in my opinion.

Algebras are closed under finite unions and intersections, need not be closed under countably many, see example take Boolean algebra, infinite negation corresponds to Grandi series, truth is not decidable, then apply Stone duality, corresponds to Grandi series -1 + 1 - 1 + 1 - 1…

Compact: every open cover admits finite sub cover. WARNING: single cover of X is finite, so insufficient for definition. A set that is closed and totally bounded (corresponding to not admitting rotations about infinitely many axes) is compact. Rotations also cause Banach-Tarski paradox. You can weaken to Lindelof with countable subcover or refinement, metacompact with point-finite open refinement, or paracompact with locally finite open refinement.

Hahn decomposition: Measure space X under signed measure can be decomposed into disjoint union of positive and negative sets P and N, up to differences in sets of measure zero. Proof: assume measure v cannot take -infty as a value, otherwise take -v without loss of generality. v(Pj) tends to supremum m, however a measure is continuous from above. Consider countable collections of Pj. By an additional lemma, countable unions of positive sets are positive, therefore P is positive. Take N = X - P. Assume nonnegative for contradiction. Note, if we have non null set E inside N, we can take union of P and E and take its measure and it exceeds supremum. Contradiction. Secondly, for A in N v(A) > 0, if B subset of A then v(B) = v(A) + k, k real number. Now for construction, consider collections of nj such that v(Aj+1) = v(Aj) + 1/nj for lowest integer n1, inductively define. Consider countably many intersections of this Aj collection, gives nj tends to infinity. Yet, the rule still applies due to point number 2, so there exist a n > nj even though nj tends to infinity. Contradiction in constructability. See stack exchange or Folland for full proof I am not sure about the last step.

Jordan decomposition: v = v+ - v-, which says a signed measure can be constructed from two positive measures called the positive and negative variations. Proof: take v+(E) = v(E intersect P) and v-(E) = -v(E intersect N), this is possible by Hahn decomposition. Note that these variations are mutually singular i.e. there exists E, F in M such that E, F disjoint, E union F whole space, v+(E) measure 0, v-(F) measure 0. Prototypical example are the positive and negative real axis with minimum 0.

Caratheodory definition of integral: define outer measure, measure m(S) = m(S intersect A) + m(S intersect Ac) are family of countable sets, forming sigma algebra. Intuition is from Lebesgue measure, outer measure = inner measure.

Radon-Nikodym idea: pick nu, sigma-finite signed measure, mu sigma-finite positive measure, then there exists two unique measure lambda and rho such that lambda and rho are mutually singular, rho << mu (what does this mean?) and nu = sigma + rho. Example, pick mu = Lebesgue measure, pick measure space as real n-dim vector space with open balls, can define point wise derivative if nu.

isProp is the dependent product of the identity types of all pairs of elements in type. We say type A is a (-1)-truncated type or a h-proposition if isProp is an inhibited type, or there is a path between pairs of points for all pairs of points in the space of sections. https://ncatlab.org/nlab/show/mere+proposition there are several provable equivalent ways about thinking.

Higher inductive type on X: A maps to F(A), group operation, unital invertible associative magma with identify and inverses.

Reflexive: space of sections of fibrations on same point. If there exists a proof a, then proof a is the same as proof a.

Symmetric: space of sections of fibrations (a,b) transported over function space to fibrations (b,a). If there exists proof a and proof b being the same, then proof b and proof a are the same.

Transitivity: space of sections of product space of fibrations (a,b) (b/c) can be moved to a(c) via a function space. There exist a predicate with if proof a is the same as proof b, and proof b is the same as proof c, so proof a is the same as proof c.

Intervals: generated by points of type segments and a path of type 0_I = 1_I. Recursion principle looks basically the same.

Circles: is of the type of base S1 and a loop of base =\_S1 base. Note that loop is not the refl_base.

Suspension: point north meridian of type suspension, point right meridian of suspension, and function meridian from the main space in a function space to the space where N = S in the suspension.

Cell complex higher inductive type: points in torus, and points p : b = b, points q: b = b, 2 path where you have p q = q p commutative, this makes it look like some naturality square between vertices a b c d. Identifying this produces a torus

Pushouts: generated by left injection from A to disjoint sum A U B, and right injection from B to disjoint sum A U B, and for each c: C, a glue that glue lefts inverses of functions of points on left injections of c with right injections of c. Left injections and right injection map to disjoint union (colimit inutitively)

W-type: give A in universe U and function type of A to universe U, A are labels, natural numbers as W-type, it will be the type 2 inhibited by 0_2 and 1_2, either it is 0, or it is a successor. So a W type is a generalisation of lists, numbers, binary tree. So 0_2 is the initial element, 1_2 is the induction principle.

N-algebra, type with two elements over the dependent pair c0: C and cs: C -> C, with the type of the dependent sum of product type of C \* (C->C). Example: N-algebra (N, 0, such).

0-type: no inductive generators

1-type: inductively generated by constructor \* of type 1.

Coproduction: generated by left inverse and right inverse, co-product of space, unions,

Surjective: a function is surjective if all fibres of are inhibited, there exists over the codomain space B there must be an induced element over the domain space A such that we have f(a) = b and these two are inhibited.

Connectedness of propositional-types: means that the unique function from a space A to the 1-type space 1 for all dimensions, fibres of maps are contractible. Every function is (-2) connected, up to level of propositions. (-1)-connectedness means surjectivity. This generalised higher level subjectivity. 0-connected is connected, 1-connected is simply connected. This gives the generalisation of connectivity in terms of dimension.

Contractible maps: a map is contractible if it is contractible over all the fibres of a point in the total space.

Left inverse and right inverse: these are the dependent sum over the induced map of spaces B to A such that the g f is homotopy to idA as points for left inverse, g quasi inverse, then f g is homotopy to idB in points for right inverse. A map is bi-invertible if it has a left inverse and a right inverse.

Fiber of a map: this is dependent sum such that fibres over an element x in map f is equal to y where x is of type A, y is of type B. In space, this means the total space where maps of points y are equal to points of map y. It is easy to visualise, just pick two points in space, and then the thing connecting them is the fiber of the map.

Types are object classifiers.

Function types are internal Hom.

Quasiinverse: lemma and proof, quasi inverses are equivalent to dependent types with (x = x). In space, quasi inverses are equivalent to the space of sections where points are equal to points?

Sets are one types where points for points x and y in space A, p, q are of space x = y, and r, s are points of space p = q, therefore r = s in points. Some sort of Poincare duality taking lines as space, and point as points.

Contractible type: logically it means that there exists for all proofs, proofs are identical to the proof being the center of contraction i.e. all proofs are the same. A space is contractible if there is a total space of the space of sections such that all points are equivalent to the point known as the center of contraction.

Retraction is a function space from spaces A to B such that there exists a function space from B to A known as it section, as well as a homotopy such that the compositions of function spaces on points in the space of sections exists.

Unit type is the terminal object.

Dependent pair of P(x): logically it is subset, these are defined as subtype, therefore the total space of fibrations is a

Fiberwise mapping: dependent product from P(x) to Q(x), space of sections from two fibrations,

Dependent pair type of sigma types: a type of pairs where it varies based on the second component without using currying

Recursor for magma: dependent PAIR product (note that the dependent pair product is doing a lot of heavy lifting) A to A to A. Logically, this refers to an associativity principle, where for all propositions, implications of propositions can be taken in any order for a triplet of implications. Spatially, this means that we take the coproduct of three function spaces over the same space, this can be done in any order.

Recursor for pointed magma: Same thing as a recursor of a magma but with a product type at the end.

Induction principle for co-products:

Induction over unit type: (1) skip step 1, (2) construct for function type of unit type to universe, the dependent type of a point C(\*), (3) this is the function type to the dependent type over the unit type

Induction of product types: (1) take dependent type of pairs C(x,y) over elements x in universe X and elements y over universe Y; (2) take dependent type over function types of product type from X _ Y -> U; (3) take a function type to dependent product to the element u of type X _ Y for a proposition C(u). Logically, (1) consider a pair of proofs x and y, there exist a proof x that proves propositions X and proof in propositions Y. Consider this pair of propositions for where the (2) conjunction of these two proofs imply U. (3) It is implied that the pair of proofs can be treated as a proof on its own. In spaces: (1) consider the product space of two points (x,y) formed by the space of sections over their base space X and Y. Then consider the space of sections over the function space of their base space as a product space X \* Y to some other space U; (3) one can form the function space to the product space itself which associate this pair of points to a single point.

Proof for propositional uniqueness principle

Negation: function type into empty type. See section 3.7.1 for traditional logical notation.

Law of the excluded middle: either A or not A is not valid in intuitionism. In intuitionism, either a statement is provable or cannot be provable to be false, or false. Statement p is stronger than not not p. In type theory, this corresponds to the idea that there is no function type from a type to empty type to empty type again. It fails spectacularly in set theory since it implies the De Morgans laws are not valid. In homotopy theory, it corresponds to the statement that there is no function space of the function space of a space.

LEM can be defined as the dependent product of isprop(A) -> (A or not A). It is also the space of sections of the function space of function isprop(A) to disjoint sum of space A and space not A. Logically, the interpretation is easiest, for all statements, if they are propositions then it implies that it must be either true or it is not true but not both.

Type of boolean: coproduct of two one pointed space, set of two singletons, true and false

Boolean recursor: logically this is if then else, in type theory, Pi_C C to C to 2 to C, where 2 is type of booleans, in sets this means there are function spaces from families of the same set (truth and negation) which map to either truth or false which maps to each statement. Topologically there is a space of sections of product spaces of a space as a function space that maps to the two point set for each space.

0-Recursor, Pi_0 C -> C, space of sections over the empty space is a space, any set is a family of functions on the empty set. Logically, any false statement implies any statement.

Coproduct type: defined by type of recursor of coproduct A + B, which is the union of sets, disjunction in logic, and coproduct of spaces.

Recursor of coproducts: known as case analysis. Functions of A to C to functions of B to C are functions of A+B a function of C. Logically, it means that there exists a proposition if A implies C, that implies B implies C, this implies A or B implies C. In sets, there is a family of functions with common codomain can be made into a family of functions with the same codomain using a function. Topologically, space of sections function spaces to the same space can be made into a coproduct with the same function space to the same space.

Recursor through unit type; the recursor from Pi C to 1 to C. Logically, it means there exists for proposition C that is true and implies proposition C. In sets; there exists a set with one element which is the set. Topologically, there is a space of sections whose function spaces maps it to basepoint which has a function space that maps it to the same space of sections.

Nullary type: type in universe with only one object, space with one point, proposition with only one proof, set with one element denoted by empty set, terminal object.

Swap; triple dependent product of elements over the same universe A to B to C such that it becomes B to A to C. In logic, it means that there exists a propositions A implying proposition B implying proposition C such that there is a proposition B implying A which then implies C. In sets, it means there is a family of functions such that family A is a function of family B is a family C with a function making it such that family B is a function of family A which is a function of family C. Topologically, there is a space of sections such that the function spaces of A to B to C has a function space making it function spaces from B to A to C.

Polymorphic functions over universe: functions that take types as arguments and acts on elements of that type.

Cartesian product: type constructed by the recursor of dependent type. Example: generates product space A and B from function spaces of A, B, C.

Recursor of dependent types: function of types from dependent type of functions of types A to B to C, to functions of types A \* B, to C. Logically, it is the recursion principle such that there exists a proposition A implying proposition B implying proposition C, such that implies it is propositions A and B implying C. As sets, it means that there exists a family of families of sets of functions A, B and C, such that the intersection of families A and B gives the set family C. Topologically, it means that there exists a space of sections of function spaces from A to B to C, such that the product space A and B is a function space of C.

Projections of dependent types: type of functions from the product type to one of its components with idempotence as the defining eliminator. In sets, it means there exists a two proofs (a,b) which implies one of proofs is a proof. In sets, it means there is a family of two sets and a family of functions that selects one set out of the two. In homotopy, there is a space of sections on a product space whose function space gives a space that is one of the two spaces.

Product type: left adjoint to type of functions

Eta-expansion: judgemental uniqueness principle

Classical homotopy: continuous totally ordered family of maps graded by intervals such that compositions of maps at the endpoint is idempotent. Need continuity if not you can make everything a homotopy. 

Types: infinity groupoid, terminal object of a global section functor for an (infinity,1) category.

Identity type: path space A^I from interval to space A.

Universe: type whose elements are types. Hierarchy of universes prevent Russell's paradox.

Univalence: isomorphic structures can be identified or there is a canonical equivalence for the function space of id applied to function space of A and B to equiv applied to function space of spaces A and B

Type of naturals: constructed using zero and successor as the induction principle.

Higher inductive types: constructions built using induction principles.

Sets: homotopy equivalent to discrete space where every connected component is contractible.

isomorphisms: Iso(A,B) are dependent pairs of over A -> B and B -> A over dependent types of g(f(x)) = x and f(g(y)). Homotopically, they refer to symmetric total spaces of function spaces with defining equations being space of sections that have judgemental equalities between the composition of functions with their inverses and the identity.

0-types: sets, proofs

1-types: propositions

Types: propositions, sets, space

Proofs: elements, points in space

Predicates, B(x), families of sets, or fibration

0-1, true false, initial and terminal objects

A \* B, disjunction, sets of pairs, product space

A -> B, B^A, implication, sets of functions, function space

Sigma types or dependent sum types, there exists, disjoint sum, total space

Pi types or dependent product type, for all, product, space of sections from total space E to base space Sigma. Cartesian product over types.

Space of sections: internal hom where codomain depends on domain and internalises indexed products. Exponentiation of two natural numbers identified with product of copies of power. Categorify this, you get space of sections. Picking terminal morphisms gets the exponential object.

First order deduction: proposition has a proof.

Propositionally equal: there exists x such that x : a =\_A b. In logic, this means there exists a proof x where proof a is proof b given proposition A. In homotopy, if there is a point x in the space a =\_A b for space A, then there is a path between points a and b in space A. Logically, it means that x is an set in the family of sets where a and b are equal elements.

Definitionally equal: there exists a variable a = b in type A. Logically, it means there exists a proof or axiom of a = b in proposition A. In sets, it means that the elements a and b are the same in set A. Topologically, it means there exists a path from a to b in space A. Compare this to propositional equality geometrically, where the space a =\_A b has paths as points.

Function type, f has a type A -> B. Logically, f is a proof that A implies B. In sets, f is in the set of functions from A to B or the exponential set B^A. In homotopy, point f is in the function space A -> B.

Hypothesis: element x has type A. Logically, x is a proof of A as a statement is a hypothesis. Set theory wise, element x is in the set A. In homotopy, point x is in space A.

Lambda-abstraction: of the form lambda (element: type)-expression. Logically, it refers to the expression that shows that x is a proof of a proposition A. Sets, it means at an expression such that an element is a member of that sets. Topologically, it means that this expression defines points to be some space.

Element to expression is of functional type. Logically, it means a proof implying an expression is an implication of propositions. Set wise, it means an element with an expression is a family of functions. Topologically it means that a function space can be defined by points to expressions as points.

Currying: apply function to a, then apply function of a to b, then get the result. Logically, it means proof an implies fa, then proving proposition fa implies b, then b is a result. Set theoretically, it means element a is in the set of functions fa, which is in the set of functions b. Topologically, it means from point a, there is a path to fa, which then there is a path to b, so there is a path from a to b.

Inductive principle for the type of functions: this means that an expression is canonically isomorphic to the lambda (element: type)-expression. Logically, it means an expression is the same thing as applying an expression of a proof with some proposition. Sets, it means a set defined by its properties is equivalent to the property itself. Topologically, it means that an expression as a space is the same as an expression defining some points on some space to be a space.

Formation rules: rules that form types:

Eliminator rules: rules that apply expressions.

Characteristic equation: take the determinant map (lambda I - A) x = 0, there is some sort of group theory since the characteristic equation is equal to the power series with alternating signs of principle minor sums, or t^n - (tr A) t^{n-1} … (-1)^A (det A).

Sum of roots and product of roots as trace and determinant. For a 2x2 matrix, trace and determinant has something to do with sum of roots, product of roots; We have x^2 - tx + d, -t is trace, d is determinant.

Trace of matrix: sum of main diagonal entries, sum of eigenvalues (counted with their multiplicities), basis free. Used to define the character of a representation.

Example of eigenvalues of Foruier transform on L^2 Hilbert space: composing 4 times Fourier transform gives identity map up to normalisation, eigenvalues are {-1, 1, -i, i}

Trace of product of matrix and conjugate transpose: sum of square of diagonal entries.

Multiplication of matrices by left: in matrix AB, left multiplication by A multiplies columns of B, right multiplication of B multiplies rows of A.

Determinant: test for invertibility if determinant is nonzero it is invertible so used to define the general linear group, volume of box in n-dimensional space, used to define special linear group of unit volume. Determinant is product of pivots / eigenvalues.

Diagonalisation failure: if we have repeated eigenvalues, these are like singularities or nilpotents. That is the only iconnection between diagonalisability with independent eigenvectors and invertibility with nonzero eigenvalues. Zero is like an absorbing element.

Matrix exponential: it is some series with the properties you want from an exponential. We have exp(At) = I + At + (At)^2/2 + ... (At)^k / k! up to infinity. Invertible, consider exp(-At). Never singular, exp(e t) is always nonzero, e is eigenvalue. So there are nonzero eigenvalues. Also determinant of exp(At) is equal to exp(trace(At)). Gives exponential map between matrix lie algebra to its lie group.

Exponential of a matrix is always invertible: proof, there is a valid notion of exp(-X).

Laplace transform of matrix exponentials: strangely this gives the resolvent example integral from 0 to infinity of exp(-ts) exp(tX) dt = (sI - X)^{-1}, s is pole/zero.

Stability: matrix exponential tends towards zero, real part of eigenvalues are less than 0, neutrally stable when real part of eigenvalues equalto zero. This is called asymptotic stability.

Determinant of matrix exponential: det(exp(A)) = exp(tr(A)), interesting, this is because additive group is changed from the multiplicative group. See the fact that the determinant map's kernel is the special lienar group.

Jacobian determinant: stretching matrix of the volume.

Normal matrices: commutes with conjugate transpose.

Similarity: B is similar to A if there exists nonsingular S such that B = S^-1 A S. Another definition of similar is if they have the same Frobenius normal form (canonical form by conjugation of invertible matrices over F) which is the same as the definition above.

Diagonalisable: if similar to diagonal matrix, then diagonalisable.

Matrices AB commute if they are simultaneously diagonal or similar to same diagonal matrix. Proof: use similarity transform, forms abelian subgroup. Same group action on group conjugate, also abelian.

Eigenvalue equation: Ax = lambda x. Converts matrices into polynomial ring.

Unitary matrices are nonsingular, its conjugate inverse is unitary. Rows and columns are orthonormal, same Euclidean norm. Proof, all follows under closure of unitary group, and also the fact that the product of unitary matrices is 1.

Selection principle, closed bounded subset of finite dimensional vector space is compact (note that unitary matrices have a spectrum closed in complex unit disk). Group of unitary disk is compact, so there must exist a limit of subsequence. Need not be unique! Similar to {-1}^n odd and even alternating matrices as counterexample!

Unitary similarity is equivalence relation: proof is easy, identity matrix, inverses and composition of inverses exist in the group of unitary matrices, so can form equivalence relation if you use these as products.

Schur form: proof: start with orthonormal basis matrices A = [Z1 Z2] \* A [Z1 Z2] which gives [lambda I, A12, 0, A22]. The lambda I, 0 is due to the properties of the orthonormal basis matrices being unitary, don’t care about A12, but A22 is not upper triangular! Iterate. Finite dim vector space have integer dimension n, iteration at most n steps, therefore any square matrix in complex numbers is unitary similar to upper triangular matrix.

Unitary matrix: is a matrix whose inverse is equal to its conjugate transpose. The product of a matrix with its inverse gives the identity matrix. 

Conjugate transpose of a matrix: swaps the rows and columns and computes its complex conjugate component wise. It is quite special, so people call it adjoint or Hermitian adjoint, however these are superseded in modern algebra.

A square complex matrix A in the set of n by n matrices M_n of complex entries have eigenvalues \lambda_1, ... \lambda_n in any order. Let x in the complex n-space C^n be a unit vector such that Ax = \lambda_1 x.

There is a unitary U =  [x u_2 ... u_n] in the set of n by n matrices M_n such that U^* A U = T = [t_{ij}] is upper triangular with diagonal entries t_ii = \lambda_i from i = 1, ..., n. This is the Schur form.

The upper triangular matrix T has the diagonal entries as the eigenvalues of A, the sum of these eigenvalues as the trace of A, the product of these eigenvalues as the determinant of A, and the main diagonal entries of adj T to be the product of all eigenvalues excluding the one corresponding to the entry in the diagonal.

The Cayley-Hamilton theorem follows by factorising the characteristic polynomial and representing the matrix A by the conjugacy UTU^*. The characteristic equation of A is that of the conjugacy which is Up_A(T)U^* = U([T - \lambda_1 I][T - \lambda_2 I]...[T - \lambda_n I])U^*. One can check that p_A(T) in this form must be zero (NOT TRIVIAL, see Horn and Johnson, pp. 110).

A square complex matrix A in the set of n by n matrices M_n of complex entries have scalars \lambda_1, ... \lambda_n in the complex plane C, positive integers q and n_1, ..., n_q such that the sum n_1 + ... + n_q = n such that A = S J_A S^{-1} where the Jordan matrix J_A is the direct sum of Jordan blocks J_{n_i}(\lambda_i), where J_A = \bigoplus^{q}_{i = 1} J_{n_i}(\lambda_i).

Jordan block: (1) is an upper triangular matrix where the the scalar \lambda_i appears n_i times on the main diagonal, if n_1 > 1 then there are k - 1 entries which are +1 in the superdiagonal, and all other entries are zero; (2) sum of a diagonal matrix and a nilpotent matrix since J_k(\lambda) = \lambda I_k + J_k(0) and J_k(0)^k = 0.

Number of Jordan blocks: the maximum number of linearly independent eigenvalues of J_A.

If all the Jordan blocks are 1 by 1, then J_A is diagonalisable, in fact, the diagonal matrix looks like this.

Multiplicity and Jordan block: number of Jordan blocks corresponding to a given eigenvalue is the geometric multiplicity of the eigenvalue, which is the dimension of the associated eigenspace.

Algebraic multiplicity of Jordan block: sum of the sizes of all the Jordan blocks corresponding to a given eigenvalue is its algebraic multiplicity.

Category theory motivates (1) generalising morphisms; (2) generalising domain/codomain duality; (3) preserve integrity respecting identification and compositional order. The fastest illustration of category theory is with Kan extensions. All categories are locally small (that is to say ignore size issues in set theory) unless otherwise stated.

A category C have domain and codomain objects ob(C) and morphisms mor(C) that respect the identity 1_C and associative composition.

A morphism is between categories is a functor F maps morphisms f from a category C to a category FC respecting composition F(f *_{F} c) -> F(f) *_{FC} F(c) and identification in both categories. One can also use the family of homs definition, used in May or Lurie.

A 2-morphism of functors is natural transformation \eta that has components \alpha_c that takes morphism c composed by a functor F to a functor G such that there is a commutative diagram between the morphism Fc and its common composite Gc' for any morphism f that takes c to c' (Gf * \alpha_c = \alpha_{c'} * Ff).

An isomorphism is a composition of two morphisms between two sets of objects whose composition and inverse identify in their respective sets of objects. Objects are isomorphic if an isomorphism between two exist between them. Objects can be grouped into a class of objects of a category if they are isomorphic. Picking the same object for the domain and codomain gives an automorphism if the morphism is isomorphism, otherwise it is endomorphisms.

A comma category F \downarrow G of two functors F: D -> C and G: E -> C has objects, triples (d, e, f), where d is a morphism in category D, e is a morphism in category E, and f which are morphisms from Fd -> Ge in category C, as well as all diagrams of this shape commuting in category C, where h: d -> d', k: e -> e' such that f' * Fh = Gk * f, for morphisms of triples (d, e, f) -> (d', e' ,f').

A left Kan extension of a functor F that takes morphisms from initial domain category C to a codomain category E along a functor K that maps morphisms from extended domain D to the same codomain category E is a functor Lan_K F that also takes morphisms from category D to category E such that there is a natural transformation \eta that takes functor F to the functorial composition of Lan_K F * K. This natural transformation \eta is defined such that any other natural transformation \gamma factors uniquely through \eta for any other functor K' that, like K, takes morphisms from category D to category E.

A right Kan extension is defined the same but the arrows of the natural transformation reversed, taking the functorial composition of Ran_K F * K to functor F from the opposite category C^op to opposite category E^op when defined in terms of the left Kan extension.

A functor is extended naturally to left composition of a left Kan extension and the functor when the domain category is extended.

A functor is extended naturally from a left composition of a right Kan extension and the functor when the domain category is extended. Easy to remember, forgetful functors are typical examples of right adjoints which are right Kan extensions.

Sections and presheaves: by definition global sections must exist when defining presheaves. Recall that sections are maps f such that f_s * s = id_B for s as a map from B to A. This is like the reverse of a retraction. A section is something that makes any map a retraction (think idempotence).

Retractions vs sections: let f be a map from A to B, a retraction r from B to A, makes any map f into a identifying idempotent button i.e. r * f = 1_A. A section s from B to A is such that any map f is now a button i.e. f * s = 1_B.

Retractions and sections are left inverses and right inverses: uniqueness of inverse means if retraction and section exist, then it is unique. A map is an isomorphism if retractions and sections exist.

Presheaf: TFAE: (1) is a functor from an opposite category to sets. Use poset of opens in topological space, partial order given by inclusion, to get back presheaf. A simplicial set is presheaf from the simplicial category; (2) define using X = Spec A on the basis of principal opens using M(D(f)) = M[f^{-1}] for f in ring A, M being A-module; (3) classica with presheaf of topological space, exists global sections s in F(Y/X)(U) such that f * s identifies on open U (this condition turns any point into a morphism), and for inclusion of opens, restrictions exist such that order of restriction does not matter given chain of inclusions (these are similar to definition of a category, to give it functoriality).

Presheaf as choice problem: regardless of what we choose for f * s = 1_B, sections exist and there is a solution of the choice problem. Definition of a presheaf is such that it guarantees that such a morphism f exists, it gives the minimal condition for morphisms (instead of points, recall we are using a functorial point of view) to exist. This motivates the classical definition of presheaves as something that asserts global sections of opens exist. You want the definition of a presheaf to be such that morphisms exist, and nontrivially the key step to do this is to ensure sections of presheaf over opens exist. As for inclusion stufff, this is required to give some consistency of properties (cannot be such that restrictions screw up) since classicaly these are done on topological spaces.

Gluing modules: A-modules are equivalent to quasi-coherent sheafs on Spec A which are equivalent to quasi-coherent sheaves on distinguished opens D(f_i) + gluing data. See Scholze corollary 11.10.

A category of presheaves has presheaf functors as objects, and natural transformations as morphisms.

Most Kan extensions define the value of an extended functor on each object (each “point”) by a weighted (co)limit. For a locally small category E, a right Kan extension is pointwise if it is preserved by all representable functors E(e, -) to the category of sets Set. Representable functors are naturally isomorphic with a representation \theta: hom_C(-,c) -> E(e, -). A left Kan extension is pointwise if its corresponding right Kan extension is pointwise. 

https://mathoverflow.net/questions/33188/a-slick-definition-of-the-kan-extension

Also, a right Kan extension of functor F from category C to category E along a functor K from category C to D is pointwise if and only if the limit lim ( d \downarrow K -> C -> E) exists and is isomorphic Ran_K F(d) for morphism d in category C. We have d \downarrow K as an indexing category. This can be shown since a pointwise extension preserves representable functors, so Yoneda's lemma applies then the Ran_K F(d) is isomorphic limit of Fpi_d: d \downarrow K -> E where a l pi_d. Dually, a left Kan extension of functor F from category C to category E along a functor K from category C to D is pointwise if and only if the colimit colim ( K \downarrow d -> C -> E ) exists and is isomorphic Lan_K F(d) for morphism d in category C.

See Emily Riehl's "Category Theory in Context" for this construction. For any small diagram F from category C to category D valued in a category with products and equalisers. There exists an equaliser diagram for monomorphisms on Fc to the product pi_{c -> x} Fx for two parallel maps to pi_{c -> x -> y} Fy. One parallel map projects to the component indexed by the composite c -> x -> y. The other parallel map projects to the component indexed by the map c -> x and then acts by F on the second map x -> y. This is the Yoneda lemma, applied to functor F from the category C to the category of sets Set for set morphisms Fc which is isomorphic to a limit formula \lim(c/C -> C -> D). This limit formula can be shown to be expressed as an equaliser. The Yoneda lemma states that these two composites are equivalent.

Yoneda's lemma implies a composition of two morphisms between two sets of objects whose composition and inverse identify in their respective sets of objects called a isomorphism. This isomorphism is canonical and unique, and is between the value of a presheaf X at a morphism c and the collection of all morphisms (hom-set) of presheaf homomorphisms from the representable presheaf y(c) to the presheaf X. This means Hom_{Set^{C^op}}(y(c), X) is isomorphic to X(c).

A left Kan extension of a functor F that takes morphisms from category C to category D along a uniqueness functor ! from a category C to the category 1 defines a natural transformation to the colimit. This left Kan extension exists if and only if the colimit exists. A right Kan extension along a uniqueness functor ! from a category C to the category 1 defines a natural transformation from the limit. This right Kan extension exists if and only if the limit exists.

A unit \eta is a natural transformation from the identity functor * to a composition of functors GF. A left Kan extension of the identity functor * along F is defined with the unit \eta as an left adjoint. Left adjoints preserves colimits. A counit \epsilon is a natural transformation from a composition of a functors GF to the identity functor *. A right Kan extension of the identity functor along G is defined with the counit \epsilon as an right adjoint. Right adjoints preserves limits.

Yoneda extension: left Kan extension along a Yoneda embedding. See definition of field extension in Galois theory, similar.

Diagonal functor intuition: categorification of the diagonal function, diag() from C to C * C, C category is given by diag(x) = (x, x), regardless of whether x is object or arrow, generally, we can have diag()_I from C to C^I, where C^I is indexing, sending each object c to constant functor diag(c).

Diagonal morphism intuition: canonical morphism of the diagonal function, diag() from C to C * C, C MORPHISM is given by diag(x) = (x, x), regardless of whether x is object or arrow, generally, we can have diag()_I from C to C^I, where C^I is indexing, sending each object c to constant functor diag(c), dually it is codiagonal. These properties are induced by universal property of Cartesian product / direct sums.

Diagonal function: diag(a)_I maps a to (a, a), I indexing set 

Adjunction of diagonal functor: diagonal functor is a functor from C to Funct(I, C), projective limit is right adjoint, inductive limit is left adjoint.

Limit as a Kan extension using diagonal functors: the following are equivalent: (1) hom sets in category C from functor Y to the projective limit of functor F is equal to the hom sets in the category of functors from indexing category J to the category C, with homs from the diagonal functor on Y to the functor F i.e. Hom_C(Y, projlim F) = Hom_{Funct(I, C)}(Diag Y, F).

Limit of a diagram with two objects without nontrivial morphisms is a product.

A limit of a unique empty diagram from the empty category 0 to a category C defines a terminal object of C. This can be thought of as a product. 

A limit of a pair of parallel morphisms is an equaliser. A limit over a cospan is a pullback, considering pairs of morphisms with the same co-domain. Dually, there are coproducts, initial objects, coequalisers, and pushouts for parallel pairs of morphisms with the same domain.

Monoidal structure: a unital associative magma, except the magma is a tensor product BIFUNCTOR of categories. Unital and associativity come as FUNCTORS of categories.

Box topology: generated by the base of Cartesian product of opens for opens in topology. Box comes from basis sets that look like boxes. Standard counterexample to how products do not preserve continuity unless one uses the product topology.

Product topology: box topology but all but finitely many opens in components are equal to the full component space. The product of continuous functions (morphisms) are continuous iff the components of the product are continuous.

Affine combination versus convex combination: affine combination allows negative coefficients, line between them and is compact. Convex combination of a finite set is compact.

Measurement of random variable: defined when the exponential is taken out of an expectation value, you replace the random variable with the measured value. This is deterministic.

Mapping space of CW complex has type of CW complex: need domain compactness, example mapping from universal infinite discrete space to discrete space.

Germ: the following are equivalent: (1, categorical) for open U and functor f, take image from i(U) from sheaves of opens on top space X OU(X) to cocone C, then G(u,f) is i(U)(f); (2, Gelfand/Manin) germ s_y of a section of presheaf F at the point y is than equivalence class of pairs (s, V), consisting of open neighbourhoods V of y and s in holomoprhic functions (V, F) given by the equivalence relation (s, V) equivalent to (s' V') means there exists open W in the intersection of V and V', and uniqueness of germ as universal property r_{V, W}(s) = r_{V', W}(s'); (3, Scholze) germ of s at x: let s_x be equivalence class of opens (U, s) at stalk of sheaf F at x.

Perfect duality, equivalence of categories from opposite category C to D consisting of dual concrete structures

Heisenberg group: non abelian, every element cubed is 1

Adjunction and exactness: let C and D be abelian categories, F be functor from C to D, G be functor from D to C, additive functor given isomorphism of bifunctors: Hom_D(FX, Y) = Hom_C(X, GY), F is left adjoint to G, G is right adjoint of F, then F is right exact and G is left exact (see Gelfand and Manin)

Exactness lemma: if 0 to A to B to C to 0, if any two are exact then the third must be exact. Proof is to take long exact sequence of homology groups. Then, eventually most of them will vanish, show injection and surjection.

Eisenstein criterion, for polynomial, if there exists a prime does not divide the nth power coefficient yet it divides the rest, and prime square does not divide the zeroth term, then the polynomial is irreducible. Example: x^2 + 2, pick 2 as the prime not dividing 1, power of x^2, 0, and 4 but it divides the other term 2.

Uses of pseudometric: you have two points with 0 distance that aren’t the same. To ignore it, quotient out by identification with distance.

Duality: pairs of concepts are mirror images of one another with some involution like two points define a line and the intersection of two lines is a point up to taking projections.

Derived functors: explicit computations of homology for Tor, and cohomology for Ext via resolutions.

Character as element fixed by s: S be finite set in which finite group G acts on, X_S be character of permutation representation p, let g be in G, show that X_S(g) is number of elements of X fixed by g, g is group action on s, g * s = s. X_S(g) is by definition the trace of permutation representation, and the permutation representation has diagonal 1 if it is a group action g fixing s in S, so the sum of these eigenvalues = 1 must be the number of elements in set X fixed by g.

Burnside's lemma: enumeration of orbits of symmetry group, or counts distinct objects up to a symmetry equivalence relation. For a finite group G, consider elements x^g that are fixed by g i.e. g * x = x. The formula for orbits is |X/G| = sum of elements x fixed by g divided by the group G. Example, rotationally distinct colourings of cube with three colouring. Identity fixes 3^6 colours, six 90 degree face rotations fix 3^3 \* 6 colourings, three 180 degree face rotations fix 3^3 colourings, eight 120 degree vertex rotation fix 3^2 colourings, six 180 degree edge rotations fix 3^3 colourings. Now take average over group of order 64, get 57, so there are 57 rotationally distinct colourings of a cube with 3 colours.

Fourier transforms in distribution theory: turn multiplication by x into differentiation with respect to k, derivatives of delta function.

Jaffard domain: Krull dimension of the ring of polynomials, is the Krull dimension of the ring + number of parameters of the polynomial ring. Example dim R[T1 … Tn] = dim R + n.

Lie group and Lie algebra correspondence: isomorphic Lie algebra does not imply isomorphic Lie group (example real coordinate space, and circle group). However, requires simple connectedness. Problem is there is a hole in circle group.

Averaging over finite group: integral over G of f(t) for f element of vector space with respect to measure dt.

Haar measure desired properties: (1) integral over finite group G of f(t) for f element of vector space with respect to measure dt is equal to integral over G of f(ts) for f element of vector space with respect to Haar measure dt for t and s in the finite group G; (1') integral over finite group G of f(t) for f element of vector space with respect to Haar measure dt is equal to integral over G of f(st) for f element of vector space with respect to measure dt for t and s in the finite group G, i.e. invariant under left translation; (2) integral over finite group G with respect to Haar measure dt is equal to 1 or total mass of Haar measure is equal to 1; 

Example of Haar measure for finite group of order g: assign each element t in finite group G a mass equal to 1/g.

Example of Haar measure on C_infty rotations in plane: assign mass of 1/2 pi for elements t in G of the form t = exp(i alpha), taken modulo 2 pi, this ensures that the total mass of the Haar measure is 1.

Inner product of two functions in the context of finite groups in a Hilbert space: integral over finite group G for two functions f, g to be integral over G f(t) * g(t)^* dt, where there is a good notion of conjugate transpose.

Schur's lemma proof that each irreducible representation of an abelian group is degree 1: consider p^i from group G (need not be finite) to general linear group GL(V_i), at least one V_i irreducible by hypothesis, then by Schur's p_i * f = f * p_{i-1} is such that f is homothety and equivalent to eigenvalue p_i * l = l * p_{i-1}, by commutativity we see that these maps are l * p_i = l * p_{i-1}, but the p_i in question is degree 1, so any irreducible representation is of degree 1.

Homothety: scalar multiple of the iddentity map.

Schur's lemma (Serre's): let p^1 be a linear representation from the finite group G to the general linear group on vector space V_1, GL(V_1), p^2 be a linear representation from the finite group G to the general linear group on vector space V_2, GL(V_2), let f be a linear mapping of V_1 such that p_s^2 * f = f * p_s^1 i.e. f is the linear map that makes these two linear representations adjoint. Schur's lemma states that if p^1 and p^2 are not isomorphic, then f = 0 i.e. this adjunction does not exist, if V_1 = V_2 and p^1 = p^2, then f is a homothety (scalar multiple of the identity).

Schur's lemma (proof by Serre for isomorphism): suppose f nonzero, KEY STEP: let W_1 be kernel (set such that fx = 0), let * be linear map composition, by hypothesis p_s^2 * fx = fx * p_s^1 = 0 because W_1 is the kernel;, KEY RESULT: W_1 is stable under G. Using V_1 irreducible, W_1 is either V_1 or 0, so W_1 is 0 since if W_1 = V_1 then f = 0. Recycle argument for W_2, so W_2 = V_2. But W_1 = 0, W_2 is V_2, this means f is isomorphism from V_1 onto V_2. 

Schur's lemma (proof by Serre for homothety): suppose V_1 = V_2, p^1 = p^2 without loss of generality, let l be eigenvalue of f, there is at least 1, field of scalars is field of complex numbers using fundamental theorem of arithmetic (this means we need algebraically closed field). Since l is eigenvalue of f, (KEY STEP) kernel of f' = f - l is nonzero. NOTE: p_s^2 * f' = f' * p_s^1 . Either f' = 0 by part 1, or f' = l i.e. f' is homothety.

Schur's lemma: all ground field, irreducible representations are unique up to homomorphism, if ground field is algebraically closed endomorphisms are scalar multiples of identity operator. Endomorphism of irreducible representation, multiply by complex number? This property is also known as complete reducibility or semisimplicity. Note: over finite fields, not completely irreducible, so modular representations is very tricky.

Schur's lemma (endomorphism ring): if a module is simple, then its endomorphism ring is a division ring.

Converse to Schur's fails with endomorphism ring definition: Z-module Q is not simple, endomorphism ring is isomorphic to Q.

Endomorphism ring examples: End(Z) gives Z, End(Q) gives Q, End(C_n) gives Z/n, End(Z^n) gives M_n(Z), End(Q^+/Z) = profinite completion of Z. So we have endomoprhism of cyclic group related to some Z/n, Cartesian product becomes matrix ring. This feels like representatives and categorical in flavour.

Schur's lemma slogan: irreducible representation of group, if matrix "commutes" with all group members, it is basically the identity up to differing eigenvalues.

Schur's lemma (in Fulton/Harris, see contrast with Serre's proof which I understand a lot better but this is a lot slicker): consider V and W irreducible representations of G, and p: V -> W is a G-module homomorphism, then either p is an isomorphism, or p = 0, and if V = W then p = e I for some complex e, and I is identity matrix. First claim, the kernel and image of the map are invariant subspaces, so p is an isomorphisms or is some vanishing map. For the second claim, since the complex numbers is algebraically closed, p as a FINITE DIMENSIONAL linear map must have an eigenvalue, so (p - eI) has nonzero kernel. By (1), (p - eI) = 0, so p = eI. Note we did use the hypothesis that V and W are finite dimensional vector spaces. Essentially, Schur's lemma states that linear transformations are represented by matrices if you restrict it to the case of the trivial group i.e. linear algebra.

Representations: group preserving map (group homomorphism) from the group to the general linear group of vector space V which is GL(V) which is the group of automorphisms (all invertible matrices) for vector space V. The representation gives the vector space the structure of a G-module for a group G (module is like vector space for rings). 

Degree of a representation: the dimension of the vector space (finite for finite simple groups)

Lp space: space using a power p as norm instead of typical Euclidean using p = 2. Triangle inequality fails for p < 1, so you need quasi triangle inequality so we have |f + g| <= C(|f| + |g|) for Lp norm, non-degenerate (zero defined) and homogeneity (constants factor out, constants in field K).

Hom Tensor adjunction on vector space: Hom(V,W) is canonically isomorphic to V * tensor W.

Duality of vector space: a vector space of rulers (sort of) of a vector space. It is not canonical, one can pick an arbitrary scale.

Periodicity of functions: reducible to linear combinations of exp(2 pi it)

Quotients: f(x) = f(y) if x is equivalent to y. That is why quotients are very powerful. They are almost functions. Even better, they form equivalence classes. Even even better, you can find unique representative elements for these quotients using the axiom of choice, which you can weaken to dependent or countable if you wish.

Linearising is the easiest thing in math (example, representation theory). Next best thing is to count (combinatorics).

Connectedness is not hereditary, example Q does not inherit connectedness from R or even path connectedness.

Free group as universal property (universal left adjoint): there is a canonical free group, with any function from set S to the group G giving a unique isomorphism with set S included to the alphabet Fs mapping to the group G. If non unique, relations exist.

Maximal subgroup: proper subgroup that is not contained in any other proper subgroup. Note this implies that there can be nonunique maximal proper subgroups.

Proper subgroup: subgroup that is a proper subset of the group (particularly, excludes the group itself as a proper subgroup of a group)

Construction of Non-Noetherian rings for each finite dimension: start with a Noetherian ring, adjoin infinite number of nilpotents. Or take affine line, adjoin infinite number of fat points somewhere, the corresponding ring is not Noetherian even though it is dim 1.

Gros topos: sheaf is a generalised space with descent

Cuspoidal cubic: y^2 - x^3

Proof that every vector space has a norm: every vector space has a finite linear combination of basis vectors (even if it has infinite dimensions, this uses some weird completion magic). Take max of the coefficients amongst finitely many basis vectors, this defines one possible norm. Infinite dimensional TOPOLOGICAL vector spaces don’t have a norm that indices the topology

Exponential functions: quintessential examples of holomorphic functions. Entropy (logarithms) turn products into addition. Exponentials is even better, if you differentiate it, integrate it or transform it with linear combinations, it is still a multiple of an exponential.

Unital subring: some authors define the identity to be in subring. Note that analysts don’t like forcing an identity at all.

Injective: covariant pullback, if f(x) = f(y) then x = y.

Well defined function: "covariant pushforward", if x = y, then f(x) = f(y)

Sobolev embedding (Tao's intuition): amplitude A, frequency N, support on volume V. Wk,p norm is AN^kV^-p, Apply uncertainty principle, V >= N^-d. Think of it as a trade off between regularity and intergrability. These are single bump function spaces, can extend a lot further. W11(R)  =  L^infty(R1) is fundamental theorem of calculus Wd1(R)  =  L^infty(Rd) is iterated and Fubini applies.

Sobolev embedding motivation: smoothness of solutions in differential equations if you do it in Soboleev spaces (and compactness so that you have nice existence theorems).

Sobolev space intuition: Banach space of measurable functions such that generalsied partial derivatives (generalised functions) or in L_p(Omega); vector space of functions with norms that is combination of L^p norms. Try 1d case.

Regularity in the context of partial differentialequations: smooth enough to be qualified as classical solution. Example: weak solution that is not smooth would be shock waves.

Using calculus to get rid of bad fractions: newton numerators of form [f(t+h) - f(t)]/h is simply the integral

Utilities problem: F - E + V =  2. Consider 2 houses to 3 utilities fully done. Need to connect one house to all three utilities. Can make at most only one face on the plane. So max faces is 3. You have 9 edges, 6 vertices, this is a max of 0 which is less than 2. Therefore, fails in plane.

Trisection angle: impossible, proof, compass and straight edge constructions obey tower law, quadratics only. Consider cos(60 degree), which is rational valued, and expressed irreducible, cubic polynomial. cos(20) therefore cannot be constructed by tower law. But 60 degrees can be constructed. So it is impossible to trisect 60 degrees.

Smooth fibrations on compact spaces are fiber bundles, example Hopf fibration not Hopf fiber bundle.

Elliptical curve over complex numbers is a Riemann surface of genus one with base point, or quotient of complex of lattice In complex, or smooth algebraic curve degree 3. Torus can be used to study complex numbers.

To get the properties of exclusive disjunction from ring sum and conjunction (or meet) from ring product given a Boolean ring, which is a ring of idempotents, apply truth table onto rings of ints modulo 2. 1 + 1 = 0, so exclusive disjunction.

Join: is union both are less than supremum in lattice. Join is supremum.

Meet: intersection is infimum, both are at least that in lattice.

Hasse diagram: diagram representing partially ordered set.

Plus construction (see Scholze lecture): A+ is the Lan(r^op) Ran(s^op) A. Step 1, apply right point wise Kan extension along the opposite of functor s^op : C -> J sending opens U on small site C to maximal sieve (set of all morphisms with codomain U). Step 2: apply left pointwise Kan extension r: J -> C as Grothendieck construction of functor Cov: C^op to Pos or category of partially ordered sets. sending opens U to set of covering sieves.

Global section functor on an (infty, 1) topos is a Hom functor of morphisms out of the terminal object H(\*, -) from infinity stack sheaf of C to infinity stack sheaf of a terminal object which is an infinity groupoid. The infinity groupoid is the terminal object.

Global section functor: direct image functor on Grothendieck topos, induced by canonically mapping spaces to terminal objects. It is right adjoint to the left adjoint which is the Set tensor on the terminal object sending set to coproduct of card(S) copies of terminal object which is the constant object. The left adjoint is the constant sheaf. It is constant since we lost all information by using the terminal object. Generalisation of the forgetful functor.

Etale space: sheafs on the site of opens for topological space is the sheaf of local sections on its etale space E (double cover as example) bundle such that the sheaf functor takes opens U to sheaf of local sections Gamma*U(E). The sheaf of global sections is the hom-sets on the sheaf from the terminal object to the sheaf functor. Sheaf of global function = Hom_Sh(X)(*, A), A is sheaf functor, terminal object, Sh(X) is sheaf category.

Motivation for slice category as bundle: Top be category of topological space, Top/B be slice category, category of topological space over object B in Top (these are the bundles of B!)

Slice category: objects are morphism, morphisms are commuting triangles to colimits X.

Coslice category: objects are morphisms, morphisms are commuting triangles from limit X.

Canonical forgetful functor from slice and coslice category: forget C_X/ and C^X/ to C, forgetting the morphisms X.

Category of pointed objects: objects are morphisms from basepoint to x, morphisms are commuting triangles from limit *, morphisms preserve chosen points.

Sections are right inverses. Sections B -> A are right inverses of bundles A -> B which are left inverses of sections. Sections typically refer to global sections, not local sections by default. In homotopy type theory, helpful for defining left injections and right injections.

Derived functors: normal functors that are presented in a category of weak equivalences (homotopy suitable setting).

Dehn twist: cut cylinder with line, glue back circle with rotation. Line becomes twisted at cut. These are the simplest infinite order elements of the mapping class group. These are "natural". There is a fundamental theorem, SL(n, Z) is generated by elementary matrices, then Mod(S_g) is generated by finitely many Dehn twists.

Mapping class group of S_g is generate by finitely many Dehn twists: prove using induction on genus, Birman exact sequence for induction on genus. Connected when g >= 2. Simplicial complex C(S_g) encodes intersecton patterns of simple closed curves.

Mapping class group of torus is isomorphic to special linear group SL(2, Z): you can prove tons of properties of of SL(2, Z) by now using the torus. This is one of the highlights of the book.

Mapping class group Mod(S_g) and S_g bundles: not surprising, since representations are related to so called locally constant sheaves / bundles, we have the following bijection. Conjugacy classes (classes form under equivalence relation of conjugation) of representations from the fundamental group / Poincare group Pi_1(B) to mapping class group Mod(S_g) bijectively corresponds to isomorphism classes of oriented S_g bundles over B.

Sympletic representation of mapping class group: a representation Mod(S_g) to Sp(2g, Z) which is the integral symplectic group. This is a "linear approximation" of the mapping class group. Serre used this representation to prove that Mod(S_g) has a torsion free subgroup of finite index.

Mapping class group of torus: is special linear group of 2 x 2 matrices, Teichmuller space is the upper half plane. Horizontal Dehn twist, take shearing matrix A = (1 1, 0 1) giving (x+y, y) on (x, y). Vertical Dehn twist, take shearing matrix B = (0 1, 1 1) giving (x, x+y) on (x, y). See what you have learned about mobius transformations.

Mapping class group: group of orientation preserving homeomorphisms of oriented topological manifold, group of automorphic homeomorphisms onto itself modulo isotopy (group of isotopic classes) i.e. MCG := Aut / Aut0. Nielsen Thurston classification is the nonlinear analogue of the Jordan canonical form for matrices. Other notation is Mod(S) = Diff^+(S, del S) / Diff_0(S, del S). Diff_0 is subgroup isotopic to identity.

Teichmuller space: space of hyperbolic metrics up to isotopic, metric space homeomorphhic to open ball.

Moduli space of Riemann surfaces: quotient space of Teichmuller space modulo the mapping class group.

Classification of surfaces: connected oriented finite type surfaces can be classified by punctures, genus, boundary. Classifying spaces encoded combinatorially in category of ribbon graphs. You can get compact, connected, orientable surface by taking closed surfaces, and removing open disks with disjoint closures, so you just need genus of surface, and boundary components. Then for noncompact surface, remove points from interiors, then you have punctures. Therefore surfaces (compact, connected, oriented that is possibly punctured) is classified up to genus g, punctures OR marked points n, and boundary b.

Euler characteristic of compact/punctured, connected and oriented surface: equal to 2 - 2g - (b + n), equal to altenrating sum of Betti numbers, the -2g is OK from what we understand about holes comparing torus to spheres. -(b + n), this I am not so sure.

CW approximation theorem: for any space X, there is an induced map Y to X for some closure finite weak topology complex Y with induced isomorphism of homology, homotopy and cohomology groups.

Modular arithmetic: m divides a - b means a = b mod m, a dividend, b remainder, m divisor.

Coprime ideals: sum of coprime ideals give the full ring, There are coprime numbers, coprime ideals, coprime polynomials. For corpime integers we have au + bv = gcd(a,b) = 1. This fact should be exploited when you think of coprime.

Bezout's identity: linear combinations of integers are equal to their greatest common divisor i.e. au + bv = gcd(a,b). Proof: if u and v are coprime, Z as linear combination have 1 as unit vector so linear combination au/gcd(a,b)+ bv/gcd(a,b) = 1 since primes are orthogonal vectors on integers. Multiply by gcd(a,b) to get the result. Alternatively, apply Euclidean algorithm backwards using the fact that intersections of linear combinations with the integers must have minimal element (or gcd(a, b) is minimal). Since these are linear combinations, by induction linear combinations of scalars of primes are equal to the greatest common divisor of the scalars.

Fundamental theorem of equivalence relations: classes of equivalence relations either equal or disjoint but not both and one can some the cardinality of classes of equivalence relations. Proof: if disjoint we are done. Suppose not disjoint, construct equivalence from element in one set to element in other set, so they must be equal sets (used the fact that sets have no repeated elements). For cardinality relation, apply cardinality functor from category of Sets to category of Naturals taking union into sum.

Freyd-Mitchell embedding: small abelian categories embeds fully and exactly into the category of R-modules over suitable ring R

Brouwerian counterexample: statement implies principle that is non-constructive. Example: something implies Zorn's lemma

Extensionality axiom, sets pictured as trees have unique branches

Foundation axiom, branches of sets pictured as trees cannot have infinite length

Von Neumann hierarchy, recursively take subsets of sets, taking unions at end of ordinals to define ordinals

Comprehension axiom: can always find a set of also some property, fails due to Russell's paradox

Pairing: inductively find sets of pairs of elements

Axiom of choice: pick some element from sets of elements to find a new set, this new set exists. Alternatively, there for a set X there exist a subset of X from each part of the paritition. This make the axiom of choice powerful, since it defines each equivalence class with a canonical representative element (when I realised this I finally understood why the axiom of choice is controversial).

Axiom of choice equivalence statements: the following are equivalent: (1) product of a collection of non-empty sets is non-empty; (2) posets which every chain has an upper bound must have a maximal element; (3) every set can be well ordered; (4) product of compact topological spaces is compact; there is a bijection A -> cartesian product A * A; (5) all vector spaces have a basis i.e. vector spaces are equivalent to free modules; (6) all unital commutative rings have a maximal ideal; (7) all surjection has an injective inverse; (8) every free abelian group is projective; (9) every spanning set includes a basis;  (10) trichotomy, two sets either have the same cardinality, or one is smaller cardinality than the other; (11) every partially ordered set has a maximal chain; (12) every chain in a partially ordered set can be extended to a maximal chain; (13) Cartesian product of any family of conneccted topological spaces is connected; (14) closed unit ball of the dual of a normed vector space over the reals has one extreme point; (15) in product topology, closure of product of subsets is equal to product of closures; (16) Freyd adjoint functor theorem.

Projective dimension of module: minimal length of projective resolution of module over a ring. Osofosky, projective dimension of modules over ring C[x,y,z] is undecidable in ZFC. 2 if continuum hypothesis holds, 3 if it fails.

Power set cardinality, if card(X) < card(Y), note that card subsets of X < card subsets of Y is undecidable in ZFC.

Whitehead problem: 0 to Z to B to A to 0 is spit short exact sequence. Equivalently Ext1(A, Z) = 0, A and B abelian groups. Does this mean A is a free group? Answer by Shelah is undecieable in Zermelo Fraenkel axioms in set theory.

Split exact sequence: short exact sequence built in the simplest possible way (quotients)

Lex: left exact, preserving FINITE colimits. So it is weaker than left adjoints.

Finitely complete category / left exact category: admits all finite limits, all limits for diagram F : J -> C, J is a finite category. 

Rex: right exact, preserving FINITE limits. So it is weaker than right adjoint.

Solvability: permutations of roots preserving algebraic relations can be used to determine solvability by radicals.

Etale topology: gives a uniform definition of Galois groups and fundamental groups.

Galois group: covering space with fundamental group or universal covering space with algebraic closure. See Galois' dream by Kuga.

Module: additive abelian groups closed under left and right linear decomposition f(ax + by) = af(x) + bf(y) of ring multiples of group elements. Beginner: like vector space over arbitrary ring instead of fields. Module over ring as a homomorphism from the ring to an endomorphism ring of an abelian group.

Endomorphism ring, End(G): set of all homomorphism of G onto itself. Endomorphism composition is product, pointiwse addition is addition. Abelian group is module over ring of integers, initial object in category of ring. 

Snake lemma: three tensor products _ M exact sequences columns with (module) M except for missing zeroes on 0 to Zm to Zn to A to 0 substituting A, B, C for A. This gives exact sequences of complexes and tensor products except at end of sequence of Tors and start of tensor products of A, B, C. To fill in snake belly, zigzag from Tor(C, M) to A _ M. Well defined forwards due to first column having final image zero. Well defined backwards due to rest of columns having final image zero.

Symmetry of Tor(A,B), not obvious because resolutions are taken first. Construct three sequence by on 0 to Zm to Zn to A to 0 by tensoring (already) Zs, Zt, B where 0 to Zs to Zt to B to 0 is exact. Gives well defined zigzag at last steps since final images vanish, warning not well defined at intermediates. So Tor(A,B) to Tor(B,A) is homomorphism. By symmetry, isomorphism.

Uniqueness of Tor under different resolutions: start with different resolutions, note that A to A is isomorphic. We are stuck with Z^(m1) to Z(m2) and Z^(n1) to Z^(n2) as maps called f - g. No problem, defined boundary maps by abuse of notation to be d, and lifts from Z^(n2) to Z^(m1) to be s. Consider f-g =  sd by bottom right triangle, and f-g = ds by top right triangle. Gives argument that f-g = ds + sd, the commutator sum. Therefore f and g are homotopic. Upon taking tensor products of B to give Tor(A, B) or Tor’(A,B) via the typical sequence 0 to Tor(A, B) to B^(m1) to B^(n1) to zero, due to homotopy of f-g, there is homomorphism of Tor(A, B) and Tor’(A,B). Symmetric argument makes this CANONICAL isomorphism.

Tor distributes over the left and right: proof is easy over bad isomorphism to tensor product of abelian groups for a module.

Construction of Tor, take step 1 free resolution 0 -> Z^M -> Z^N -> A -> 0. You can have M and N drawn at the top in your head, then step 2 you take tensor products with coefficients in B. You will get the exact sequence once you compute homology of this which gives 0 -> Tor(A, B) -> B^M -> B^B -> A -> 0.

Free resolution: take free modules as coefficient of chain complexes… C2 -> C1 -> C0 -> 0 as basis of i-th simplex. You can weaken this to projective resolutions for duality between projective and injectives. Take homotopy of complexes when defining Tor.

Projective resolution: infinite exact sequence of modules from ... -> P_n -> ... -> P_1 -> P_0 -> M -> 0, all P_is are projective, M arbitrary modules.

Universal coefficient theorem: compute arbitrary homologies over manifold/space M with arbitrary coefficients groups/functors, G instead of using integers. Typical example sheaf of global sections as a group functor. Let _ be tensor, then you can show that it is 0 -> Hi(M, Z) _ G -> Hi(M, G) -> Tor(Hi(M, Z), G) -> 0, which is not Hi(M, Z) \* G as one naively thinks.

Standard counterexample for Hom sets over the module integers modulo two, take sequence from 0 to Z to Z to Z/2 to zero is exact. Take Hom functor integers on Z/2 so it must be 0 to Hom(Z, Z/2) to Hom(Z, Z/2) to Hom(Z/2, Z/2) which is not right exact since kernel Hom(Z, Z/2) vanish but not Hom(Z/2, Z/2) which is Z/2 as standard double cover. Therefore, Ext must be a left exact functor, corresponding to the double cover obstruction. See Borcherds video for homological algebra. Further, the same counterexample can be used to show Tor is only right exact, 0 to Z to 2Z to Z/2 to 0 is exact. Take tensor products in Z/2 coefficients, you get Z/2 to Z/2 to Z/2 to 0 is exact, so this is right exact. This exemplifies the tensor hom adjunction, and also the tor-ext adjunction. Tensor is left adjoint to the right adjoint which is hom. This is one example of the Eckham-Hilton duality.

Constructing Tor: (1) take free or projective resolution of a sequence of abelian groups, (2) take functor/tensor product, (3) take homology. Gives Tor group with “coefficient” of some functor F. Similar construction for Ext but with injective resolutions.

Probability laws are natural transformations from random variable functor to measurable functor.

Random variable: are Set endofunctors A^{omega}. Measurable function from sample space to measurable space. Motivation: you want a different measures.

Measure space: a triple of a set X, sigma algebra M and a measure mu. Kolmogorov triple works the same way, an triple of an outcome space X, a sigma algebra Sigma, and a probability measure omega.

Measurable space: simply a pair of X is a set and M subset of powerset of X that is a sigma algebra (i.e. algebra closed under countable unions and finite complements)

Idea of a measurable space: pick out subsets where size is well defined, theses subsets are measurable, then assign a number or a measure to those spaces based on how big it is. Not all subsets are measurable if you have axiom of choice, example being Lebesgue measure on the real line.

Borel sigma algebra: set in topological space formed by open sets using countable unions, countable intersections, and relative complements.

Sigma algebra: closed under countable complements, countable unions, and countable intersections.

Ring on set X and collection of subset: a collection M closed under relative complementation under unions of finitary families i.e. empty set is i n M, for S and T sets in M, their union and rleative complement is in M.

Generating sigma algebras: turns out this is very difficult, and it fails for sigma-rings and sigma-algebras. https://ncatlab.org/nlab/show/sigma-algebra you will need descriptive set theory and be very careful to get it, and you need coutnable choice here since you need to show the countable union of a countable union is a countable union.

Microcanonical phase space as an example of a sigma algebra: example take R^N, N is order of Avogadro's number to be microcanonical spahase space P, then take macrocanonical phase space p with R^2 or R^n with features that can be measured. Take PROJECTION of f: P -> p, the preimage of this projection is a sigma algebra on the microcanonical phase space P, the thermodynamic entropy of this system is theorectically the information theoretic entropy with respect to this sigma algebra. This is a neat example that relates it to physics.

Power set as prototypical example of a sigma algebra: a powe set is closed under all operations, so it is a sigma algebra. Feels like some sort of free object with all possibilities covered.

Algebra of sets on X: closed under finite nions and complements. An algebra is a sigma algebra provided it is closed under countable disjoint unions. Replace a sequence of sets with a disjoint sequence. Sufficient to establish that it is closed under countable unions with this.

Preimage of sigma algebras are sigma algebras: prove using the fact that preimages preserve intersections, unions, and relative complements.

Permutation matrix: matrix that is exactly 1 in each column and row. Named because multiplication by permutation matrix permutes the rows and columns.

Reducible matrix: if there exists a permutation matrix such that conjugation (by transpose) oby this permutation i.e. R^T P R, for P permutation matrix gives an upper triangular block matrix, then the matrix is reducible. Intuition is that upper triangular matrix is more or less solved.

Irreducibility gives invariant distribution: row reduction gives an outcast subgroup of nodes, with no arrows pointing out of it, if you think of each row as some node, therefore, we have the existence of a stable distribution.

Weak ergodicity: time average goes to ensemble average.

Primitive Markov chain: exists positive s such that (P^s)_{ij} > 0  for any pair (i, j)

Ergodicity theorem: let {X_m} be irreducible finite Markov chain, then the average of f(X_m) i.e. 1/n sum_{0 to n-1} f(X_m) tends towards the sum of the product of the unique invariant distribution and f(i) as n tends towards inifinity.

Poisson process: {N_t}_{t >= 0} increasing, right continuous, integer valued process. Defined by properties: initial value at zero is zero, then N_t has stationary independent increments, i.e. for totally lineared ordered nonnegative time 0 <= t1 <= ... <= tn, we have N_t2 - N_t1, N_t3 - N_t2 ... being independent.

Ito isometry: expectation of integral of square of the expectation of the function with respect to Wiener process is equal to the expectation of the square of the function with respect to time i.e. Exp(int^T_S f(w,t) dW_t)^2 = Exp(int^T_S f^2(w,t) dt). Proof using simple functions, split into dummy variable, then split into autocorrelated part and uncorrelated part. Apply independence of e_j e_k delta W_j and delta W_k. Also we have B(t)^2 not equivalent to B(t) for Brownian motion B. It is useful because it preserves measure.

F_t adapted: a measurable function is F_t adapted if f(t, -) is F_t measurable.

Natural filtration:  the filtration that records all the information then at that time.

Adapted (in statistics): information of the process is precisely and completely available at the same time. It is an non-antipating process.

Ito integral: consider the diffusion term sigma(X_t, t), then consider the typical Riemann integral definition, where the integral from 0 to time t of sigma(X_s, s) dW_s is the limit as subdivisions go to zero of the Riemann sum of sigma(X_j, t_j)(W_t_j+1 - W_t_j). There are three possible choices for the integral which is either have the left endpoint integral (for the example of integrating from 0 to time T of W_t dW_t) i.e. sum of W_tj (W_tj+1 - W_tj) = 0 (this corresponds to Ito's integral).

White noise: derivative of Wiener process in the sense of distribution. Has constant power spectral density.

Coloured noise: has non-constant, power spectrum density.

Wiener process derivative: comprises of drift term and diffusion term.

Diffusion term in probability: dertivative of the white noise.

Locally ringed space: (1) is a ringed space i.e. all stalks at x are a local ring. Ringed space such that all presheafs are local rings i.e. colimits of global section functors of opens. By duality between commutative algebra and algebraic geometry, this corresponds to maximal ideals; (2) sheaf + topological space. The idea is fairly simple, you have a ring of functions locally on each open set.

Notation for locally ringed space: Spec A is (Spec A, O_{Spec A}) by abuse of notation. Howevr next step is fully faithful functor from opposite category of ring to locally ringed spaces, evolving from opposite category of topological space to sets.

Ringed space (locally ringed in local rings): topological sapce endowed with a sheaf of rings called the structure sheaf O_X on X such that O_{X,x} is a local ring (with unique maximal ideal) for all x in X, denote it as (X, O_X)

Subringed space is locally isomorphic to opens (on some site) cut out by ??? functions on the opens.

Embedding: very loose way to say adjoint to forgetful functor with extra stuff

Symmetric monoidal category: a braided monoidal category where braidings of tensor product in the same product gives the identity on the tensor product. Or, monoidal tensor products have commutativity up to natural isomorphism.

Braided monoidal category: a monoidal category with a natural isomorphism of tensor products with their indices swapped that gives commutativity using some hexagonal diagram (due to using two categories). This natural isomorphism is called the braiding.

Monoidal category: vertically categorified category where the tensor product is a functor from the product of categories to the category itself with nice properties, (need to define 5, associator, left unitor, right unitor, triangle identity, pentagonal identity because you are working with two category.

Proof that right adjoints preserve limits, the one I understood is the proof here https://ncatlab.org/nlab/show/adjoints+preserve+%28co-%29limits: start with the fact that hom adjunction is naturally isomorphic. This is obvious, by definition of adjunction HomC(L(d), c) is naturally isomorphic to HomD(d, R(c)). You will want to pick c to be the limit, since R is the right adjoint. The second thing is that Hom functors preserve limits. Lastly apply Yoneda's lemma, natural isomorphism of Hom sets of objects give isomorphism of objects. Apply the first to second to somehow take out the limit. Apply Yoneda's, the limits are preserved and are naturally isomorphic under action of right adjoints. Formally dual for colimits.

Hom functors, takes product of morphisms in opposite category and category (order is important) to category of set, specifically pairs of morphisms to hom-sets. This preserves limits, taking pairs of (colimit in opposite category, limit in covariant category) to limits in set. Contravariance in first variable C^op \* C means it preserves colimits in the first variable, but C^op reverses this so it also preserves limits. In a sense, the definition of Hom functors ensures that it preserves limits.

Sheaf cohomology: obstructions when you have an abelian group on a space and try to patch things locally on abelian groups.

Sheaf cohomology (Wikipedia gives best definition): right derived functors of left exact functor (here, the functor becomes the “coefficients” of the cohomology) of the sheaves of abelian groups on a space to abelian groups. Implies vanishing on negative sheaf cohomology, and also the zeroth cohomology group is given by the group of global sections of the left exact functor on the space.

Enough injectives: for every sheaf there is an injective sheaf with injection from sheaf to injective sheaf. This is proved knowing that category of abelian sheaves form an abelian category. Abelian category Mitchell embeds into category of modules over ring. Nice Kunneth, snakes.

General working example for pullbacks and pushforwards in motivating homology, consider a continuous map of topological spaces from Y to X, there is a pullback of sheaves over abelian groups f^\_ from Ab(X) to Ab(Y) which requires sheafification first over colimits, however it is better described by the equality between stalks of the pullback composed with its presheaf functor to the stalk on the image of the element. Pushforward of sheaves is easier in this case from f\_\_ from Ab(Y) to Ab(X), where the composition of the pushforward with the (pre)sheaves functor on a topological space X gives the the global sections functor on the preimage of the topological space. The pullback is exact, the pushforward is only left exact. The composition of the right derived functor on the pushforward on some space X gives the sheafification of opens to its cohomology on the inverse images with coefficients in the (pre)sheaf functor. Note that inverse images of a sheaf is typically only a presheaf, need to sheafify again.

Motivation for cohomology, the following are equivalent exact sequence of presheaf/sheaf functors is exact if it is exact in stalks, however the global sections functors only give a left exact sequence. The easiest example considering these presheaf functors with integers as the kernel, sheaves over the reals as the image to the sheaves and sheaves over the cokernel is the unit circle. There is an exact sequence of stalks, given by the double cover as the real image of the integers over the circle as a quotient space, but there is no canonical lift of the identity residing the circle to its double cover. This gives a counterexample to how global section functors (which are continuous maps between the circle to the reals or the double cover or continuous maps between the circle to the circle) are exact.

Cohomology from the abelian sheaf functor to the global sections of abelian sheaves functor can be defined as a right derived functor of the zeroth cohomology of underlying sheaf functor to the global sections functor of sets. This has so called enough injectives for snake lemma.

Topological group. Group with left actions and inverses which are continuous (function which gives opens in domain induced by preimage of the function).

Categorical inverse limit on pairs of objects in a category with projections onto a grading of graded objects and transition morphisms between graded objects that commutes when composed. Specifically the composition of the transition morphism with pre-projection gives post-projection with universal property that gives unique morphisms that exists to this inverse limit. This is also known as a direct limit in category theory. Typical example is the infinite sequence of preimages with closeness at the end (or decidable if you use Stone duality). See construction of a completion of a ring for an example.

Natural projections of the inverse limit: pick out the i-th component of the direct product of an inverse limit. Example: the inverse limit of A_i has a vector a in the direct product (categorical product) of all A_i such that a_i = f_ij(a_j) for all MORPHISMS (you can take A_i to be groups, and f_ij to be group homomorphisms) f_ij : f_j to f_i BUT i <= j (note the order). This is the definition of an inverse system. They satisfy a universal property, so this construction is gauranteed to be unique.

Anima: generalisation of homotopy types

Presheaf is a functor from the opposite of category of opens to sets. Note that the opposite of a category of opens hard to define. Closest thing is spatial frame which is Stone dual to sober topological spaces.

Presheaf with functor F# such that for union of open covers, there is a canonical isomorphism of opens that gives the equaliser of morphisms between product of sections to the product of section (set-theoretic) intersections (overlap). This equaliser is glueing or descent.

Sheafification: the following are equivalent: (1) left adjoint to the fully faithful inclusion of the category of sheaves into presheaves. You can use an adjoint functor theorem. Follows from the key step of the preservation of all limits from the definition of Zariski descent; (2) sheafification is a universal property, morphism of presheaves, sheafify, apply universal property so true for sheaves; (3) intuition is that the best approximation of a sheaf such that the stalks are the same, so inverse image of a sheaf f_pre^{-1} G and sheafification f^-1{G} agrees for small open sets.

Directed system: find upper bound of finite subset, finite limit exists, so there is inductive limit.

Sheafification intuition: presheaves of function which are P is sheafified to sheaves of functions which are locally P.

Separated presheaf: sections F(U) include into product of section of covering opens U_i for any cover.

Sections are the sheaf functors applied on opens.

Left adjoint and right adjoint being the same functor is not an equivalence, consider endofunctor of A-modules taking the module to the zero ideals Hom(0,M) is naturally isomorphic to H(M,0) but these are not equivalence of categories.

Forgetful functors always have left adjoint which is “free” to get back all your structure. The left adjoints have various examples, free groups and polynomial rings are OK, completion of metric spaces and universal enveloping algebras are not OK examples.

Kan extensions are simply induced functors from F\* : Set^B to Set^A given functor F from A to B. Ends describe Kan extensions explicitly.

Special adjoint functor theorem: example: consider inclusion as functor from compact Hausdorff spaces to topological space, it has small homsets for both, Tychonoff theorem gives preservation of finite products, equalisers exist so finite limits are preserved. Subobjects exist, since injective continuous (injective monics) exist and are small, so compact Hausdorff spaces are well powered. Cogenerating set is small, and is unit interval. Therefore by the special adjoint functor theorem, Stone Cech compactification exists as left adjoint to this functor of inclusions

Ergodic theory, semi group actions with no (additively structured) inverses, use this as the basis of modelling dynamics and absorbing states in ergodic theory. See Erdos notes.

Irrational rotation of circle as ergodic: if rational then periodic so not ergodic in fact it is root of unity, there is idempotence on the action and it will not visit everywhere on the circle.

Sign of permutation is inevitable, proof is consider a n sphere, boundary is (n-1) sphere which can be constructed in simplicies/CW complex, but spheres can be realised as sphere spectrum, which correspond to the integers as group under addition forgetting the spectra properly, integers as a abelian group has two automorphisms, trivial and negations therefore there is a well defined homomorphism from symmetric group of n to symmetric group order 2. Related to Tor.

Motivating projective space using solutions: projective space give as many solutions as possible, example x^2 + 1 = 0 fails for R, R is not algebraically closed. The other case is where 0 = 1, you need to turn from projective space into affine space, x + y = 1 and x + y = 2 has a solution of two parallel lines, intersecting at infinity. y = 1 - x, y = 2 - x, same gradient, different y intercept.

Example, take model of group object. We have group, topological group, Lie group, semi direct product. Category of points of topoi is isomorphic to models of theory.

Ultraproduct, Cartesian product modulo ultra filter, filter is family of subset of power set 2^I, I is some indexing or grading, closed under superset and non empty intersections, the following are equivalent filter is ultrafilter, no filter greater than that filter, proper subsets are closed by inclusion or the complement inclusion. Ultraproducts are defining things in first order logic.

Ultrafilter lemma: the following are equivalent: (1) every proper filter on a set X is contained in some ultra filter on X; (2) every prefilter on a set X, there exists a maximal prefilter subordinate to it; (3) every proper filter subbase on a set X is contained in some ultrafilter on X.

Makkai conceptual completeness, for a functor of (coherent) pretopoi, if the induced contravariant functor on models of pretopoi is an equivalence of categories, then the former functor is an equivalence of categories

Boolean ring: it is a ring of idempotent, 0 and 1 are idempotent so it is canonically isomorphic to ring of integers modulo 2. Now, consider 1 + 1 = 0 using the fact that it is a ring and must have additive inverse 1. If you drop additive inverse and have 1 as an absorbing element 1 + 1 = 1, you get (default) disjunction, and it is a Boolean semiring. It is commutative, proof: start with a + a = 0, by substituting a + a with (a + a)^2, then consider x + y, you should get xy + yx = 0 using the same trick, recycle trick to get xy + (xy + yx) = xy. Boolean ring is characteristic 2, so xy = yx. This  is the classical example of a reduced ring, with no nonzero nilpotent elements since 1 is idempotent.

Boolean algebra: is a ring where every element is idempotent. A Boolean algebra is a distributive lattice (ideal in lattice) and a Boolean ring.

Frame: Stone dual to topological space that is a partially ordered set lattice with some defining distribution of conjunction and the existence of either supremum or infinum for every set

Stone spaces: compact Hausdorff spaces which are totally disconnected. Cantor topology is the prototypical example of a Stone space.

Isbell adjunction and Isbell duality, space is geometry, quantity is algebra, take the smooth space and consider its colimit, the left adjunction taking smooth spaces to smooth rings, as copresheafification, consider a smooth algebra, taking its spectrum or sheafification gives its limit which is a smooth space as right adjoint.

Six functor formalism, three adjunctions. You want two adjunctions first, direct image to inverse image for morphisms as adjoints, direct image with compact support with exceptional inverse image or Verdier duality adjoints for separated morphisms, lastly it's the symmetric monoidal tensor product with internal hom as adjoint. See Scholze's notes.

Separated morphism: diagonal morphism is a morphism mapping a space X to its diagonal X with product in Y is such is a closed subspace of the diagonal X to Y. Motivation is from the fact that Zariski topology is not Hausdorff in general.

Diagonal: canonical isomorphism to the self Cartesian product

Internal hom is basically internally defined morphism as object or a generalisation of non set as that identity, however they just define it as right adjoint to symmetric monoidal tensor product Analogous Ext and Tor. Symmetric monoidal Tor means internal Ext. Ext measures defect in how set exactness, Tor measures defect in tensor product exactness.

Direct image with compact support, consider morphism of schemes, consider sections such that restrictions of support to opens are nice.

Pontrjagin dual: easy example is additive on integers to circle group, take products of roots of unity gives Fourier theory. Circle group is compact and connected, integers must be discrete and torsion free by Pontrjagin duality. The exponential maps gives self duality of the additive reals (sums of powers of exponential). This gives a duality between abelian discrete groups like additivity on integers to compact commutative topological groups like the circle group. Several key steps includes construction of the Haar measure and associating it with this group.

Eckhmann-Hinton duality: The most basic duality by reversing arrows in category theory.

Fuks duality: take endofunctors of compact pointed (important for suspensions) Hausdorff spaces. Duality is expressed between loop space and suspension space. Endofunctor of loop space gives suspension space. Endofunctor of suspension space gives loop space. This works heuristically for: homotopy dual to cohomology, mapping cylinder to mapping cocylinder, fibration to cofibration.

Tannaka duality: monoid with its module category are dual, considering automorphisms/endomorphisms of some forgetful functor called the fibre functor that gives the monoid structure. Just apply Yoneda's lemma using the fact that the fibre functor is endomorphism. See also representable functors, and the fact that modules are representations over rings.

Proof sketch for G-set with Tannaka duality (like Cayley's theorem), C as Set^G or GSet Aut(F) = Set^(SetG)(F,F) = Set^(SetG)(SetG(G, -), SetG(G, -)) = SetG(G, G) = G Abusing notation for GSet and isomorphism due to Yoneda's lemma.

Makkai duality: syntax of first order logic (pretopoi) corresponds to the semantics of first order logic (ultracategories). Further, opposite category of small pretopoi maps to ultracategories, ultrafunctors of from ultra category to set has the structure of a small pretopos

Koszul duality: generalising the fact that d^2 = 0 encodes a commutative law and d^2w (differential) = 0, recall that this is case for some long sequences, one can get that having free graded comm algebra on the special linear group into a differential graded algebra is the same as making it into a Lie algebra (Jacobi identity is indeed = 0), duality having free graded Lie algebra on special linear group into a differential graded algebra makes it into a commutative algebra (d^2 = 0 encodes a commutative law)

Graded ring: as an abelian group, it decomposes into direct sums groups of homogenous elements.

C[x] as graded ring: C[x] is isomorphic to C + x^2 C + x^3 C + ...

Standard affine charts: set U_i of (x_0, ..., x_n), x_i nonzero in the complex projective plane of dimension n. Surprised it is not paired with a homomorphism.

Homogeneous variety: algebraic variety of the form G/P, G is LINEAR algebraic group, P is parabolic subgroup.

Conics in complex projective plane: variety V_pr(x^2 + y^2 - z^2) in CP^2, view as subspace of P^3, lines intersect origin, looks like CONIC!, pick x = 1, get hyperbola, y = 1 get hyperbola, z = 1 get circle.

Distinguished open set: Vakil feels principal open set works better. Forms a basis for the Zariski topology on Spec(R). Spec(R)_f = Spec(R) \ V(f). Used to define morphism of sheaves.

Morphisms of sheaves (injective and bijective): are injective/bijective if for all x in X in topological space they are injective or bijective on stalks i.e. p_x: F_x -> G_x are injective/bijective, equivalent to saying they are injective or bijective for all open subsets U or X.

Morphisms of sheaves (surjective): surjective is stricter, it must be surjective on p_x: F_x -> G_x is surjective for all x in X, it cannot only be locally surjective on opens, it must be surjective for all stalks of points.

Locality of spectral space: a spectral space is local if it has a unique closed points. This is similar for saying a ring is a local ring if it has a unique maximal ideal.

Rational function: let U be open in V, V projective variety, rational function on projective variety is quotient f/g, f,g are homogenous of same degree, f,g in coordinate ring C(V) and vanishing locus of p is disjoint with U.

Vanishing locus: kernel of a homogenous map i.e. V_pr(f) = {(x_0, ..., x_n) such that f(x_0, ... x_n) = 0}

Vanishing locus of an ideal: kernel of maps f in ideal i.e. {x such that f(x) = 0 for all f in the ideal}

Irrelevant ideal: the following are equivalent: (1) homogenous ideal, but V_pr(I) = 0; (2) ideal (x_0, ... x_n).

Homogenous nullstellensatz: duality between projective varieties in complex projective space of order n, and homogenous ideals of coordinate ring(x_0 to x_n) EXCEPT for the irrelevant ideal.

Same vanishing locus gives same radical i.e. V_pr(I) = V_pr(J) != 0 implies radical(I) = radical(J): proof, not sure?

Bezout's theorem: forgetful functor from curves d and e of degree d and e in CP^2 intersects at exactly d * e points. Hint: one is the definition of intersection of exactly needed for combinatorics since in projective space, any two lines intersect.

If vanishing locus is empty for an ideal, then either I = (1) or unit ideal or the radical of I is a single point: proof

Ergodicity: all states are accessible from one another. One can lose ergodicity with irreversible decisions. Take some measurable space, impose either actions on monoid of measurable space with measurable functions (random variables) or Markov kernels (don’t understand this), then a invariant measure is ergodic if the measure obeys some zero one law (measure which are only zero and one).

Ergodic theory: statistical properties of deterministic dynamical systems.

Poincare recurrence: almost all points in any subset of phase space eventaully revisit the set.

Ergodicity for compact abelian groups automorphisms: let G be compact abelian group, u normalised Haar measure, T an group automoprhism, G* be Pontryagin dual group, consisting of continuous characters of G, T* be corresponding adjoint automorphism of G*. We say T is ergodic if (T*)^n(X) is idempotent on the character i.e. (T*)^n(X) = X is possible only when n = 0 or X is the trivial character. Basically you do not want T to be idempotent, and you want it to visit everywhere otherwise it will get stuck in some finite loop. 

Example of ergodicity for compact abelian group automoprhisms: pick G as n-dim torus, automorphism T is unimodular matrix, then T is ergodic if and only if no eigenvalue of A is a root of unity. It will not get stuck on some dots on a circle and go back to the identity and it will visit everywhere.

Stabiliser of a group element a is a set such that left action of group element in group G is absorbed into a by a ga = a

Künneth formula, takes products of cohomology to tensor products of cohomology correcting by Tor groups. Like distribution law for Ext and Tor.

Universal coefficient theorem, generalisation of Künneth formula in stable homotopy theory where cohomology or Ext is replaced by suitable spectra, and tensor product or Tor is replaced by smash product

Compatification, include the point at infinity means consider that (or assume that) something is decidable in infinite time is under consideration

Neighbourhood means it is possible to do logical inference in finite time.

Refinement of open cover means better experiment than the open cover itself in terms of efficiency of information obtained.

Open cover refers to decidable experiment in finite time, compact means admits open covers referring to decidable by one experiment.

Example of verification in finite time corresponding to semidecidable logic, verify something is open in finite time, closed set not so because of points in the boundary requiring infinitely many computations. https://math.stackexchange.com/questions/31859/what-concept-does-an-open-set-axiomatise

Stone duality, poset lattice correspond to topology, with poset lattice interpreted as a form of logic, this corresponds to topology being defined as a semidecidable logic, where arbitrary unions correspond decidable disjunctions, finite intersections correspond to decidable conjunctions in finite time.

Pro object: projective, projective limit is older term for categorical limit. Contrast to ind objects or indcutive object, corresponding to inductive limit, old name for colimit.

Profinite sets by Stone duality: profinite set is a pro object in the category of finite sets, using Stone duality these are equivalent to Stone spaces, or compact Hausdorff totally disconnected topological spaces i.e. closed under topology, where distinct points have disjoint open neighbourhoods, with only connected subspaces as singletons or totally disconnected space, which are topological spaces with sets and a collection of sets with sets closed under arbitrary unions and finite intersections. For me, I just think of counting apples, apples as neighbourhoods, and core of apples as singletons.

Profinite set and simplicial stuff: simplicial object in the category of compact and totally disconnected topological spaces.

Etale cohomology, you want a topological or etale topology with arbitrary direct limits and finitely inverse limits, reminiscent of the definition of a topology with arbitrary unions and finite intersections. This topological notion gives the right correspondence for topoi. It has the right derived functor of the global sections of abelian sheaves on the etale sites with families of surjective maps as covers.

De Rham cohomology: sheaf cohomology of the sheaf of locally constant R-valued functions ona  manifold. De Rham complex is resolution of this sheaves by fine sheaves, motivating fine sheaves since these are not injective sheaf.

Morphism of topos should have the same intuition as continuous functions, preimages

Giraud axioms: defines a topos, need flatness unramified so that you don’t have a double cover where one half winds to infinity to map nicely onto the circle.

Etale space, geometrically corresponds to some double cover. The circle is some terminal object that all other objects (looking like etale space) maps into the terminal object, analogous to how double cover maps onto circle.

Prefix free definition of Kolmogorov complexity, constraints on what counts as a definition only. Practical outcomes, products become direct sums of complexity up to additive constant O(1). More importantly, probability of 2^-K converges for prefix free Kolmogorov complexity of K.

Grothendieck's typical question: two examples. (1) if we have a functor from schemes/rings to set, what scheme or ring does it represent? Similarly if we have a spectra, what cohomology theory does it represent by Brown's representability theorem in connected CW complex with base point?

Complete varieties, define them in such a way such that it is easy to generalise. Define proper maps of scheme, pick base scheme a field, then if proper map of schemes exist preimage is complete variety, easy to generalise if you can easily replace the base scheme.

Example of base scheme to define families of schemes, reverse currying, take elliptic curve y^2 - x^3 - ax - b. Instead of working over C2, work over C4, then have a, b fixed point. The inverse image of the fixed point is a family of schemes.

Morphisms of schemes are primary object in Grothendieck's philosophy, the idea is you want to define maps to a base scheme, and every scheme maps to the terminal object the spectrum of the integers. This way when you have some definition of a property of the morphism, you can replace the base scheme to get something else

Z[t]/t^2 thickening of affine line with nilpotent everywhere, K1 contains invertible elements, can tell it is NOT A1 homotopy invariant by picking certain invertible elements that is in one but not the other

Brown representability: all cohomology theories can be represented by spectra, need pointed connected spaces, CW complexes to state LES.

Wedge sum: (1) glue together pointed spaces at the point; (2) coproduct in the coslice category.

Cayley's Theorem, one of my favourites because once you understand Cayley's Theorem, you understand Yoneda embedding and Yoneda's lemma. Note: not trivial, requires key step. Consider underlying element of group x, mapping to left action gx. IMPORTANT: groups are closed, so this is bijection, since this is a bijection on the same set, it is a permutation, so groups must be isomorphic to permutation groups (or subgroups of symmetric groups) under composition of permutations. Yoneda's: considering homset(b, a) mapping to natural transformations nat(hom(a, -), hom(b, -)). This must be an isomorphism, since compositions of morphisms are morphisms (we used the assumption of a locally small category here, this is large enough to only form a set). Therefore, define this as an Yoneda embedding (if on sets), and all small categories are embed into the category of functors of defined on that categories, which are represented by pre-sheaves or representable functors.

Groups as symmetries of something given by Cayley theorem, closure of left action is key step. Some examples include how the circle group embedds in the symmetric group of the natural numbers.

Real exponential exact sequence: 0 to integers to reals to circle group to 0 is a short exact sequence.

Character of abelian group: homomorphism from abelian group A to the circle group.

Circle group: the following are equivalent (by group isomorphism) - (1) quotient group of additive reals by additive integers, induced by the canonical embedding of the integers into the reals; (2) unitary group U(1); (3) special orthogonal group SO(2); (4) subgroup of group of units in teh field of complex number given by fixed positive modulus.

Subgroup of unital associative magmas with inverses preserved. Same unit, same magma operation.

Free abelian group, group by composition of basis elements

Chain complex has free abelian group (have generators as basis) on n simplex with sign alternating boundary maps preserving orientation (clockwise or counterclockwise). Related to Tor.

Nerves, take functor from n simplex to category. Nerve of 0 is object, nerve of 1 is morphism, nerve of 2 is pairs of morphisms. Fully faithful embedding, take forgetful of partial order structure of nerves to get back category

Smooth morphism of scheme, approximated by affine space at any point, no nilpotent, but regular scheme. You want finiteness condition (presentation whatever that means) and flatness. Since this is a morphism of schemes, it is relative and defines a smooth scheme. That is the beauty of Grothendieck's morphism oriented way of thinking. IMPORTANT POINT. YOU WANT THE FIBRES TO BE REGULAR. Example maps between regular schemes can fail to be smooth. Example V(xy) from affine plane to affine line. But the affine plane and affine line are regular schemes!

Regular, think differential geometrically, consider dimension of Zariski tangent space is equal to the Krull dimension (computed using chains of noetherian stuff, max length) of local ring (local rings/ maximal ideals / points)

Krull dimension: supremum of lengths of strict inclusion chains of prime ideals. Example: field has Krull dimension zero. field k[x1 to xn] has Krull dimension n; or maximum length of chain of subvarieties of scheme X, if X is a variety then dim X is the transcendence degree of R(X) over the ground field.

Height (Krull dimension) of prime ideal: the supremum of all lengths of all chains of prime ideals contained in the prime ideal.s The height of the prime ideal is the Krull dimension of the localisation of the ring at the prime ideal for a prime ideal in the ring.

Noetherian ring, Krull dimension: a ring where every prime ideal has finite height.

Fully faithful, get from cohomology to abelian group by taking cohomology of a point

Subobject classifier: basic idea is instead of subset object of a set X, pick a set X then pick a map called a characteristic map chi, the subset is now a characteristic map chi, this is Grothendieck philosophy, use a machine/morphism instead of the thing itself.

Ring: a monoid with tensor product of abelian groups.

Galois extension, normal means linear affines, separable means no nilpotents.

Galois extension is a normal separable extension. Normal means decomposed to linear factor, separable (in the context of Galois theory) means no repeated roots or factors. Automorphism fixing some point. Automorphism of field extension (recall you have some subfield, of a field extension) is an endomorphism (recall idempotence) that is an isomorphism (preserve structure), Galois group is exists for these, on the automorphisms of a field extension. Analogous to linear algebra, Jordan blocks with nontrivial multiplicity.

Subfield and subgroups are bijective, that is the fundamental theorem of Galois theory.

Prime spectrum: colimit of some sort of chain of suspensions. Reminds me of stalks, which are colimits of neighbourhoods of functions.

Maximal spectrum: subset of prime spectrum with all maximal spectrum.

Presheaf, separated presheaf, sheaf: presheaf as contravariant functor from opposite category of Top to Set, separated presheaf means it satisfied locality, sheaf means it satisfies locality and glueing.

Sheaf over empty set is one point set: proof take U be empty, cover U by all the open sets indexed over empty set, sheaf condition says F(empty) is equaliser(product of empties to product of empties), product over nothing is single point, equaliser of unique map from a point to a point with itself, so sheaf over empty set is a one point set.

Prime spectrum of ring A is quasicompact: proof, Spec A be cover of Spec A by open sets, now remove U_i so that Z_i = Spec(A) \ U_i = V(M_i) by Gelfand duality, intersection of V(M_i) is empty, now let a in A be the ideal generated by union of these M_i so by definition V(a) = V(union of M_i). Assume ideal a is not A, so there is maximal ideal containing a, but m is also prime ideal m in V(a) which is empty, so a = A, unit ideal in a, so there exists generating functions such that sum of f_i g_i = 1, Pick finite indexing set J in I so that f_1 ... f_m in union of M_j indexed by J, this tells us that union of these J generates the unit ideals so V(union of M_i over indexing J) = V(A) = empty, so Spec A must be the union of U_k with indexing set J, J finite, so we have quasicompactness. (NOTE: prime spectrum is not Hausdorff in general.)

Spec(-) is functorial: for any ring A, unique map from Z to A, so unique map from Spec A to Spec Z. all of algebraic geometry lives over Spec Z, so you can do number theory. This follows from the theorem that given f from ring A to ring B, Spec f defined by q giving preimage from ideal q in ring B is well defined. The key step for well definedness is that product between elements in ideal and elements in ring is in the ideal in the image of f.

Prime spectrum of Z: all nonzero prime ideals (2), (3), (5), ... ideal (0) as generic point arbitrary to all others, residue fields at these points are finite fields Z/pZ and Q. Elements of Z act as functions of Spec(Z), example n in Z, n(p) = n mod p. Points are fields. 

Prime decomposition in Spec: V(12) = {(2), {3}}, V(64) = {(2)}

Spec f is continuous given f morphism A to B of rings: proof: preimage of closed set V(M) in Spec(A) is V(f(M)) in Spec(B).

Given f: ring A -> ring B, Spec f with q -> preimage of ideal q is well defined: proof x, y in A and xy in preimage of f with codomain ideal q, then f(x)f(y) = f(y) in ideal q (check definition of ideal as absorbings set) by image, so x and y is in preimage of f with codomain ideal q, so preimage of f with codomain ideal q is a prime ideal in A by definition.

Separatedness: (1) cannot be represented by two disjoint open subsets. Generalise to sites!; (2) separated with diagonal map from X -> cart prod of X and X with product topology is closed. Proof: separated, then open subsets fail to meet diagonal so diagonal of X is closed; conversely if closed, take cartesian product excluding diagonal morphism then find disjoint opens, so separated. See Qing Liu's 3.3.1.

Higher inductive types are machine readable homotopy theory. Call yourself again when you define some homotopic object. Example is circle with a base with a type called circle (recursively) and a loop with a type base == base. For 2 spheres, same exercise, use base2 as twosphere, but use idpath of base2 instead of ==. Example, univalence axiom can have this loops as the integers. Interval also work the same logic, interval is defined inductively where zero and one has type interval, then segment is of type zero == one. Suspension, define north and south inductively as susp X, then define meridian as the X -> north == south.

Finite fields of non prime integers: F_4 using irreducible quadratic x^2 + x + 1 as quotient of F_2

Rings of integers modulo integer must have prime characteristic, prime powers do not have invertibles, classic example is 2 \* 2 is not invertible in Z/4.

Fermats little theorem by induction using binomial theorem: induct, then you get (a^(p) + 1) mod p to (a + 1) mod p using induction hypothesis, the 1 appears at the last term of binomial coefficient (a^p) due to many terms being a 

K-theory: (1) vector bundles, pick nice things like infinity-ring or spectra (2) sheafify with site, Zariski, etale, Nisnevich 

The type of functions is denoted by a witness a to a morphism of propositions A -> B so we have a : a -> B.

Type witness pair, a is a witness of proposition A (proposition as types) we denote this by a : A.

Bool as a two type: can be thought of as a type of propositions.

Equality and homotopy path lifting property: path lifting is done for projective, but I do not understand.

Function type is analogous to Cartesian product since both can used as primitives to construct a type theory.

Spectrum (sphere): representation of cohomology by Brown representability theorem.

Fields: (1) every element is invertible; (2) every module (vector space) over fields are free or have basis (need Zorn's); (3) matrix analysis, the main definition is that it be closed under "addition" and "multiplication"; (4) localise to become so small in affines like dots.

Smash product: (1) generalised tensor product which is a product that is bilinear since a ring is a monoid with tensor product of abelian groups. Tensor product corresponds to Tor; (2) tensor product in coslice category.

Field extension: define some subfield with some subset, then the main field is the field extension. Also, the subset is adjunction to the field extension. From field to field extension, if it is a ring homomorphism preserving ring structure, must be an injection.

Division ring: ring where 0 != 1, and every nonzero element has multiplicative inverse, if noncommutative then it is skew field.

Eilenberg-Steenrod axioms for cohomology: contravariance, homotopy invariant, excision, suspension isomorphisms, disjoints to products, dimension axiom.

Contravariance, maps X to Y induces maps the other way round

Excision: cohomology of Y vanishes on X, then it must come from reduced cohomology of X mod Y as quotient group. Somehow can be used to prove the Freudenthal suspension theorem.

Homotopy invariant, preserves homotopy which is some interval map that is a continuous idempotent endomorphism.

Suspension isomorphism, cohomology of space is isomorphic to suspension of a space up to shift by one.

Disjoint unions of spaces form products of abelian groups under cohomology

Dimension axiom, get back abelian group taking zeroth cohomology of a point, vanishing otherwise. Should feel like considering vector space when you take cohomology of a point. Points are like fields, take zeroth cohomology should feel like vector space.

Total singular complex in May's book is the same as a CW complex, proof of S(X) has extension property.

Square of stable infinity categories Cartesian. You have D(R) D(R[1/f]) D(R[1/g]) D(R[1/fg]) being commuting as Cartesian. D is derived category of a ring. Note that the quotient looks like Zariski descent already.

Motivic homotopy theory: use affine line instead of unit interval in definition of homotopy.

Retracts are continuous idempotent (or misleadingly, projections) endomorphisms. Projections are similar, but the main difference is that projections sort of reduce the dimension. Projection in linear algebra are not invertible.

Deformation retracts are continuous homotopic idempotent endomorphisms. Difference is notion of time.

Cobordism: you draw two spaces, draw some cylinder in between two of them, that is a cobordism somehow. Natural space like thing that looks like a morphism.

Group completion of finite sets gives sphere spectrum. Barrett-Priddy-Quillen theorem.

Bott periodicity: take complex k theory of point of higher degrees. Of even degrees it is integers, vanishes for odd degrees. Not sure how you get the right way round?

Symmetric spectra, some centrality, defined by some suspension, unit isomorphism, stable homotopy groups, multiplication maps. Take some chain of smash products must be equivariant (domain and codomain acted on by the same group) both acted on by symmetric group. A monoid of this is a symmetric ring spectrum. With pointed simplicial sets.

Types, you have witness k of a type K. Denoted by k : K. K is proposition, in some universe with type ambiguity Ui : Ui+1 vanishing to avoid paradoxes. Propositions, are analogous, set objects which are analogous to points.

Family of types: is known as a context.

Types of maps: corresponds to proofs corresponds to functions on sets corresponding to function spaces.

Simplicial set: is a presheaf on the simplicial category with finite non empty totally ordered sets as objects and non decreasing monotonic maps satisfying the cosimplicial identities.

Kan condition: compatible by deletion of adjacent, and a simplex delete a vertex and get back any vertex. NOTE: in May this is called Kan extension, but modern literature saves Kan extension for categorical notion.

Suspension. Draw two points at the top. Make suspension. Somehow there is some sigma and somehow you can spam it till infinity.

Spectra, some cohomology theory, fully faithful from abelian group. Generalise abelian group. Examples. Spectra means I can use geometry

Propositions as types, you want types to be points.

Higher inductive type. Motivation! Apply homotopy theory methods in logic. Most exciting part, thing I care about.

Motives: realisation from some nice category to explain other cohomology theories.

Ring: (1) an abelian group with a monoidal structure that interacts with the abelian group via the tensor product; (2) Ab group + means associative, commutative, additive id, additive inverse, where Ab group *, associative, multiplicative identity, and distributive.

Smash product: tensor product in spectra.

Magma: means set with binary operation. Unital associative magma, monoid. Unital associative invertible magma, group.

Spec(C[x,y]) drawing: Three types of prime ideals. Maximal points. Non-closed 1D points that look like curves that contain maximal closed points so it is irreducible, and a generic point, if you localise you invert everything that is not in C[x,y].

Spec(R[x]): Line affine line, with ramification points of complex conjugate pairs.

Mapping from Z -> Z[i] gives mapping from Spec (Z) \leftarrow Spec(Z[i]). This gives three types. Ramification points, no primes, splits into two.

Picard group: (1) corresponds to a group of line bundles. This assigning a vector space 1D to each point. Group completion of Dedekind domain gives ring of integer and Picard group; (2) Picard group is the Pic(X) = {invertible O_X-modules which are called line bundles} / isomorphisms, where X is a scheme.

Quasi-coherent sheaf O_X module, X is a scheme is of finite type: if there exists an open cover X is the union of opens of U_i with U_i = Spec A_i such that M(U_i) is a finitely generated A_i module where M is some O_X module. See Scholze Proposition 12.20.

Noetherian scheme: the following are equivalent: (1) X is quasicompact scheme, for all open affines U = SpecA in X, the ring A is noetherian. Classif cexample of demanding property on open affine cover of scheme X (see local compactness), which descends to a property of all affine open subschemes of X.

Philosophy of invertible sheaves: varieties are looked at classically as topological spaces, instead study varieties as functions of them (using the language of bundles, using some sort of duality). So we study line bundles instead using the sheaf of sections.

Invertible sheaf on variety: let X be variety, it is an O_X module (local ring L) with open cover U_i (hint local definition) such that there are isomorphisms L|U_i to O_{U_i}, agreeing on the intersects i.e. there exists invertible functions f_ij on overlaps U_i intersect U_j such that for any U in U_i intersect U_j, p_i(z) function on U is equal to f_ij p_i(z). Cocycle condition follows from this definition.

Line bundles defined as invertible sheaves: invertible ring O_X-modules, X is a scheme, see theorem 12.15 in Scholze's notes. See also Vakil notes (introduction to algebraic geometry, class 21).

Classical line bundles on complex manifold: cover U_i, trivilisations U_i cross C, C is complex numbers, and transition functions f_ij satisfying cocycle condition i.e. f_{ij} f_{jk} = f_{ik}. Constructed so that if u is in intersection U_i and U_j, then (u,z) in U_j cross C, is such that (u, f_ij z) is in U_{ik} cross C. Cech cohomology gives this as an element of the Cech cohomology on space X with the group being the sheaf of invertible (= nowhere zero) analytic functions.

Cocycle condition: f_{ij} f_{jk} = f_{ik}, functoriality condition.

Bundle over category generally: object B in category C, a bundle is an object E of C equipped with a morphism called the submersion / projection in C from E to B. Picture, B is base space, E is total space, bundle is E, fibres E_x over generalised element x in B is the pullback x^* E (limit, see Lawvere's Conceptual Mathematics for this to make sense). So pullbacks x^* E are bundles over generalised element (or points) x in base space B. Fibre bundles require homeomorphisms, pullback of the bundle along the inclusion of a point as open and homeomorphic. Espace etale require local homeomorphism, there exist a covering open neighbourhood where image of stalk is open in base space, and is homeomorphism.

Comparison of bundles over category to etale space: etale space is object p: E -> B in Top/B, like fibres E_x  also in Top/B such that p is local homeomorphism (exists local neighbourhood, think locality definition such that image is open in base space, and it is homemomorphism). So pullbacks are stalks of p over x (stalks for etale space, pullbacks more generally). Total space is union of STALKS for etale space (not fibres FOR COVERING SPACE).

Example of stalks not being fibres (OVER covering space but instead over ESPACE ETALE): espace etale are typically not fibre bundles. Example: consider sheaf of sections t_M of tangent bundle TM -> M of manifold of smooth variety. Fibre bundle is vector space (of tangent vectors) by definition as vector bundles, but stalk of sheaf of sections t_M is at best module over LOCAL ring O_x. Local ring O_x need not be a field (recall definition of local homeomorphisms, ). More explicitly, stalk is germs of vector fields at x, fibre is tangent vectors. Local homeomorphisms are not local isomorphisms in natural way.

Morphisms of bundles: a morphism such that both E_1 and E_2 have morphisms to B, i.e. a certain diagram commutes where E_1 -> E_2, E_1 -> B, E_2 -> B. Morphisms of bundles allow for construction of category.

Group completion of circle S1, give trivial Z and Mobius band Z/2 since two mobius bands give circle

Group completion needs Zariski sheafification ahead of time to work on some projective modules thing.

Ideal class groups: (1) corresponds to Picard group schemes of the ring of integers; (2) for number field K, quotient group J_K/P_K, J_K is group of rational ideals of the ring of integers K, P_K is its subgroups of principal ideals;

Class number of algebraic number field: order of ideal class group.

Motivation of class group: measures how unique factorisation fails.

Discrete valuation ring corresponds to Sierpinski two point space.

Intuition of valuation rings: S = Spec Z, scheme X is separated equivalent to X quasiseparated and for every valuation ring with fraction field K, X(V) -> X(K) is injective.

Chinese Remainder Theorem: (1) giving a function on a disconnected space is the same as a giving a function on its connected components for disjoint union of subvarieties. This corresponds to the product of the spectrum of two schemes which gives the disjoint union of schemes; (2) representations of ideal of composites can be decomposed that of prime finite fields

Spec(C[x,y])/(x,y): local ring at one point.

Spectrum of zero ring: empty since zero is not a prime ideal and zero is not an integral domain. Hartshorne define it this way.

Integral scheme: the following are equivalent: (1) a scheme X is integral if the ring O_X(U) is an integral domain for all nonempty U open in X; (2) an irreducible and reduced scheme;

Integral scheme is not a local condition: A = k * k, A not integral, but Spec A = disjoint union of two copies of Spec k, k is integral domain.

Kernel of surjective map from rings to fields correspond to maximal ideals.

Localisation of quotients and taking of quotients of localisations are equivalent, and they both give a residue field. Geometric intuiton is that they become a point.

Stalks of sheaves: (1) represent localisation of A-module at prime p or local rings; (2) colimit for x in open U, and U in Ouv(X) sheaf of open U, note this colimit is taken over a filtered indexing set; (3) stalk F at x is the pairs of open set U and s such that x is in U which is part of Ouv(X), and s is in F(U) under the equivalence relation if there exists a V contained in intersection of U and U' such that s|V = s'|V. These are the equivalence class of (U, s) int the stalk. The filteredness let us say that the functor defined by taking stalk of a sheaf is exact by showing filtered colimits of abelian groups are exact; (4) direct limits over open subset containing a point; (5) if B is a basis of topology X then stalk of F at x is the colimit for x in open, U in basis for sheaf over U F(U), comes from the fact that all opens U in basis containing X is cofinal in the set of all opens containg X, useful when we look at structural sheaf of the spectrum of ring A, taking very nice values of the basis of principal open subsets.

Skyscraper sheaf: (1) like Dirac delta distribution.

Mapping from Z -> Z[x] gives mapping from Spec (Z) \leftarrow Spec(Z[x]). Fibers are finite field. Horizontal lines are quadratic residues. Fiber at zero is the ring of quotients, invert anything nonzero.

Fibres of O-module of locally ringed space at point p correspond to F_p / m_p F_p, fibre at p quotient out by residual field?

Fibres of presheaf F at a point y: (1, Gelfand/Manin) set F_y of all germs of presheaf F at this point, note that given the language of inductive limit, the fibre F_y is the inductive limit of holomorphic functions for variety V and presheaf F on V.

Glueing is flat descent. Categorically: 0 -> F(U) -> product of F(U_{i}) -> product of F(U_{ij}) is exact. There exists an exact sequence of products of overlapping open covers in topological space. Motivates the definition of site: where we generalise with fibre products, and open covers are generalised to sites.

Tangent space: assign polynomial its linear term in Taylor's series at point a, take all equations describing variety X, linearise them at a, take the common zero locus. Approximates local dimension. Oh this is magical reading it again.

Regular local ring is an integral domain: a variety that is regular at a point should not consist of several components that meet in this point. This corresponds to the points being able to be approximated by affine varieties at that point, see also definition of smoothness, but they approximate it by Euclidean space with Euclidean topology instead.

Valuation of an element: order of vanishing of a local function on a curve at a point. Note: works on any integral domains and quotient fields, so can be in any abelian group and not just integers. Example: for a k to be a field of rational functions of variety X around smooth point a, the valuation can be thought of as an order of a zero or pole at smooth point a in the variety.

Fields as zero dimensional regular local rings: smooth schemes modelled by affines with Krull dimension zero.

Fields as commutative division ring: compare and contrast with skew fields. All finite division rings are commutative and are finite fields by Wedderburn's little theorem.

Discrete valuation rings: one dimensional regular local rings, ;ocal properties of smooth points on curves.

Singular curve: some sort of self crossing in the curve. Nonsingular means no crossing.

Dedekind domains geometrically correspondence: irreducible smooth curves in algebraically closed fields.

Dedekind domain: (1) normal, noetherian, integral domain such that dim Spec A = 1 so Spec A has a generic point and closed point; (2) for C normal curve over field k, for all open U  = Spec A in C, then the ring A is a Dedekind domain; (3) K is finite extension of Q, integral closure of Z in K is sheaf of rings O_K, then O_K is a Dedking domain;

Analogy between number field case and function field case: Spec O_K, K number field is analogous to curves over a field.

Toy example for ample line bundles: line bundle O(1) over projective space P^n_k is ample.

Picard group of Dedekind domain corresponds to how far the Dedekind domain is from unique factorisation domain. See also K-theory of Dedekind domain giving the direct sum of the integers with its Picard group.

Prime factorisation: Decomposition of varieties into pieces that cannot be subdivided further. Prime factorisation also encodes orders of vanishing of function f of all points of a irreducible smooth curve X. Example: X = V(y^2 - x(x-1)(x - \lambda)) in Gathmann's notes. Exercise: draw this Pick general linear function l, general line crosses at three points which are maximal ideals so (l) = P_1 * P_2 * P_3, special linear functions l' COINCIDES so (l') = P_1' P_2'.

Underlying valuations on the local rings: defined originally not only on these discrete valuation rings, but also on their quotient field. Geometrically, this means that we can equally well consider orders of rational functions, i. e. quotients of polynomials, at a smooth point of a curve. These orders can then be positive (if the function has a zero), negative (if it has a pole), or zero (if the function has a non-zero value at the given point).

Zariski topology on k^n exists and is unique: check affine algebraic set are closed under arbitrary sections and finite unions. V(empty) is k^n and V(1) is empty, intersection of varieties are varieties under the union of affine algebraic sets for arbitrary intersections, for closure under finite unions, induct on union of two affine algebraic set, union of varieties are varieties of product, so we have containment of union of V(M_1) and V(M_2) to V(M_1 * M_2), now converse is more subtle, cosnider nonzero f in M_1 and fg(x) = f(x) g(x) = 0 in M_1 M_2, f(x) is nonzero, we are in a field (integral domain), so g(x) must be 0 for all g in M_2, so x is in V(M_2) showing that if you are in V(M_1 * M_2) you are union of V(M_1) and V(M_2).

Zariski topology: closed sets are exactly the affine topological sets, disjoint union of closed sets in Zariski topology is empty.

Dimension of variety: supremum of chain inclusions of irreducible closed subsets / subvarieties X.

Condensed formalism: compact (all limit points are points), Hausdorff (disjoint opens exist), totally disconnected

Codimension of Y in XL supremum of chain inclusions of irreducible closed subsets / subvarieties from Y to X. Local dimension at this point. Local dimension of irreducible variety is the same at every point.

Pure dimension: valid only for Noetherian topological spaces, every irreducible component has same dimension which is n. Affine varieties with pure dimension 1 are curves, pure dimension 2 are surfaces, more than that hypersurfaces. Examples where definition of pure dimensions breaks down includes a line (variety) passing through a plane (variety)

Subvariety Y on fixed variety X: ideal of all functions on X that vanish on Y. Specifically, radical ideals. Ideals of subvarieties are always radical and exact on algebraically closed fields.

Morphism of varieties: ring homomorphism with source and target reversed. Made automatic with presheaves as contravariant functors from category typically of rings to category of (open) sets. Sections of presheaf are elements of ring of functions on open sets.

Germs of (pre)sheaf at point a: functions defined on small neighbourhood, these are local functions. Examples: rational functions with nonvanishing denominator at point a.

Stalks of a (pre)sheaf at a point, like localisations of presheaf at some point. These are used to define local rings, see definition of local ring in Fulton's intersection theory.

Passing from ideals to varieties reverses inclusions. Smaller zero ideal generates whole space. Vanishes on whole space.

Localisation makes more elements invertible by allowing fractions, geometrically it is zooming in on a variety at a local point.

Spectrum of integers. Points of all prime ideals, with a fat point with the zero ideal.

Full space: zero ideal.

Empty set: (1) as ideal or the unit ideal. Useful in showing (quasi)compactness of Zariski topology?

Intersection of subvarieties: sum of ideals.

Union of subvarieties: product or intersection of ideals.

Difference of subvarieties: quotient of ideals. Strictly, the difference Y \ Z is in general not a variety, so the exact geometric operation corresponding to quotient ideals is taking the smallest subvariety containing Y \ Z.

Disjoint subvarieties: coprime ideals.

Absolute product in category is fibered product over the final object: example X * Y = X *_Z Y in the category of schemes, example X * Y = X *_S Y in the category of S-schemes like S is the spectrum ofthe field.

Fibered products correspond to tensor products. Exercise: draw fibered products.

Fibered products always exist (see Vakil notes): proof key step is to check that Spec A *_C B  correspond to universal property for tensor product, when we think of tensor product as cofibered product in the category of rings.

Vector bundles are equivalent to class groups. Exercise: make sense of this. See also the above about representation of fundamental groups being locally constant sheaves aka bundles. Also, prove integers as principal ideal domain from homology of torus and classification of surfaces.

Lattice of integers correspond to the adjoining a root onto the integers.

Homology or cohomology show how far it fails under localisation. Exactness give some Euler characteristic +2, F - E + V - 2 = 0. Mike Hopkins add holes become zero, easy way to remember is to divide the a torus in the regions. 4 barriers, 4 regions, no vertices, so zero.

Zero germ corresponds to localisation of maximal ideal at point p being zero. See also stalks.

Images of varieties: contraction of ideals.

Inverse images of subvarieties: extension of ideals.

Prime ideals: (1) irreducibles or points; (2) a and b if product ab is in P, then either a or in P or b is in P; (3) ideal where Euclid's lemma apply, p prime number, p divides ab then p divides a or p divids b.

Maximal ideals: closed points.

Not every ring is the coordinate ring of a variety, so for general rings we have to find an algebraic argument (Zorn's lemma) that ensures the existence of maximal ideals.

For every ideal in a ring, a radical of an ideal consists of the intersections of prime ideals is shown by Zorn's lemma. This corresponds to the geometrically obvious statement that the variety is the union of its irreducible subvarieties.

Another construction that requires Zorn's lemma is that if you have 0 -> F' -> F -> F'' -> 0, the functor F(U, -) is exact if F'is a flasque sheaf, left exact in general, surjectivity need to be proved with Zorn's lemma.

Fractions: rational functions that are local functions well defined at a point.

Rational functions: let U be open subset of variety V, rational function on U is a quotient f(x) / g(x) of two elements f and g in coordinate ring of the variety V, requiring g(x) to be nonzero 

Localisation: restricting function to arbitrarily small neighbourhoods q. Like defining differentiability and continuity.

Localisation as u(as' - a's) = 0 for some u in S, S multiplicatively closed. Gathmann gives an immediate way to remember geometrically: Pick point a = (1, 0), (y/1) and (0/1) must agree for variety X = V(xy) but fails since (y * 1 - 0 * 1) is not equal to 0. This is fixed by introducing x so x(y * 1 - 0 * 1) = xy = 0.

Noetherian: finite descending inclusion chain of varieties towards empty. Make subvariety smaller by dropping irreducible component or reduce dimension of subvariety. Decomposition of a subvariety into finitely many irreducible subvarieties is always possible for Noetherians.

V(x,y) is y = x is a point.

V(xy) is xy axes.

Embedded components: subvariety contained in another subvariety. Example is (0) as fat point contained in line for the spectrum of integers, isolated points. The corresponding algebraic statement is that P_2 contains another prime ideal P_1 occurring as a radical in the decomposition; we will also say that P_2 is an embedded and P_1 an isolated prime ideal.

Artinian: finitely ascending chains of varieties. So Artinian coordinate rings are finite unions of points. Not true for Noetherian. Algebraically, this means zero ideal is always product of maximal ideals.

Prime and irreducible elements. Consider coordinate ring R = R[x,y]/(x^2 + y^2 - 1). Irreducible. Since it is a circle, not a product of two lines. Lines are linear polynomials in R[x,y]. It is still irreducible in R since lines must cross from inside to outside. This is not prime in R since it consists of two points. Exercise, reproduce example 8.7 in Gathmann.

Irreducible: cannot be written as union of closed sets in Zariski topology.

Ring extension map C[x,y] -> C[x,y]/(f) (smaller ideal to larger ideal) is morphism of varieties pi from larger variety to smaller variety. Drawing only the real points, we have examples of points V(xy) with morphism pi to the real line (V(x)). Exercise: reproduce Gathmann 9.4 as exercise. Inverse images of pi are fibers. Geometrically, this is an infinite fibre at x = 0. Try examples of y^2 - x^2 giving two point fibres except at origin, and xy - 1 giving one point fibres except empty fibre at origin. The precise geometric correspondence is more complicated.

Normal domains: Coordinate ring of irreducible varieties. Quotient field are rational functions well defined except at isolated points where denominator vanishes. Example: C[x] is normal, rational function is ill defined as a pole but cannot satisfy monic relation since its highest order pole cannot be cancelled by lower order poles. R[x,y]/(y^2 - x^2 - x^3) is not normal, looks like reducible two lines V(x+y) V(x-y) at origin approaching +1 and -1 at origin.

Noetherian normalisation: example of V(x_1x_2 - 1) fails lying over at origin. Coordinate transform to tilt it to V(y_2 - y_1^2 - 1), x_1 = y_2 + y_1, x_2 = y_2 - y_1. Lying over is OK. See Gathmann notes.

Finite ring extensions: surjective geometric maps with finite fibers preserving dimension. See example 9.19 in Gathmann.

Sum of radical ideals are not radical. Easy: take tangent of V(x^2) and V(x)

Blowing up: replace origin with a projective space to see inside it.

Regular local ring is always an integral domain (no zero divisors): variety is locally irreducible at every smooth point.

Fat points: See Spec(K[x]/(x^2)). There is a fat point at the origin on an affine line you can only see linearisations, on a plane it will start to stick out more.

Local rings: (1) rational function with well defined values at point and does not admit similar evaluation maps since the denominator of the fraction might vanish there i.e. unique maximal ideal. Note that Zorn's lemma only guarantees existence and not uniqueness, so uniqueness is important; (2) local ring of scheme X along variety V denoted O_{V,X} is the localisation of such a coordinate ring at the corresponding prime ideal; (3) local ring O_{V,X} is the stalk of the structure sheaf O_X of scheme X at the generic point of V.

Projective curves: add point at infinity for parallel lines to intersect. Embed each point (x_1, ..., x_n) to (1, x_1: ... x_n) as affine coordinates, the reamining points are (0, x_1: ... x_n) as points at infinity so P^n = A^{n} \cup P^{n-1}. as affine and infinite part. Analysts call these Riemann spheres.

Flatness at level of schemes: Let f : X -> S be a morphism of schemes, and assume that S is reduced. (i) If S is a smooth curve then f is called (geometrically) flat if no component of X is mapped to a single point in S. Here by component we mean an irreducible or embedded component, i.e. (in the affine picture) the subvarieties of X occurring in the primary decomposition of the ring that defines X.

Weak Nullstellensatz shows that the “traditional points” are present as points of the scheme, carries over to any algebraically closed field. If the field is not algebraically closed, traditional points are glued together into clumps by Galois conjugation, as in real affine line and the affine line over F_p. Maximal ideals become these points.s

Quasicompact and quasiseparated if and only if X can be covered by a finite number of affine open subsets, any two of which have intersection also covered by a finite number of affine open subsets. I notice that affines causes the word quasi.

Consider the case A = C[x, y]/(xy) and f = x. What is the localization A_f? The space Spec C[x, y]/(xy) “is” the union of the two axes in the plane. Localizing means throwing out the locus where x vanishes. So we are left with the x-axis, minus the origin, so we expect Spec C[x]_x . Exercise: what natural isomorphism is there?

Suppose we have a function (ring element) vanishing at all points. Then it is not necessarily the zero function! Why, nilpotent. The translation of this question is: is the intersection of all prime ideals necessarily just 0? The answer is no, as is shown by the example of the ring of dual numbers k[\epsilon]/(\epsilon^2): \epsilon is not equal to 0, but \epsilon^2 = 0. Any function whose power is zero certainly lies in the intersection of all prime ideals. Functions are not determined by their values at points: the fault of nilpotents.

If a ring has no nonzero nilpotents, we say that it is reduced. Compare to irreducible.

Projective n-space is the union of lines through origin in dimension n+1.

A geometric point of a scheme X is defined to be a morphism Spec(k) -> X where k is an algebraically closed field.

A geometric fiber of a morphism X -> Y is defined to be the fiber over a geometric point of Y, i.e., the fibered product with the geometric point Spec k -> Y.

A morphism has connected (respectively. irreducible, integral, reduced) geometric fibers if all its geometric fibers are connected (resp. irreducible, integral, reduced). One usually says that the morphism has geometrically connected (resp. geometrically irreducible, geometrically integral, geometrically reduced) fibers.

A k-scheme X is geometrically connected (resp. geometrically irreducible, geometrically integral, geometrically reduced) if the structure morphism X -> Spec k has geometrically connected (resp. irreducible, integral, reduced) fibers. Recall Grothendieck's philosophy where you want to define the structure morphism to get these properties over a base spectrum/scheme Spec k. We will soon see that to check any of these conditions, we need only base change to k.

Site: a structure that enables descent not by using intersections of subsets in descent with fibre products. See condensed formalism intro by Scholze.

Zariski cotangent space of a local ring (A, m) is defined to be m/m^2; it is a vector space over the residue field A/m.

The dual vector space is the Zariski tangent space. If X is a scheme, the Zariski cotangent space Tv at a X,p point p in X is defined to be the Zariski cotangent space of the local ring (O)(X,p) (and similarly for the Zariski tangent space TX,p). Elements of the Zariski cotangent space are cotangent vectors or differentials; elements of the tangent space are tangent vectors.

Schemes: (1) are topological spaces with a sheaf of unital rings whose colimits over all values of this sheaf on open subsets over every point called stalks that must be local rings or rings with a unique maximal ideal; (2) schemes is a locally ringed space with a covering of X by open subsets such that for each open U_i and structure sheaf of X at each open U_i i.e. (U_i, O_{X at U_i}) is isomorphic to a affine scheme.

Localism in definitions using basis: (1) have some local properties in open subset / sites, then (2) collection of these sets form basis to construct what you wants. Examples include: locally path connected where basis of open sets is path connected, locally contractible where basis of open sets is contractible, locally ringed space with a ring of function at each open set.

Localism in definition using containment: (1) have some opens / sites contained in set with desired property; (2) use this collection of opens as some basis. Examples include: locally compact where opens are contained in compact sets, fibre products where basis of sets are products glued on a base space to form a total space.

Localism in definition using points: (1) local property is defined at point; (2) neighbourhood of points have these properties and form basis. Example: analytic functions locally at a point has Taylor's series. Examples include: locally finite where each point has neighbourhood intersecting finitely many points.

